{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 19 12:02:36 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  On   | 00000000:B1:00.0 Off |                  N/A |\r\n",
      "| 27%   32C    P8     1W / 250W |     11MiB / 10989MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 0.05,\n",
      " 'dataset': 'CUB',\n",
      " 'dim': 512,\n",
      " 'gamma': 0.7,\n",
      " 'gpu': '0',\n",
      " 'hyperbolic': True,\n",
      " 'init_weights': None,\n",
      " 'lr': 0.001,\n",
      " 'lr_decay': True,\n",
      " 'max_epoch': 10,\n",
      " 'model_type': 'protonetwithhyperbolic',\n",
      " 'query': 15,\n",
      " 'save_path': None,\n",
      " 'shot': 1,\n",
      " 'step_size': 20,\n",
      " 'temperature': 1,\n",
      " 'train_c': False,\n",
      " 'train_x': False,\n",
      " 'validation_way': 5,\n",
      " 'way': 5}\n",
      "CUDA IS AVAILABLE\n",
      "using gpu: 0\n",
      "epoch 1, train 1/100, loss=1.5950 acc=0.3333\n",
      "epoch 1, train 2/100, loss=1.5054 acc=0.3067\n",
      "epoch 1, train 3/100, loss=1.9748 acc=0.2800\n",
      "epoch 1, train 4/100, loss=1.6075 acc=0.2400\n",
      "epoch 1, train 5/100, loss=1.5983 acc=0.2000\n",
      "epoch 1, train 6/100, loss=1.5752 acc=0.3067\n",
      "epoch 1, train 7/100, loss=1.5866 acc=0.3733\n",
      "epoch 1, train 8/100, loss=1.6512 acc=0.2133\n",
      "epoch 1, train 9/100, loss=1.5243 acc=0.3867\n",
      "epoch 1, train 10/100, loss=1.5383 acc=0.3067\n",
      "epoch 1, train 11/100, loss=1.5589 acc=0.2933\n",
      "epoch 1, train 12/100, loss=1.6857 acc=0.2267\n",
      "epoch 1, train 13/100, loss=1.6021 acc=0.1600\n",
      "epoch 1, train 14/100, loss=1.5463 acc=0.3467\n",
      "epoch 1, train 15/100, loss=1.5273 acc=0.2533\n",
      "epoch 1, train 16/100, loss=1.6465 acc=0.2933\n",
      "epoch 1, train 17/100, loss=1.5757 acc=0.2000\n",
      "epoch 1, train 18/100, loss=1.4470 acc=0.4267\n",
      "epoch 1, train 19/100, loss=1.3947 acc=0.4133\n",
      "epoch 1, train 20/100, loss=1.4480 acc=0.3867\n",
      "epoch 1, train 21/100, loss=1.6921 acc=0.3067\n",
      "epoch 1, train 22/100, loss=1.6541 acc=0.2933\n",
      "epoch 1, train 23/100, loss=1.8779 acc=0.2000\n",
      "epoch 1, train 24/100, loss=1.8148 acc=0.2933\n",
      "epoch 1, train 25/100, loss=1.5960 acc=0.2800\n",
      "epoch 1, train 26/100, loss=1.6121 acc=0.2667\n",
      "epoch 1, train 27/100, loss=1.5945 acc=0.3600\n",
      "epoch 1, train 28/100, loss=1.5725 acc=0.2400\n",
      "epoch 1, train 29/100, loss=1.6239 acc=0.1733\n",
      "epoch 1, train 30/100, loss=1.5109 acc=0.4000\n",
      "epoch 1, train 31/100, loss=1.5817 acc=0.3333\n",
      "epoch 1, train 32/100, loss=1.5753 acc=0.2933\n",
      "epoch 1, train 33/100, loss=1.5254 acc=0.4267\n",
      "epoch 1, train 34/100, loss=1.5439 acc=0.3600\n",
      "epoch 1, train 35/100, loss=1.6010 acc=0.2667\n",
      "epoch 1, train 36/100, loss=1.6185 acc=0.2400\n",
      "epoch 1, train 37/100, loss=1.4031 acc=0.5467\n",
      "epoch 1, train 38/100, loss=1.6033 acc=0.2667\n",
      "epoch 1, train 39/100, loss=1.5728 acc=0.2533\n",
      "epoch 1, train 40/100, loss=1.3809 acc=0.4267\n",
      "epoch 1, train 41/100, loss=1.5007 acc=0.3600\n",
      "epoch 1, train 42/100, loss=1.6404 acc=0.2267\n",
      "epoch 1, train 43/100, loss=1.5830 acc=0.3200\n",
      "epoch 1, train 44/100, loss=1.4879 acc=0.2533\n",
      "epoch 1, train 45/100, loss=1.4596 acc=0.4000\n",
      "epoch 1, train 46/100, loss=1.6415 acc=0.2267\n",
      "epoch 1, train 47/100, loss=1.6774 acc=0.3333\n",
      "epoch 1, train 48/100, loss=1.5241 acc=0.3867\n",
      "epoch 1, train 49/100, loss=1.5789 acc=0.3333\n",
      "epoch 1, train 50/100, loss=1.5326 acc=0.3733\n",
      "epoch 1, train 51/100, loss=1.5569 acc=0.3467\n",
      "epoch 1, train 52/100, loss=1.5420 acc=0.3333\n",
      "epoch 1, train 53/100, loss=1.4965 acc=0.3467\n",
      "epoch 1, train 54/100, loss=1.4312 acc=0.4933\n",
      "epoch 1, train 55/100, loss=1.5962 acc=0.2133\n",
      "epoch 1, train 56/100, loss=1.5327 acc=0.3467\n",
      "epoch 1, train 57/100, loss=1.3186 acc=0.4133\n",
      "epoch 1, train 58/100, loss=1.6447 acc=0.2800\n",
      "epoch 1, train 59/100, loss=1.5973 acc=0.1733\n",
      "epoch 1, train 60/100, loss=1.3466 acc=0.3200\n",
      "epoch 1, train 61/100, loss=1.5607 acc=0.3333\n",
      "epoch 1, train 62/100, loss=1.5849 acc=0.2267\n",
      "epoch 1, train 63/100, loss=1.5841 acc=0.3200\n",
      "epoch 1, train 64/100, loss=1.5916 acc=0.1733\n",
      "epoch 1, train 65/100, loss=1.2856 acc=0.4667\n",
      "epoch 1, train 66/100, loss=1.6491 acc=0.2667\n",
      "epoch 1, train 67/100, loss=1.4317 acc=0.4533\n",
      "epoch 1, train 68/100, loss=1.4838 acc=0.3733\n",
      "epoch 1, train 69/100, loss=1.2719 acc=0.4133\n",
      "epoch 1, train 70/100, loss=1.5856 acc=0.3333\n",
      "epoch 1, train 71/100, loss=1.6979 acc=0.4667\n",
      "epoch 1, train 72/100, loss=1.3647 acc=0.5200\n",
      "epoch 1, train 73/100, loss=1.4500 acc=0.3867\n",
      "epoch 1, train 74/100, loss=1.5306 acc=0.4133\n",
      "epoch 1, train 75/100, loss=1.5642 acc=0.2933\n",
      "epoch 1, train 76/100, loss=1.5401 acc=0.3200\n",
      "epoch 1, train 77/100, loss=1.5165 acc=0.3200\n",
      "epoch 1, train 78/100, loss=1.5016 acc=0.2933\n",
      "epoch 1, train 79/100, loss=1.4561 acc=0.4400\n",
      "epoch 1, train 80/100, loss=1.5653 acc=0.3467\n",
      "epoch 1, train 81/100, loss=1.5316 acc=0.3333\n",
      "epoch 1, train 82/100, loss=1.4548 acc=0.4267\n",
      "epoch 1, train 83/100, loss=1.6081 acc=0.2667\n",
      "epoch 1, train 84/100, loss=1.4175 acc=0.5067\n",
      "epoch 1, train 85/100, loss=1.5849 acc=0.2400\n",
      "epoch 1, train 86/100, loss=1.5817 acc=0.3333\n",
      "epoch 1, train 87/100, loss=1.4750 acc=0.3467\n",
      "epoch 1, train 88/100, loss=1.5450 acc=0.2667\n",
      "epoch 1, train 89/100, loss=1.3864 acc=0.5067\n",
      "epoch 1, train 90/100, loss=1.3781 acc=0.4533\n",
      "epoch 1, train 91/100, loss=1.6814 acc=0.2133\n",
      "epoch 1, train 92/100, loss=1.6333 acc=0.3600\n",
      "epoch 1, train 93/100, loss=1.5649 acc=0.3467\n",
      "epoch 1, train 94/100, loss=1.6599 acc=0.2800\n",
      "epoch 1, train 95/100, loss=1.7634 acc=0.3200\n",
      "epoch 1, train 96/100, loss=1.5376 acc=0.2933\n",
      "epoch 1, train 97/100, loss=1.5216 acc=0.3867\n",
      "epoch 1, train 98/100, loss=1.5777 acc=0.2533\n",
      "epoch 1, train 99/100, loss=1.6039 acc=0.2667\n",
      "epoch 1, train 100/100, loss=1.4760 acc=0.3333\n",
      "best epoch 0, best val acc=0.0000\n",
      "epoch 1, val, loss=1.5010 acc=0.3446\n",
      "ETA:6m/58m\n",
      "epoch 2, train 1/100, loss=1.5369 acc=0.3333\n",
      "epoch 2, train 2/100, loss=1.4271 acc=0.4133\n",
      "epoch 2, train 3/100, loss=1.5447 acc=0.2800\n",
      "epoch 2, train 4/100, loss=1.6580 acc=0.2400\n",
      "epoch 2, train 5/100, loss=1.3507 acc=0.2933\n",
      "epoch 2, train 6/100, loss=1.5191 acc=0.4000\n",
      "epoch 2, train 7/100, loss=1.5142 acc=0.3067\n",
      "epoch 2, train 8/100, loss=1.3210 acc=0.5067\n",
      "epoch 2, train 9/100, loss=1.5702 acc=0.2800\n",
      "epoch 2, train 10/100, loss=1.6608 acc=0.3467\n",
      "epoch 2, train 11/100, loss=1.5227 acc=0.2667\n",
      "epoch 2, train 12/100, loss=1.2996 acc=0.4133\n",
      "epoch 2, train 13/100, loss=1.3346 acc=0.4533\n",
      "epoch 2, train 14/100, loss=1.4209 acc=0.3200\n",
      "epoch 2, train 15/100, loss=1.4780 acc=0.3467\n",
      "epoch 2, train 16/100, loss=1.5199 acc=0.3333\n",
      "epoch 2, train 17/100, loss=1.4869 acc=0.3067\n",
      "epoch 2, train 18/100, loss=1.5794 acc=0.2267\n",
      "epoch 2, train 19/100, loss=1.3933 acc=0.4133\n",
      "epoch 2, train 20/100, loss=1.5572 acc=0.3067\n",
      "epoch 2, train 21/100, loss=1.5184 acc=0.3467\n",
      "epoch 2, train 22/100, loss=1.4665 acc=0.3733\n",
      "epoch 2, train 23/100, loss=1.6902 acc=0.1467\n",
      "epoch 2, train 24/100, loss=1.4202 acc=0.3067\n",
      "epoch 2, train 25/100, loss=1.5079 acc=0.3333\n",
      "epoch 2, train 26/100, loss=1.3768 acc=0.4667\n",
      "epoch 2, train 27/100, loss=1.6633 acc=0.2933\n",
      "epoch 2, train 28/100, loss=1.5961 acc=0.2400\n",
      "epoch 2, train 29/100, loss=1.5942 acc=0.2533\n",
      "epoch 2, train 30/100, loss=1.6227 acc=0.2400\n",
      "epoch 2, train 31/100, loss=1.4051 acc=0.3333\n",
      "epoch 2, train 32/100, loss=1.3551 acc=0.3600\n",
      "epoch 2, train 33/100, loss=1.5066 acc=0.3600\n",
      "epoch 2, train 34/100, loss=1.4564 acc=0.4133\n",
      "epoch 2, train 35/100, loss=1.4307 acc=0.3200\n",
      "epoch 2, train 36/100, loss=1.5962 acc=0.2667\n",
      "epoch 2, train 37/100, loss=1.4282 acc=0.3333\n",
      "epoch 2, train 38/100, loss=1.6563 acc=0.2267\n",
      "epoch 2, train 39/100, loss=1.3745 acc=0.4667\n",
      "epoch 2, train 40/100, loss=1.2526 acc=0.4533\n",
      "epoch 2, train 41/100, loss=1.5602 acc=0.2400\n",
      "epoch 2, train 42/100, loss=1.6529 acc=0.2133\n",
      "epoch 2, train 43/100, loss=1.5131 acc=0.4000\n",
      "epoch 2, train 44/100, loss=1.2361 acc=0.4533\n",
      "epoch 2, train 45/100, loss=1.3471 acc=0.3733\n",
      "epoch 2, train 46/100, loss=1.3146 acc=0.4533\n",
      "epoch 2, train 47/100, loss=1.5769 acc=0.2267\n",
      "epoch 2, train 48/100, loss=1.5704 acc=0.2533\n",
      "epoch 2, train 49/100, loss=1.5908 acc=0.2400\n",
      "epoch 2, train 50/100, loss=1.3921 acc=0.3467\n",
      "epoch 2, train 51/100, loss=1.4666 acc=0.4533\n",
      "epoch 2, train 52/100, loss=1.5199 acc=0.3867\n",
      "epoch 2, train 53/100, loss=1.6853 acc=0.2400\n",
      "epoch 2, train 54/100, loss=1.5517 acc=0.3067\n",
      "epoch 2, train 55/100, loss=1.5421 acc=0.3200\n",
      "epoch 2, train 56/100, loss=1.3694 acc=0.4133\n",
      "epoch 2, train 57/100, loss=1.5163 acc=0.3467\n",
      "epoch 2, train 58/100, loss=1.3879 acc=0.3733\n",
      "epoch 2, train 59/100, loss=1.1603 acc=0.6000\n",
      "epoch 2, train 60/100, loss=1.4476 acc=0.4533\n",
      "epoch 2, train 61/100, loss=1.3312 acc=0.3733\n",
      "epoch 2, train 62/100, loss=2.6396 acc=0.4133\n",
      "epoch 2, train 63/100, loss=1.4745 acc=0.4000\n",
      "epoch 2, train 64/100, loss=1.4385 acc=0.4133\n",
      "epoch 2, train 65/100, loss=1.6010 acc=0.2133\n",
      "epoch 2, train 66/100, loss=1.3121 acc=0.5067\n",
      "epoch 2, train 67/100, loss=1.3982 acc=0.4533\n",
      "epoch 2, train 68/100, loss=1.5698 acc=0.2133\n",
      "epoch 2, train 69/100, loss=1.3103 acc=0.4400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train 70/100, loss=1.5203 acc=0.3067\n",
      "epoch 2, train 71/100, loss=1.4762 acc=0.4133\n",
      "epoch 2, train 72/100, loss=1.4294 acc=0.3200\n",
      "epoch 2, train 73/100, loss=1.4927 acc=0.4133\n",
      "epoch 2, train 74/100, loss=1.4251 acc=0.4267\n",
      "epoch 2, train 75/100, loss=1.4655 acc=0.3600\n",
      "epoch 2, train 76/100, loss=1.4623 acc=0.4133\n",
      "epoch 2, train 77/100, loss=1.4770 acc=0.4267\n",
      "epoch 2, train 78/100, loss=1.6985 acc=0.1333\n",
      "epoch 2, train 79/100, loss=1.7936 acc=0.2133\n",
      "epoch 2, train 80/100, loss=1.2769 acc=0.4800\n",
      "epoch 2, train 81/100, loss=1.3999 acc=0.3733\n",
      "epoch 2, train 82/100, loss=1.6329 acc=0.2267\n",
      "epoch 2, train 83/100, loss=1.7516 acc=0.2267\n",
      "epoch 2, train 84/100, loss=1.3775 acc=0.4400\n",
      "epoch 2, train 85/100, loss=1.6626 acc=0.2533\n",
      "epoch 2, train 86/100, loss=1.1644 acc=0.5333\n",
      "epoch 2, train 87/100, loss=1.5334 acc=0.2933\n",
      "epoch 2, train 88/100, loss=1.2915 acc=0.3733\n",
      "epoch 2, train 89/100, loss=1.5758 acc=0.2000\n",
      "epoch 2, train 90/100, loss=1.5864 acc=0.2400\n",
      "epoch 2, train 91/100, loss=1.4501 acc=0.3867\n",
      "epoch 2, train 92/100, loss=1.6140 acc=0.2533\n",
      "epoch 2, train 93/100, loss=1.3982 acc=0.4000\n",
      "epoch 2, train 94/100, loss=1.7402 acc=0.2267\n",
      "epoch 2, train 95/100, loss=1.4649 acc=0.3733\n",
      "epoch 2, train 96/100, loss=1.2928 acc=0.3600\n",
      "epoch 2, train 97/100, loss=1.2710 acc=0.4667\n",
      "epoch 2, train 98/100, loss=1.5332 acc=0.2800\n",
      "epoch 2, train 99/100, loss=1.4282 acc=0.3733\n",
      "epoch 2, train 100/100, loss=1.4623 acc=0.3067\n",
      "best epoch 1, best val acc=0.3446\n",
      "epoch 2, val, loss=1.4477 acc=0.3632\n",
      "ETA:12m/58m\n",
      "epoch 3, train 1/100, loss=1.5838 acc=0.2667\n",
      "epoch 3, train 2/100, loss=1.3285 acc=0.4533\n",
      "epoch 3, train 3/100, loss=1.2403 acc=0.6267\n",
      "epoch 3, train 4/100, loss=1.3215 acc=0.4667\n",
      "epoch 3, train 5/100, loss=1.5827 acc=0.2400\n",
      "epoch 3, train 6/100, loss=1.4588 acc=0.3733\n",
      "epoch 3, train 7/100, loss=1.4762 acc=0.3733\n",
      "epoch 3, train 8/100, loss=1.5647 acc=0.3467\n",
      "epoch 3, train 9/100, loss=1.2456 acc=0.4800\n",
      "epoch 3, train 10/100, loss=1.5364 acc=0.5067\n",
      "epoch 3, train 11/100, loss=1.3540 acc=0.4800\n",
      "epoch 3, train 12/100, loss=1.3802 acc=0.3733\n",
      "epoch 3, train 13/100, loss=1.4970 acc=0.2933\n",
      "epoch 3, train 14/100, loss=1.6986 acc=0.2133\n",
      "epoch 3, train 15/100, loss=1.1878 acc=0.5867\n",
      "epoch 3, train 16/100, loss=1.5909 acc=0.2533\n",
      "epoch 3, train 17/100, loss=1.1953 acc=0.5333\n",
      "epoch 3, train 18/100, loss=1.4189 acc=0.3600\n",
      "epoch 3, train 19/100, loss=1.2894 acc=0.5067\n",
      "epoch 3, train 20/100, loss=1.5685 acc=0.2933\n",
      "epoch 3, train 21/100, loss=1.7515 acc=0.2933\n",
      "epoch 3, train 22/100, loss=1.2366 acc=0.4667\n",
      "epoch 3, train 23/100, loss=1.5261 acc=0.2667\n",
      "epoch 3, train 24/100, loss=1.2872 acc=0.5333\n",
      "epoch 3, train 25/100, loss=1.3742 acc=0.4533\n",
      "epoch 3, train 26/100, loss=1.5000 acc=0.3333\n",
      "epoch 3, train 27/100, loss=1.5703 acc=0.2933\n",
      "epoch 3, train 28/100, loss=1.4426 acc=0.5467\n",
      "epoch 3, train 29/100, loss=1.3412 acc=0.5200\n",
      "epoch 3, train 30/100, loss=1.5226 acc=0.3600\n",
      "epoch 3, train 31/100, loss=1.5040 acc=0.3333\n",
      "epoch 3, train 32/100, loss=1.3313 acc=0.4533\n",
      "epoch 3, train 33/100, loss=1.5172 acc=0.3600\n",
      "epoch 3, train 34/100, loss=1.5677 acc=0.2933\n",
      "epoch 3, train 35/100, loss=1.4514 acc=0.3467\n",
      "epoch 3, train 36/100, loss=1.6284 acc=0.3467\n",
      "epoch 3, train 37/100, loss=1.5291 acc=0.4000\n",
      "epoch 3, train 38/100, loss=1.4144 acc=0.3600\n",
      "epoch 3, train 39/100, loss=1.1790 acc=0.6133\n",
      "epoch 3, train 40/100, loss=1.2927 acc=0.4133\n",
      "epoch 3, train 41/100, loss=1.4424 acc=0.4000\n",
      "epoch 3, train 42/100, loss=1.6614 acc=0.2800\n",
      "epoch 3, train 43/100, loss=1.4166 acc=0.4133\n",
      "epoch 3, train 44/100, loss=1.4586 acc=0.3600\n",
      "epoch 3, train 45/100, loss=1.3310 acc=0.3200\n",
      "epoch 3, train 46/100, loss=1.4931 acc=0.4533\n",
      "epoch 3, train 47/100, loss=1.3206 acc=0.4000\n",
      "epoch 3, train 48/100, loss=1.3535 acc=0.4667\n",
      "epoch 3, train 49/100, loss=1.1361 acc=0.5600\n",
      "epoch 3, train 50/100, loss=1.6057 acc=0.3067\n",
      "epoch 3, train 51/100, loss=1.5192 acc=0.3467\n",
      "epoch 3, train 52/100, loss=1.5655 acc=0.2667\n",
      "epoch 3, train 53/100, loss=1.4847 acc=0.4133\n",
      "epoch 3, train 54/100, loss=1.2992 acc=0.4533\n",
      "epoch 3, train 55/100, loss=1.6165 acc=0.3067\n",
      "epoch 3, train 56/100, loss=1.2827 acc=0.4933\n",
      "epoch 3, train 57/100, loss=1.1893 acc=0.5067\n",
      "epoch 3, train 58/100, loss=1.6522 acc=0.2533\n",
      "epoch 3, train 59/100, loss=1.3607 acc=0.3467\n",
      "epoch 3, train 60/100, loss=1.4321 acc=0.2800\n",
      "epoch 3, train 61/100, loss=1.2546 acc=0.4933\n",
      "epoch 3, train 62/100, loss=1.4335 acc=0.3333\n",
      "epoch 3, train 63/100, loss=1.4629 acc=0.3067\n",
      "epoch 3, train 64/100, loss=1.1410 acc=0.5200\n",
      "epoch 3, train 65/100, loss=1.2526 acc=0.5333\n",
      "epoch 3, train 66/100, loss=1.3470 acc=0.4000\n",
      "epoch 3, train 67/100, loss=1.7060 acc=0.3600\n",
      "epoch 3, train 68/100, loss=1.2061 acc=0.4800\n",
      "epoch 3, train 69/100, loss=1.2252 acc=0.3867\n",
      "epoch 3, train 70/100, loss=1.1209 acc=0.4267\n",
      "epoch 3, train 71/100, loss=1.9112 acc=0.2267\n",
      "epoch 3, train 72/100, loss=1.4375 acc=0.4267\n",
      "epoch 3, train 73/100, loss=1.3872 acc=0.4400\n",
      "epoch 3, train 74/100, loss=1.3628 acc=0.4133\n",
      "epoch 3, train 75/100, loss=1.1382 acc=0.5600\n",
      "epoch 3, train 76/100, loss=1.5408 acc=0.3600\n",
      "epoch 3, train 77/100, loss=1.4734 acc=0.2800\n",
      "epoch 3, train 78/100, loss=1.6770 acc=0.1600\n",
      "epoch 3, train 79/100, loss=1.4472 acc=0.3867\n",
      "epoch 3, train 80/100, loss=1.5298 acc=0.2800\n",
      "epoch 3, train 81/100, loss=1.2813 acc=0.4800\n",
      "epoch 3, train 82/100, loss=1.3252 acc=0.4533\n",
      "epoch 3, train 83/100, loss=1.3984 acc=0.4267\n",
      "epoch 3, train 84/100, loss=1.2250 acc=0.5867\n",
      "epoch 3, train 85/100, loss=1.6006 acc=0.2533\n",
      "epoch 3, train 86/100, loss=1.4250 acc=0.4133\n",
      "epoch 3, train 87/100, loss=1.0324 acc=0.6933\n",
      "epoch 3, train 88/100, loss=1.4323 acc=0.4000\n",
      "epoch 3, train 89/100, loss=1.3933 acc=0.4800\n",
      "epoch 3, train 90/100, loss=1.1647 acc=0.4667\n",
      "epoch 3, train 91/100, loss=1.6777 acc=0.2800\n",
      "epoch 3, train 92/100, loss=1.4431 acc=0.4400\n",
      "epoch 3, train 93/100, loss=1.0815 acc=0.5200\n",
      "epoch 3, train 94/100, loss=1.5649 acc=0.2933\n",
      "epoch 3, train 95/100, loss=1.5116 acc=0.3333\n",
      "epoch 3, train 96/100, loss=1.4721 acc=0.4000\n",
      "epoch 3, train 97/100, loss=1.5820 acc=0.2533\n",
      "epoch 3, train 98/100, loss=1.4172 acc=0.4800\n",
      "epoch 3, train 99/100, loss=1.7255 acc=0.2667\n",
      "epoch 3, train 100/100, loss=1.4342 acc=0.3067\n",
      "best epoch 2, best val acc=0.3632\n",
      "epoch 3, val, loss=1.4377 acc=0.3883\n",
      "ETA:17m/58m\n",
      "epoch 4, train 1/100, loss=1.6196 acc=0.2400\n",
      "epoch 4, train 2/100, loss=1.4728 acc=0.2933\n",
      "epoch 4, train 3/100, loss=1.4924 acc=0.3600\n",
      "epoch 4, train 4/100, loss=1.5021 acc=0.2933\n",
      "epoch 4, train 5/100, loss=1.0295 acc=0.6400\n",
      "epoch 4, train 6/100, loss=1.4186 acc=0.3733\n",
      "epoch 4, train 7/100, loss=1.3828 acc=0.5333\n",
      "epoch 4, train 8/100, loss=1.2358 acc=0.5067\n",
      "epoch 4, train 9/100, loss=1.7208 acc=0.4133\n",
      "epoch 4, train 10/100, loss=1.7044 acc=0.3333\n",
      "epoch 4, train 11/100, loss=1.1471 acc=0.4800\n",
      "epoch 4, train 12/100, loss=1.1899 acc=0.5200\n",
      "epoch 4, train 13/100, loss=1.6156 acc=0.1867\n",
      "epoch 4, train 14/100, loss=1.3866 acc=0.4533\n",
      "epoch 4, train 15/100, loss=1.3142 acc=0.4000\n",
      "epoch 4, train 16/100, loss=1.1008 acc=0.4800\n",
      "epoch 4, train 17/100, loss=1.4120 acc=0.3733\n",
      "epoch 4, train 18/100, loss=1.2443 acc=0.4000\n",
      "epoch 4, train 19/100, loss=1.5858 acc=0.2800\n",
      "epoch 4, train 20/100, loss=1.5320 acc=0.2400\n",
      "epoch 4, train 21/100, loss=1.3704 acc=0.3867\n",
      "epoch 4, train 22/100, loss=1.1196 acc=0.5333\n",
      "epoch 4, train 23/100, loss=1.2334 acc=0.5333\n",
      "epoch 4, train 24/100, loss=1.2483 acc=0.5067\n",
      "epoch 4, train 25/100, loss=1.3395 acc=0.3867\n",
      "epoch 4, train 26/100, loss=1.3118 acc=0.4933\n",
      "epoch 4, train 27/100, loss=1.5272 acc=0.3467\n",
      "epoch 4, train 28/100, loss=1.2526 acc=0.5600\n",
      "epoch 4, train 29/100, loss=1.4685 acc=0.2800\n",
      "epoch 4, train 30/100, loss=1.6532 acc=0.2267\n",
      "epoch 4, train 31/100, loss=1.1672 acc=0.4533\n",
      "epoch 4, train 32/100, loss=1.3941 acc=0.4133\n",
      "epoch 4, train 33/100, loss=1.3284 acc=0.5067\n",
      "epoch 4, train 34/100, loss=1.4580 acc=0.3333\n",
      "epoch 4, train 35/100, loss=1.3705 acc=0.3733\n",
      "epoch 4, train 36/100, loss=1.2518 acc=0.4933\n",
      "epoch 4, train 37/100, loss=1.3518 acc=0.4000\n",
      "epoch 4, train 38/100, loss=1.5254 acc=0.3467\n",
      "epoch 4, train 39/100, loss=1.3671 acc=0.4933\n",
      "epoch 4, train 40/100, loss=1.3815 acc=0.3200\n",
      "epoch 4, train 41/100, loss=1.3051 acc=0.4267\n",
      "epoch 4, train 42/100, loss=1.4753 acc=0.4400\n",
      "epoch 4, train 43/100, loss=1.3500 acc=0.4133\n",
      "epoch 4, train 44/100, loss=1.2681 acc=0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train 45/100, loss=1.3462 acc=0.3600\n",
      "epoch 4, train 46/100, loss=1.4098 acc=0.3333\n",
      "epoch 4, train 47/100, loss=1.4956 acc=0.3600\n",
      "epoch 4, train 48/100, loss=1.3181 acc=0.5600\n",
      "epoch 4, train 49/100, loss=1.5175 acc=0.3600\n",
      "epoch 4, train 50/100, loss=1.4883 acc=0.3600\n",
      "epoch 4, train 51/100, loss=1.4757 acc=0.2800\n",
      "epoch 4, train 52/100, loss=1.5108 acc=0.3067\n",
      "epoch 4, train 53/100, loss=1.4915 acc=0.3333\n",
      "epoch 4, train 54/100, loss=1.5796 acc=0.2933\n",
      "epoch 4, train 55/100, loss=1.6569 acc=0.2000\n",
      "epoch 4, train 56/100, loss=1.3581 acc=0.4933\n",
      "epoch 4, train 57/100, loss=1.6117 acc=0.1867\n",
      "epoch 4, train 58/100, loss=1.6973 acc=0.2000\n",
      "epoch 4, train 59/100, loss=1.4393 acc=0.3333\n",
      "epoch 4, train 60/100, loss=1.4555 acc=0.3200\n",
      "epoch 4, train 61/100, loss=1.5074 acc=0.2933\n",
      "epoch 4, train 62/100, loss=1.3522 acc=0.5067\n",
      "epoch 4, train 63/100, loss=1.7331 acc=0.2267\n",
      "epoch 4, train 64/100, loss=1.5225 acc=0.3867\n",
      "epoch 4, train 65/100, loss=1.2617 acc=0.4533\n",
      "epoch 4, train 66/100, loss=1.6773 acc=0.1867\n",
      "epoch 4, train 67/100, loss=1.4224 acc=0.3467\n",
      "epoch 4, train 68/100, loss=1.4950 acc=0.3333\n",
      "epoch 4, train 69/100, loss=1.2703 acc=0.5467\n",
      "epoch 4, train 70/100, loss=1.5034 acc=0.3467\n",
      "epoch 4, train 71/100, loss=1.6191 acc=0.2400\n",
      "epoch 4, train 72/100, loss=1.6693 acc=0.1867\n",
      "epoch 4, train 73/100, loss=1.6356 acc=0.3467\n",
      "epoch 4, train 74/100, loss=1.4837 acc=0.3333\n",
      "epoch 4, train 75/100, loss=1.4762 acc=0.2800\n",
      "epoch 4, train 76/100, loss=1.5040 acc=0.3333\n",
      "epoch 4, train 77/100, loss=1.4929 acc=0.3200\n",
      "epoch 4, train 78/100, loss=1.5816 acc=0.3333\n",
      "epoch 4, train 79/100, loss=1.4912 acc=0.3467\n",
      "epoch 4, train 80/100, loss=1.3531 acc=0.4400\n",
      "epoch 4, train 81/100, loss=1.3814 acc=0.4133\n",
      "epoch 4, train 82/100, loss=1.2861 acc=0.4267\n",
      "epoch 4, train 83/100, loss=1.6603 acc=0.2267\n",
      "epoch 4, train 84/100, loss=1.2964 acc=0.4800\n",
      "epoch 4, train 85/100, loss=1.3843 acc=0.3733\n",
      "epoch 4, train 86/100, loss=1.2669 acc=0.5600\n",
      "epoch 4, train 87/100, loss=1.6124 acc=0.2133\n",
      "epoch 4, train 88/100, loss=1.5507 acc=0.2533\n",
      "epoch 4, train 89/100, loss=1.6411 acc=0.2667\n",
      "epoch 4, train 90/100, loss=1.4116 acc=0.4267\n",
      "epoch 4, train 91/100, loss=1.3093 acc=0.4667\n",
      "epoch 4, train 92/100, loss=1.3790 acc=0.4267\n",
      "epoch 4, train 93/100, loss=1.3729 acc=0.4400\n",
      "epoch 4, train 94/100, loss=1.4193 acc=0.3733\n",
      "epoch 4, train 95/100, loss=1.3012 acc=0.5067\n",
      "epoch 4, train 96/100, loss=1.3627 acc=0.4933\n",
      "epoch 4, train 97/100, loss=1.1175 acc=0.5200\n",
      "epoch 4, train 98/100, loss=1.5924 acc=0.3733\n",
      "epoch 4, train 99/100, loss=1.4710 acc=0.3600\n",
      "epoch 4, train 100/100, loss=1.4348 acc=0.3600\n",
      "best epoch 3, best val acc=0.3883\n",
      "epoch 4, val, loss=1.4022 acc=0.3990\n",
      "ETA:23m/58m\n",
      "epoch 5, train 1/100, loss=1.3407 acc=0.4800\n",
      "epoch 5, train 2/100, loss=1.0938 acc=0.5333\n",
      "epoch 5, train 3/100, loss=1.3581 acc=0.4933\n",
      "epoch 5, train 4/100, loss=1.5974 acc=0.3600\n",
      "epoch 5, train 5/100, loss=1.4389 acc=0.3867\n",
      "epoch 5, train 6/100, loss=1.3689 acc=0.3867\n",
      "epoch 5, train 7/100, loss=1.2174 acc=0.5467\n",
      "epoch 5, train 8/100, loss=1.1642 acc=0.5200\n",
      "epoch 5, train 9/100, loss=1.6332 acc=0.3067\n",
      "epoch 5, train 10/100, loss=1.5087 acc=0.3467\n",
      "epoch 5, train 11/100, loss=1.3138 acc=0.5067\n",
      "epoch 5, train 12/100, loss=1.6381 acc=0.2667\n",
      "epoch 5, train 13/100, loss=1.3354 acc=0.3467\n",
      "epoch 5, train 14/100, loss=1.1578 acc=0.5467\n",
      "epoch 5, train 15/100, loss=1.4981 acc=0.3333\n",
      "epoch 5, train 16/100, loss=1.1370 acc=0.4000\n",
      "epoch 5, train 17/100, loss=1.5025 acc=0.3333\n",
      "epoch 5, train 18/100, loss=1.4752 acc=0.4800\n",
      "epoch 5, train 19/100, loss=1.3818 acc=0.4133\n",
      "epoch 5, train 20/100, loss=1.2323 acc=0.4667\n",
      "epoch 5, train 21/100, loss=1.4431 acc=0.3867\n",
      "epoch 5, train 22/100, loss=1.4677 acc=0.3200\n",
      "epoch 5, train 23/100, loss=1.3787 acc=0.3733\n",
      "epoch 5, train 24/100, loss=1.5926 acc=0.2667\n",
      "epoch 5, train 25/100, loss=1.2938 acc=0.3733\n",
      "epoch 5, train 26/100, loss=1.4235 acc=0.3733\n",
      "epoch 5, train 27/100, loss=1.6183 acc=0.2267\n",
      "epoch 5, train 28/100, loss=1.2328 acc=0.4000\n",
      "epoch 5, train 29/100, loss=1.4728 acc=0.3333\n",
      "epoch 5, train 30/100, loss=1.6012 acc=0.2400\n",
      "epoch 5, train 31/100, loss=1.4659 acc=0.4000\n",
      "epoch 5, train 32/100, loss=1.4687 acc=0.2667\n",
      "epoch 5, train 33/100, loss=1.5264 acc=0.3467\n",
      "epoch 5, train 34/100, loss=1.5139 acc=0.2800\n",
      "epoch 5, train 35/100, loss=1.2363 acc=0.3067\n",
      "epoch 5, train 36/100, loss=1.5407 acc=0.2800\n",
      "epoch 5, train 37/100, loss=1.4790 acc=0.4133\n",
      "epoch 5, train 38/100, loss=1.5668 acc=0.3467\n",
      "epoch 5, train 39/100, loss=1.6237 acc=0.2000\n",
      "epoch 5, train 40/100, loss=1.1661 acc=0.5067\n",
      "epoch 5, train 41/100, loss=1.4294 acc=0.4400\n",
      "epoch 5, train 42/100, loss=1.3607 acc=0.3467\n",
      "epoch 5, train 43/100, loss=1.3596 acc=0.3733\n",
      "epoch 5, train 44/100, loss=1.5195 acc=0.4133\n",
      "epoch 5, train 45/100, loss=1.2421 acc=0.4533\n",
      "epoch 5, train 46/100, loss=1.3724 acc=0.3867\n",
      "epoch 5, train 47/100, loss=1.5374 acc=0.2533\n",
      "epoch 5, train 48/100, loss=1.4412 acc=0.3733\n",
      "epoch 5, train 49/100, loss=1.5049 acc=0.3333\n",
      "epoch 5, train 50/100, loss=1.6748 acc=0.2000\n",
      "epoch 5, train 51/100, loss=1.3334 acc=0.3867\n",
      "epoch 5, train 52/100, loss=1.6754 acc=0.2267\n",
      "epoch 5, train 53/100, loss=1.3421 acc=0.4667\n",
      "epoch 5, train 54/100, loss=1.4367 acc=0.4400\n",
      "epoch 5, train 55/100, loss=1.2590 acc=0.4667\n",
      "epoch 5, train 56/100, loss=1.4965 acc=0.2267\n",
      "epoch 5, train 57/100, loss=1.5074 acc=0.2933\n",
      "epoch 5, train 58/100, loss=1.5450 acc=0.2533\n",
      "epoch 5, train 59/100, loss=1.3631 acc=0.3467\n",
      "epoch 5, train 60/100, loss=1.6788 acc=0.1200\n",
      "epoch 5, train 61/100, loss=1.4351 acc=0.4000\n",
      "epoch 5, train 62/100, loss=1.1616 acc=0.4400\n",
      "epoch 5, train 63/100, loss=1.4544 acc=0.4133\n",
      "epoch 5, train 64/100, loss=1.4278 acc=0.4533\n",
      "epoch 5, train 65/100, loss=1.5072 acc=0.2533\n",
      "epoch 5, train 66/100, loss=1.3887 acc=0.3867\n",
      "epoch 5, train 67/100, loss=1.6179 acc=0.3200\n",
      "epoch 5, train 68/100, loss=1.3074 acc=0.4400\n",
      "epoch 5, train 69/100, loss=1.3252 acc=0.4267\n",
      "epoch 5, train 70/100, loss=1.4996 acc=0.3600\n",
      "epoch 5, train 71/100, loss=1.4023 acc=0.3733\n",
      "epoch 5, train 72/100, loss=1.3081 acc=0.4400\n",
      "epoch 5, train 73/100, loss=1.4374 acc=0.4000\n",
      "epoch 5, train 74/100, loss=1.5067 acc=0.3200\n",
      "epoch 5, train 75/100, loss=1.3360 acc=0.4000\n",
      "epoch 5, train 76/100, loss=1.3892 acc=0.4133\n",
      "epoch 5, train 77/100, loss=1.5894 acc=0.2133\n",
      "epoch 5, train 78/100, loss=1.3571 acc=0.4667\n",
      "epoch 5, train 79/100, loss=1.4473 acc=0.3733\n",
      "epoch 5, train 80/100, loss=1.4712 acc=0.3600\n",
      "epoch 5, train 81/100, loss=1.5893 acc=0.3600\n",
      "epoch 5, train 82/100, loss=1.6294 acc=0.1333\n",
      "epoch 5, train 83/100, loss=1.3198 acc=0.5200\n",
      "epoch 5, train 84/100, loss=1.3214 acc=0.4400\n",
      "epoch 5, train 85/100, loss=1.4717 acc=0.3733\n",
      "epoch 5, train 86/100, loss=1.2826 acc=0.4400\n",
      "epoch 5, train 87/100, loss=1.4245 acc=0.3333\n",
      "epoch 5, train 88/100, loss=1.5989 acc=0.2533\n",
      "epoch 5, train 89/100, loss=1.4115 acc=0.4133\n",
      "epoch 5, train 90/100, loss=1.2164 acc=0.5200\n",
      "epoch 5, train 91/100, loss=1.3542 acc=0.4000\n",
      "epoch 5, train 92/100, loss=1.0892 acc=0.5867\n",
      "epoch 5, train 93/100, loss=1.4928 acc=0.3333\n",
      "epoch 5, train 94/100, loss=1.1133 acc=0.5600\n",
      "epoch 5, train 95/100, loss=1.0402 acc=0.6533\n",
      "epoch 5, train 96/100, loss=1.5174 acc=0.4000\n",
      "epoch 5, train 97/100, loss=1.5540 acc=0.3333\n",
      "epoch 5, train 98/100, loss=1.3776 acc=0.4400\n",
      "epoch 5, train 99/100, loss=1.4335 acc=0.3600\n",
      "epoch 5, train 100/100, loss=1.3604 acc=0.4667\n",
      "best epoch 4, best val acc=0.3990\n",
      "epoch 5, val, loss=1.3853 acc=0.4169\n",
      "ETA:29m/58m\n",
      "epoch 6, train 1/100, loss=1.5183 acc=0.4400\n",
      "epoch 6, train 2/100, loss=1.2529 acc=0.4933\n",
      "epoch 6, train 3/100, loss=1.5266 acc=0.3600\n",
      "epoch 6, train 4/100, loss=1.1845 acc=0.5333\n",
      "epoch 6, train 5/100, loss=1.1530 acc=0.4267\n",
      "epoch 6, train 6/100, loss=1.1817 acc=0.5467\n",
      "epoch 6, train 7/100, loss=1.3715 acc=0.4000\n",
      "epoch 6, train 8/100, loss=1.4307 acc=0.3733\n",
      "epoch 6, train 9/100, loss=1.2769 acc=0.4267\n",
      "epoch 6, train 10/100, loss=1.3333 acc=0.4667\n",
      "epoch 6, train 11/100, loss=1.3630 acc=0.3867\n",
      "epoch 6, train 12/100, loss=1.2909 acc=0.5333\n",
      "epoch 6, train 13/100, loss=1.4815 acc=0.3600\n",
      "epoch 6, train 14/100, loss=1.6404 acc=0.2533\n",
      "epoch 6, train 15/100, loss=1.4483 acc=0.3333\n",
      "epoch 6, train 16/100, loss=1.4367 acc=0.3333\n",
      "epoch 6, train 17/100, loss=1.5083 acc=0.4133\n",
      "epoch 6, train 18/100, loss=1.4197 acc=0.3333\n",
      "epoch 6, train 19/100, loss=1.4687 acc=0.3867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train 20/100, loss=1.4405 acc=0.4267\n",
      "epoch 6, train 21/100, loss=1.4266 acc=0.3333\n",
      "epoch 6, train 22/100, loss=1.3117 acc=0.5067\n",
      "epoch 6, train 23/100, loss=1.1023 acc=0.6133\n",
      "epoch 6, train 24/100, loss=1.2457 acc=0.5200\n",
      "epoch 6, train 25/100, loss=1.8192 acc=0.3467\n",
      "epoch 6, train 26/100, loss=1.4048 acc=0.4267\n",
      "epoch 6, train 27/100, loss=1.5432 acc=0.4000\n",
      "epoch 6, train 28/100, loss=1.4859 acc=0.3600\n",
      "epoch 6, train 29/100, loss=1.0083 acc=0.7067\n",
      "epoch 6, train 30/100, loss=1.5750 acc=0.2267\n",
      "epoch 6, train 31/100, loss=1.2871 acc=0.4533\n",
      "epoch 6, train 32/100, loss=1.1615 acc=0.4933\n",
      "epoch 6, train 33/100, loss=1.4674 acc=0.3733\n",
      "epoch 6, train 34/100, loss=1.2979 acc=0.4667\n",
      "epoch 6, train 35/100, loss=1.3461 acc=0.3867\n",
      "epoch 6, train 36/100, loss=1.4141 acc=0.5200\n",
      "epoch 6, train 37/100, loss=1.5071 acc=0.2533\n",
      "epoch 6, train 38/100, loss=1.1942 acc=0.4400\n",
      "epoch 6, train 39/100, loss=1.3034 acc=0.4533\n",
      "epoch 6, train 40/100, loss=1.3902 acc=0.4933\n",
      "epoch 6, train 41/100, loss=1.1595 acc=0.4800\n",
      "epoch 6, train 42/100, loss=1.6718 acc=0.1600\n",
      "epoch 6, train 43/100, loss=1.1617 acc=0.5333\n",
      "epoch 6, train 44/100, loss=1.6285 acc=0.2400\n",
      "epoch 6, train 45/100, loss=1.3438 acc=0.3333\n",
      "epoch 6, train 46/100, loss=1.5271 acc=0.2667\n",
      "epoch 6, train 47/100, loss=1.0468 acc=0.5467\n",
      "epoch 6, train 48/100, loss=1.3775 acc=0.3600\n",
      "epoch 6, train 49/100, loss=1.4908 acc=0.3867\n",
      "epoch 6, train 50/100, loss=1.1572 acc=0.6133\n",
      "epoch 6, train 51/100, loss=1.4885 acc=0.3867\n",
      "epoch 6, train 52/100, loss=1.3088 acc=0.4133\n",
      "epoch 6, train 53/100, loss=1.0735 acc=0.6667\n",
      "epoch 6, train 54/100, loss=1.0425 acc=0.6533\n",
      "epoch 6, train 55/100, loss=0.8921 acc=0.6667\n",
      "epoch 6, train 56/100, loss=1.4688 acc=0.3200\n",
      "epoch 6, train 57/100, loss=1.6143 acc=0.2267\n",
      "epoch 6, train 58/100, loss=1.2098 acc=0.4267\n",
      "epoch 6, train 59/100, loss=1.3936 acc=0.3600\n",
      "epoch 6, train 60/100, loss=1.3791 acc=0.4667\n",
      "epoch 6, train 61/100, loss=1.5596 acc=0.2400\n",
      "epoch 6, train 62/100, loss=1.0732 acc=0.5200\n",
      "epoch 6, train 63/100, loss=1.2744 acc=0.4133\n",
      "epoch 6, train 64/100, loss=1.1370 acc=0.6667\n",
      "epoch 6, train 65/100, loss=1.4936 acc=0.2933\n",
      "epoch 6, train 66/100, loss=0.9431 acc=0.7200\n",
      "epoch 6, train 67/100, loss=1.1150 acc=0.6933\n",
      "epoch 6, train 68/100, loss=1.3164 acc=0.5333\n",
      "epoch 6, train 69/100, loss=1.1795 acc=0.4800\n",
      "epoch 6, train 70/100, loss=1.6039 acc=0.2533\n",
      "epoch 6, train 71/100, loss=1.4851 acc=0.3733\n",
      "epoch 6, train 72/100, loss=1.2299 acc=0.5067\n",
      "epoch 6, train 73/100, loss=1.5246 acc=0.3467\n",
      "epoch 6, train 74/100, loss=1.5237 acc=0.3200\n",
      "epoch 6, train 75/100, loss=1.2487 acc=0.5467\n",
      "epoch 6, train 76/100, loss=1.5199 acc=0.3733\n",
      "epoch 6, train 77/100, loss=1.2014 acc=0.4000\n",
      "epoch 6, train 78/100, loss=0.9744 acc=0.5733\n",
      "epoch 6, train 79/100, loss=1.3841 acc=0.4667\n",
      "epoch 6, train 80/100, loss=1.5508 acc=0.3467\n",
      "epoch 6, train 81/100, loss=1.5079 acc=0.3333\n",
      "epoch 6, train 82/100, loss=1.4156 acc=0.4000\n",
      "epoch 6, train 83/100, loss=1.1283 acc=0.5200\n",
      "epoch 6, train 84/100, loss=1.5280 acc=0.4133\n",
      "epoch 6, train 85/100, loss=1.3474 acc=0.3867\n",
      "epoch 6, train 86/100, loss=1.2148 acc=0.4267\n",
      "epoch 6, train 87/100, loss=1.4437 acc=0.4000\n",
      "epoch 6, train 88/100, loss=1.3124 acc=0.4667\n",
      "epoch 6, train 89/100, loss=1.1888 acc=0.4933\n",
      "epoch 6, train 90/100, loss=1.3550 acc=0.3467\n",
      "epoch 6, train 91/100, loss=1.3199 acc=0.4267\n",
      "epoch 6, train 92/100, loss=1.4647 acc=0.3467\n",
      "epoch 6, train 93/100, loss=1.6470 acc=0.1867\n",
      "epoch 6, train 94/100, loss=1.4538 acc=0.3867\n",
      "epoch 6, train 95/100, loss=1.4371 acc=0.4533\n",
      "epoch 6, train 96/100, loss=0.9554 acc=0.6533\n",
      "epoch 6, train 97/100, loss=1.6207 acc=0.2400\n",
      "epoch 6, train 98/100, loss=1.1494 acc=0.6000\n",
      "epoch 6, train 99/100, loss=1.4514 acc=0.3733\n",
      "epoch 6, train 100/100, loss=1.1170 acc=0.5333\n",
      "best epoch 5, best val acc=0.4169\n",
      "epoch 6, val, loss=1.3588 acc=0.4207\n",
      "ETA:34m/58m\n",
      "epoch 7, train 1/100, loss=1.2971 acc=0.5467\n",
      "epoch 7, train 2/100, loss=1.3291 acc=0.4800\n",
      "epoch 7, train 3/100, loss=1.2569 acc=0.5200\n",
      "epoch 7, train 4/100, loss=1.2791 acc=0.4000\n",
      "epoch 7, train 5/100, loss=1.2973 acc=0.4800\n",
      "epoch 7, train 6/100, loss=1.4913 acc=0.3867\n",
      "epoch 7, train 7/100, loss=1.6886 acc=0.1867\n",
      "epoch 7, train 8/100, loss=1.4253 acc=0.3600\n",
      "epoch 7, train 9/100, loss=1.4589 acc=0.2667\n",
      "epoch 7, train 10/100, loss=1.5068 acc=0.3867\n",
      "epoch 7, train 11/100, loss=0.9899 acc=0.5467\n",
      "epoch 7, train 12/100, loss=1.2406 acc=0.5333\n",
      "epoch 7, train 13/100, loss=1.0571 acc=0.5733\n",
      "epoch 7, train 14/100, loss=1.1410 acc=0.5467\n",
      "epoch 7, train 15/100, loss=1.4789 acc=0.4000\n",
      "epoch 7, train 16/100, loss=1.5568 acc=0.2800\n",
      "epoch 7, train 17/100, loss=1.5165 acc=0.2933\n",
      "epoch 7, train 18/100, loss=1.5587 acc=0.2400\n",
      "epoch 7, train 19/100, loss=1.2670 acc=0.4933\n",
      "epoch 7, train 20/100, loss=1.4248 acc=0.3867\n",
      "epoch 7, train 21/100, loss=1.4783 acc=0.3600\n",
      "epoch 7, train 22/100, loss=1.4864 acc=0.3333\n",
      "epoch 7, train 23/100, loss=1.4077 acc=0.4667\n",
      "epoch 7, train 24/100, loss=1.6503 acc=0.2000\n",
      "epoch 7, train 25/100, loss=1.3103 acc=0.3200\n",
      "epoch 7, train 26/100, loss=1.2204 acc=0.5867\n",
      "epoch 7, train 27/100, loss=1.3690 acc=0.4133\n",
      "epoch 7, train 28/100, loss=1.2269 acc=0.5600\n",
      "epoch 7, train 29/100, loss=1.2714 acc=0.5733\n",
      "epoch 7, train 30/100, loss=1.5432 acc=0.3867\n",
      "epoch 7, train 31/100, loss=1.2871 acc=0.3333\n",
      "epoch 7, train 32/100, loss=1.0774 acc=0.6933\n",
      "epoch 7, train 33/100, loss=1.6780 acc=0.1467\n",
      "epoch 7, train 34/100, loss=1.0813 acc=0.6533\n",
      "epoch 7, train 35/100, loss=1.4806 acc=0.3867\n",
      "epoch 7, train 36/100, loss=1.4784 acc=0.4533\n",
      "epoch 7, train 37/100, loss=1.3805 acc=0.3333\n",
      "epoch 7, train 38/100, loss=1.3309 acc=0.4400\n",
      "epoch 7, train 39/100, loss=1.7026 acc=0.2400\n",
      "epoch 7, train 40/100, loss=1.4842 acc=0.3733\n",
      "epoch 7, train 41/100, loss=1.2627 acc=0.5467\n",
      "epoch 7, train 42/100, loss=1.5649 acc=0.2800\n",
      "epoch 7, train 43/100, loss=1.7332 acc=0.4000\n",
      "epoch 7, train 44/100, loss=1.5005 acc=0.3867\n",
      "epoch 7, train 45/100, loss=1.4214 acc=0.3733\n",
      "epoch 7, train 46/100, loss=1.9359 acc=0.3600\n",
      "epoch 7, train 47/100, loss=1.3268 acc=0.4533\n",
      "epoch 7, train 48/100, loss=1.5141 acc=0.3333\n",
      "epoch 7, train 49/100, loss=1.5772 acc=0.1467\n",
      "epoch 7, train 50/100, loss=1.5157 acc=0.3467\n",
      "epoch 7, train 51/100, loss=1.2929 acc=0.6133\n",
      "epoch 7, train 52/100, loss=1.3631 acc=0.4400\n",
      "epoch 7, train 53/100, loss=1.2977 acc=0.4533\n",
      "epoch 7, train 54/100, loss=1.2320 acc=0.5200\n",
      "epoch 7, train 55/100, loss=1.5771 acc=0.2267\n",
      "epoch 7, train 56/100, loss=1.5179 acc=0.4133\n",
      "epoch 7, train 57/100, loss=1.4896 acc=0.2800\n",
      "epoch 7, train 58/100, loss=1.3515 acc=0.4400\n",
      "epoch 7, train 59/100, loss=1.2841 acc=0.4933\n",
      "epoch 7, train 60/100, loss=1.4146 acc=0.4000\n",
      "epoch 7, train 61/100, loss=1.3015 acc=0.3200\n",
      "epoch 7, train 62/100, loss=1.2934 acc=0.5067\n",
      "epoch 7, train 63/100, loss=1.3752 acc=0.3333\n",
      "epoch 7, train 64/100, loss=1.5601 acc=0.3867\n",
      "epoch 7, train 65/100, loss=1.1717 acc=0.4000\n",
      "epoch 7, train 66/100, loss=1.4434 acc=0.4133\n",
      "epoch 7, train 67/100, loss=1.1830 acc=0.4400\n",
      "epoch 7, train 68/100, loss=1.1373 acc=0.6133\n",
      "epoch 7, train 69/100, loss=1.5652 acc=0.3467\n",
      "epoch 7, train 70/100, loss=1.4279 acc=0.4800\n",
      "epoch 7, train 71/100, loss=1.5445 acc=0.2667\n",
      "epoch 7, train 72/100, loss=1.2703 acc=0.5200\n",
      "epoch 7, train 73/100, loss=1.4742 acc=0.3200\n",
      "epoch 7, train 74/100, loss=1.2111 acc=0.4000\n",
      "epoch 7, train 75/100, loss=1.5142 acc=0.1600\n",
      "epoch 7, train 76/100, loss=1.5005 acc=0.4267\n",
      "epoch 7, train 77/100, loss=1.4932 acc=0.3600\n",
      "epoch 7, train 78/100, loss=1.4732 acc=0.4800\n",
      "epoch 7, train 79/100, loss=1.5409 acc=0.2933\n",
      "epoch 7, train 80/100, loss=1.3517 acc=0.4000\n",
      "epoch 7, train 81/100, loss=1.1346 acc=0.6133\n",
      "epoch 7, train 82/100, loss=1.6292 acc=0.2267\n",
      "epoch 7, train 83/100, loss=1.4432 acc=0.3867\n",
      "epoch 7, train 84/100, loss=1.5865 acc=0.2800\n",
      "epoch 7, train 85/100, loss=1.1467 acc=0.5467\n",
      "epoch 7, train 86/100, loss=1.3834 acc=0.4533\n",
      "epoch 7, train 87/100, loss=1.0886 acc=0.5867\n",
      "epoch 7, train 88/100, loss=1.2289 acc=0.4933\n",
      "epoch 7, train 89/100, loss=1.6356 acc=0.2933\n",
      "epoch 7, train 90/100, loss=0.9920 acc=0.5600\n",
      "epoch 7, train 91/100, loss=1.1599 acc=0.4933\n",
      "epoch 7, train 92/100, loss=1.3527 acc=0.4400\n",
      "epoch 7, train 93/100, loss=1.0661 acc=0.7200\n",
      "epoch 7, train 94/100, loss=1.6094 acc=0.2667\n",
      "epoch 7, train 95/100, loss=1.1206 acc=0.5600\n",
      "epoch 7, train 96/100, loss=1.3417 acc=0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train 97/100, loss=1.4651 acc=0.4133\n",
      "epoch 7, train 98/100, loss=1.2137 acc=0.4533\n",
      "epoch 7, train 99/100, loss=1.3480 acc=0.3200\n",
      "epoch 7, train 100/100, loss=1.2584 acc=0.4533\n",
      "best epoch 6, best val acc=0.4207\n",
      "epoch 7, val, loss=1.3442 acc=0.4304\n",
      "ETA:40m/58m\n",
      "epoch 8, train 1/100, loss=1.5650 acc=0.2667\n",
      "epoch 8, train 2/100, loss=1.4770 acc=0.3600\n",
      "epoch 8, train 3/100, loss=1.4077 acc=0.4800\n",
      "epoch 8, train 4/100, loss=1.6552 acc=0.2667\n",
      "epoch 8, train 5/100, loss=1.3635 acc=0.4800\n",
      "epoch 8, train 6/100, loss=0.8490 acc=0.7333\n",
      "epoch 8, train 7/100, loss=1.1542 acc=0.6400\n",
      "epoch 8, train 8/100, loss=1.3793 acc=0.5067\n",
      "epoch 8, train 9/100, loss=1.4084 acc=0.3333\n",
      "epoch 8, train 10/100, loss=1.2953 acc=0.4933\n",
      "epoch 8, train 11/100, loss=1.3436 acc=0.4133\n",
      "epoch 8, train 12/100, loss=1.1306 acc=0.5733\n",
      "epoch 8, train 13/100, loss=1.5316 acc=0.3467\n",
      "epoch 8, train 14/100, loss=1.3535 acc=0.3867\n",
      "epoch 8, train 15/100, loss=1.6842 acc=0.2400\n",
      "epoch 8, train 16/100, loss=1.6200 acc=0.2267\n",
      "epoch 8, train 17/100, loss=0.9436 acc=0.5600\n",
      "epoch 8, train 18/100, loss=1.3656 acc=0.4400\n",
      "epoch 8, train 19/100, loss=1.5554 acc=0.2667\n",
      "epoch 8, train 20/100, loss=1.1991 acc=0.5200\n",
      "epoch 8, train 21/100, loss=2.0039 acc=0.1600\n",
      "epoch 8, train 22/100, loss=1.5994 acc=0.3200\n",
      "epoch 8, train 23/100, loss=1.1447 acc=0.6000\n",
      "epoch 8, train 24/100, loss=1.3100 acc=0.4400\n",
      "epoch 8, train 25/100, loss=1.1999 acc=0.5333\n",
      "epoch 8, train 26/100, loss=0.9639 acc=0.6400\n",
      "epoch 8, train 27/100, loss=1.2915 acc=0.4667\n",
      "epoch 8, train 28/100, loss=1.5654 acc=0.3467\n",
      "epoch 8, train 29/100, loss=1.2718 acc=0.5200\n",
      "epoch 8, train 30/100, loss=1.3502 acc=0.4000\n",
      "epoch 8, train 31/100, loss=1.2625 acc=0.3867\n",
      "epoch 8, train 32/100, loss=1.5061 acc=0.3867\n",
      "epoch 8, train 33/100, loss=1.6774 acc=0.1733\n",
      "epoch 8, train 34/100, loss=1.1817 acc=0.5067\n",
      "epoch 8, train 35/100, loss=1.6400 acc=0.2267\n",
      "epoch 8, train 36/100, loss=1.3923 acc=0.5067\n",
      "epoch 8, train 37/100, loss=1.6500 acc=0.4000\n",
      "epoch 8, train 38/100, loss=1.3053 acc=0.5733\n",
      "epoch 8, train 39/100, loss=1.2503 acc=0.4800\n",
      "epoch 8, train 40/100, loss=1.4276 acc=0.3733\n",
      "epoch 8, train 41/100, loss=1.1521 acc=0.5600\n",
      "epoch 8, train 42/100, loss=1.4378 acc=0.4267\n",
      "epoch 8, train 43/100, loss=1.4408 acc=0.3200\n",
      "epoch 8, train 44/100, loss=1.6822 acc=0.2133\n",
      "epoch 8, train 45/100, loss=1.2590 acc=0.4667\n",
      "epoch 8, train 46/100, loss=0.9967 acc=0.5867\n",
      "epoch 8, train 47/100, loss=1.4867 acc=0.4933\n",
      "epoch 8, train 48/100, loss=1.7099 acc=0.3200\n",
      "epoch 8, train 49/100, loss=1.4194 acc=0.3867\n",
      "epoch 8, train 50/100, loss=1.4949 acc=0.3600\n",
      "epoch 8, train 51/100, loss=1.3699 acc=0.4400\n",
      "epoch 8, train 52/100, loss=1.3758 acc=0.3333\n",
      "epoch 8, train 53/100, loss=1.4543 acc=0.3733\n",
      "epoch 8, train 54/100, loss=1.2224 acc=0.7067\n",
      "epoch 8, train 55/100, loss=1.4821 acc=0.4000\n",
      "epoch 8, train 56/100, loss=1.0929 acc=0.5200\n",
      "epoch 8, train 57/100, loss=1.2261 acc=0.5067\n",
      "epoch 8, train 58/100, loss=1.3760 acc=0.4667\n",
      "epoch 8, train 59/100, loss=1.2401 acc=0.5200\n",
      "epoch 8, train 60/100, loss=1.3579 acc=0.4133\n",
      "epoch 8, train 61/100, loss=1.7001 acc=0.2533\n",
      "epoch 8, train 62/100, loss=1.3210 acc=0.4800\n",
      "epoch 8, train 63/100, loss=1.4521 acc=0.4400\n",
      "epoch 8, train 64/100, loss=1.5691 acc=0.3200\n",
      "epoch 8, train 65/100, loss=1.3917 acc=0.3333\n",
      "epoch 8, train 66/100, loss=1.5189 acc=0.4000\n",
      "epoch 8, train 67/100, loss=1.2810 acc=0.4000\n",
      "epoch 8, train 68/100, loss=1.4731 acc=0.4267\n",
      "epoch 8, train 69/100, loss=1.4093 acc=0.2933\n",
      "epoch 8, train 70/100, loss=1.4291 acc=0.2933\n",
      "epoch 8, train 71/100, loss=1.4783 acc=0.4133\n",
      "epoch 8, train 72/100, loss=1.4346 acc=0.3867\n",
      "epoch 8, train 73/100, loss=1.3883 acc=0.4400\n",
      "epoch 8, train 74/100, loss=1.1230 acc=0.5600\n",
      "epoch 8, train 75/100, loss=1.5330 acc=0.4000\n",
      "epoch 8, train 76/100, loss=1.4575 acc=0.2533\n",
      "epoch 8, train 77/100, loss=1.2428 acc=0.5467\n",
      "epoch 8, train 78/100, loss=1.1152 acc=0.5467\n",
      "epoch 8, train 79/100, loss=1.2945 acc=0.4533\n",
      "epoch 8, train 80/100, loss=1.5402 acc=0.2133\n",
      "epoch 8, train 81/100, loss=1.2452 acc=0.4800\n",
      "epoch 8, train 82/100, loss=1.3912 acc=0.3600\n",
      "epoch 8, train 83/100, loss=1.3023 acc=0.4133\n",
      "epoch 8, train 84/100, loss=1.2479 acc=0.4933\n",
      "epoch 8, train 85/100, loss=1.5521 acc=0.4533\n",
      "epoch 8, train 86/100, loss=1.0975 acc=0.4933\n",
      "epoch 8, train 87/100, loss=1.6808 acc=0.2267\n",
      "epoch 8, train 88/100, loss=1.4051 acc=0.3733\n",
      "epoch 8, train 89/100, loss=0.9836 acc=0.6933\n",
      "epoch 8, train 90/100, loss=1.0181 acc=0.5733\n",
      "epoch 8, train 91/100, loss=1.5046 acc=0.3600\n",
      "epoch 8, train 92/100, loss=1.1398 acc=0.4400\n",
      "epoch 8, train 93/100, loss=1.0790 acc=0.6400\n",
      "epoch 8, train 94/100, loss=0.7222 acc=0.7733\n",
      "epoch 8, train 95/100, loss=1.4937 acc=0.2933\n",
      "epoch 8, train 96/100, loss=1.6628 acc=0.2000\n",
      "epoch 8, train 97/100, loss=1.6020 acc=0.3467\n",
      "epoch 8, train 98/100, loss=1.1298 acc=0.5333\n",
      "epoch 8, train 99/100, loss=1.6467 acc=0.2000\n",
      "epoch 8, train 100/100, loss=1.7114 acc=0.3067\n",
      "best epoch 7, best val acc=0.4304\n",
      "epoch 8, val, loss=1.4303 acc=0.4282\n",
      "ETA:46m/58m\n",
      "epoch 9, train 1/100, loss=1.5786 acc=0.2933\n",
      "epoch 9, train 2/100, loss=1.2720 acc=0.4400\n",
      "epoch 9, train 3/100, loss=1.4485 acc=0.3333\n",
      "epoch 9, train 4/100, loss=1.1742 acc=0.5067\n",
      "epoch 9, train 5/100, loss=1.3043 acc=0.4400\n",
      "epoch 9, train 6/100, loss=1.5029 acc=0.3067\n",
      "epoch 9, train 7/100, loss=1.4453 acc=0.4267\n",
      "epoch 9, train 8/100, loss=1.3261 acc=0.3333\n",
      "epoch 9, train 9/100, loss=1.4320 acc=0.4533\n",
      "epoch 9, train 10/100, loss=1.2175 acc=0.4000\n",
      "epoch 9, train 11/100, loss=1.3946 acc=0.5333\n",
      "epoch 9, train 12/100, loss=1.0036 acc=0.5733\n",
      "epoch 9, train 13/100, loss=1.1973 acc=0.4800\n",
      "epoch 9, train 14/100, loss=1.2691 acc=0.4267\n",
      "epoch 9, train 15/100, loss=1.4986 acc=0.5867\n",
      "epoch 9, train 16/100, loss=1.2871 acc=0.3600\n",
      "epoch 9, train 17/100, loss=1.4140 acc=0.4933\n",
      "epoch 9, train 18/100, loss=1.0634 acc=0.5600\n",
      "epoch 9, train 19/100, loss=0.7954 acc=0.7200\n",
      "epoch 9, train 20/100, loss=1.2211 acc=0.4533\n",
      "epoch 9, train 21/100, loss=1.0126 acc=0.4933\n",
      "epoch 9, train 22/100, loss=1.1909 acc=0.5333\n",
      "epoch 9, train 23/100, loss=1.6349 acc=0.3333\n",
      "epoch 9, train 24/100, loss=1.5345 acc=0.4267\n",
      "epoch 9, train 25/100, loss=1.2781 acc=0.4533\n",
      "epoch 9, train 26/100, loss=1.3706 acc=0.5733\n",
      "epoch 9, train 27/100, loss=1.1370 acc=0.6267\n",
      "epoch 9, train 28/100, loss=1.3758 acc=0.4533\n",
      "epoch 9, train 29/100, loss=1.0679 acc=0.6000\n",
      "epoch 9, train 30/100, loss=1.2650 acc=0.4933\n",
      "epoch 9, train 31/100, loss=1.4719 acc=0.4000\n",
      "epoch 9, train 32/100, loss=1.0205 acc=0.6133\n",
      "epoch 9, train 33/100, loss=1.1099 acc=0.5867\n",
      "epoch 9, train 34/100, loss=1.2148 acc=0.4400\n",
      "epoch 9, train 35/100, loss=1.3021 acc=0.4533\n",
      "epoch 9, train 36/100, loss=1.2428 acc=0.5467\n",
      "epoch 9, train 37/100, loss=1.4801 acc=0.3067\n",
      "epoch 9, train 38/100, loss=1.1934 acc=0.4800\n",
      "epoch 9, train 39/100, loss=1.3948 acc=0.4400\n",
      "epoch 9, train 40/100, loss=1.3838 acc=0.4267\n",
      "epoch 9, train 41/100, loss=1.3794 acc=0.4400\n",
      "epoch 9, train 42/100, loss=1.5202 acc=0.3867\n",
      "epoch 9, train 43/100, loss=1.3415 acc=0.4267\n",
      "epoch 9, train 44/100, loss=1.3186 acc=0.5333\n",
      "epoch 9, train 45/100, loss=1.2786 acc=0.4000\n",
      "epoch 9, train 46/100, loss=1.4706 acc=0.5067\n",
      "epoch 9, train 47/100, loss=1.4127 acc=0.3867\n",
      "epoch 9, train 48/100, loss=1.4891 acc=0.4000\n",
      "epoch 9, train 49/100, loss=1.2130 acc=0.4800\n",
      "epoch 9, train 50/100, loss=1.3089 acc=0.4400\n",
      "epoch 9, train 51/100, loss=1.6483 acc=0.4000\n",
      "epoch 9, train 52/100, loss=1.4748 acc=0.2800\n",
      "epoch 9, train 53/100, loss=1.2354 acc=0.4933\n",
      "epoch 9, train 54/100, loss=1.3431 acc=0.4533\n",
      "epoch 9, train 55/100, loss=1.2877 acc=0.4000\n",
      "epoch 9, train 56/100, loss=1.3005 acc=0.3600\n",
      "epoch 9, train 57/100, loss=1.1751 acc=0.6400\n",
      "epoch 9, train 58/100, loss=1.5873 acc=0.2267\n",
      "epoch 9, train 59/100, loss=1.4930 acc=0.3467\n",
      "epoch 9, train 60/100, loss=1.0761 acc=0.4800\n",
      "epoch 9, train 61/100, loss=0.9523 acc=0.6667\n",
      "epoch 9, train 62/100, loss=1.1015 acc=0.5067\n",
      "epoch 9, train 63/100, loss=1.2328 acc=0.4267\n",
      "epoch 9, train 64/100, loss=1.6803 acc=0.2000\n",
      "epoch 9, train 65/100, loss=1.5139 acc=0.3067\n",
      "epoch 9, train 66/100, loss=1.5704 acc=0.2000\n",
      "epoch 9, train 67/100, loss=1.1653 acc=0.5867\n",
      "epoch 9, train 68/100, loss=1.4507 acc=0.3600\n",
      "epoch 9, train 69/100, loss=1.3781 acc=0.3733\n",
      "epoch 9, train 70/100, loss=1.4457 acc=0.4000\n",
      "epoch 9, train 71/100, loss=1.0691 acc=0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train 72/100, loss=1.4416 acc=0.4133\n",
      "epoch 9, train 73/100, loss=1.2881 acc=0.4000\n",
      "epoch 9, train 74/100, loss=1.6549 acc=0.2133\n",
      "epoch 9, train 75/100, loss=1.4893 acc=0.3067\n",
      "epoch 9, train 76/100, loss=1.3363 acc=0.3467\n",
      "epoch 9, train 77/100, loss=1.3794 acc=0.4400\n",
      "epoch 9, train 78/100, loss=1.0154 acc=0.6400\n",
      "epoch 9, train 79/100, loss=1.6094 acc=0.2133\n",
      "epoch 9, train 80/100, loss=1.5711 acc=0.4000\n",
      "epoch 9, train 81/100, loss=1.6024 acc=0.2933\n",
      "epoch 9, train 82/100, loss=1.5967 acc=0.3333\n",
      "epoch 9, train 83/100, loss=1.6006 acc=0.2533\n",
      "epoch 9, train 84/100, loss=1.3542 acc=0.2800\n",
      "epoch 9, train 85/100, loss=1.5732 acc=0.3067\n",
      "epoch 9, train 86/100, loss=1.4659 acc=0.3333\n",
      "epoch 9, train 87/100, loss=1.2298 acc=0.4933\n",
      "epoch 9, train 88/100, loss=1.0836 acc=0.6267\n",
      "epoch 9, train 89/100, loss=1.5451 acc=0.3467\n",
      "epoch 9, train 90/100, loss=1.1422 acc=0.6000\n",
      "epoch 9, train 91/100, loss=1.4897 acc=0.3600\n",
      "epoch 9, train 92/100, loss=1.2563 acc=0.4400\n",
      "epoch 9, train 93/100, loss=1.4360 acc=0.3733\n",
      "epoch 9, train 94/100, loss=1.3229 acc=0.4800\n",
      "epoch 9, train 95/100, loss=1.2151 acc=0.4133\n",
      "epoch 9, train 96/100, loss=1.4177 acc=0.4400\n",
      "epoch 9, train 97/100, loss=1.2373 acc=0.5467\n",
      "epoch 9, train 98/100, loss=1.8504 acc=0.2000\n",
      "epoch 9, train 99/100, loss=1.2903 acc=0.6000\n",
      "epoch 9, train 100/100, loss=1.2963 acc=0.4533\n",
      "best epoch 7, best val acc=0.4304\n",
      "epoch 9, val, loss=1.3294 acc=0.4375\n",
      "ETA:52m/58m\n",
      "epoch 10, train 1/100, loss=1.5108 acc=0.3333\n",
      "epoch 10, train 2/100, loss=1.3555 acc=0.4800\n",
      "epoch 10, train 3/100, loss=1.5598 acc=0.2000\n",
      "epoch 10, train 4/100, loss=1.3687 acc=0.4533\n",
      "epoch 10, train 5/100, loss=1.3896 acc=0.4533\n",
      "epoch 10, train 6/100, loss=1.2545 acc=0.5600\n",
      "epoch 10, train 7/100, loss=1.4196 acc=0.4400\n",
      "epoch 10, train 8/100, loss=1.2007 acc=0.5333\n",
      "epoch 10, train 9/100, loss=1.4432 acc=0.3867\n",
      "epoch 10, train 10/100, loss=1.5792 acc=0.2533\n",
      "epoch 10, train 11/100, loss=1.4499 acc=0.3467\n",
      "epoch 10, train 12/100, loss=1.6510 acc=0.2667\n",
      "epoch 10, train 13/100, loss=1.5797 acc=0.2933\n",
      "epoch 10, train 14/100, loss=1.2847 acc=0.4400\n",
      "epoch 10, train 15/100, loss=1.4260 acc=0.3600\n",
      "epoch 10, train 16/100, loss=1.5624 acc=0.3200\n",
      "epoch 10, train 17/100, loss=1.2167 acc=0.4000\n",
      "epoch 10, train 18/100, loss=1.2904 acc=0.4400\n",
      "epoch 10, train 19/100, loss=0.9200 acc=0.5867\n",
      "epoch 10, train 20/100, loss=1.1809 acc=0.4933\n",
      "epoch 10, train 21/100, loss=1.1045 acc=0.5867\n",
      "epoch 10, train 22/100, loss=1.3856 acc=0.4533\n",
      "epoch 10, train 23/100, loss=1.1635 acc=0.4533\n",
      "epoch 10, train 24/100, loss=1.2501 acc=0.4933\n",
      "epoch 10, train 25/100, loss=1.4197 acc=0.4133\n",
      "epoch 10, train 26/100, loss=1.2586 acc=0.3867\n",
      "epoch 10, train 27/100, loss=1.3716 acc=0.4533\n",
      "epoch 10, train 28/100, loss=1.3336 acc=0.3200\n",
      "epoch 10, train 29/100, loss=1.0354 acc=0.6267\n",
      "epoch 10, train 30/100, loss=1.0560 acc=0.6667\n",
      "epoch 10, train 31/100, loss=1.1470 acc=0.6000\n",
      "epoch 10, train 32/100, loss=1.3195 acc=0.4400\n",
      "epoch 10, train 33/100, loss=1.2603 acc=0.4533\n",
      "epoch 10, train 34/100, loss=1.0905 acc=0.5733\n",
      "epoch 10, train 35/100, loss=1.4708 acc=0.3200\n",
      "epoch 10, train 36/100, loss=1.3043 acc=0.4133\n",
      "epoch 10, train 37/100, loss=1.4005 acc=0.3867\n",
      "epoch 10, train 38/100, loss=1.2008 acc=0.5200\n",
      "epoch 10, train 39/100, loss=1.0762 acc=0.4800\n",
      "epoch 10, train 40/100, loss=1.2275 acc=0.4667\n",
      "epoch 10, train 41/100, loss=1.1081 acc=0.5600\n",
      "epoch 10, train 42/100, loss=1.2441 acc=0.5600\n",
      "epoch 10, train 43/100, loss=1.4026 acc=0.4133\n",
      "epoch 10, train 44/100, loss=1.4134 acc=0.2933\n",
      "epoch 10, train 45/100, loss=1.5762 acc=0.2933\n",
      "epoch 10, train 46/100, loss=1.0506 acc=0.6267\n",
      "epoch 10, train 47/100, loss=1.2731 acc=0.4133\n",
      "epoch 10, train 48/100, loss=0.9020 acc=0.6533\n",
      "epoch 10, train 49/100, loss=1.5287 acc=0.3333\n",
      "epoch 10, train 50/100, loss=1.3184 acc=0.4533\n",
      "epoch 10, train 51/100, loss=1.4930 acc=0.3200\n",
      "epoch 10, train 52/100, loss=1.0668 acc=0.4800\n",
      "epoch 10, train 53/100, loss=1.4028 acc=0.3467\n",
      "epoch 10, train 54/100, loss=1.1506 acc=0.6533\n",
      "epoch 10, train 55/100, loss=1.7156 acc=0.2133\n",
      "epoch 10, train 56/100, loss=1.1682 acc=0.5333\n",
      "epoch 10, train 57/100, loss=1.1192 acc=0.5333\n",
      "epoch 10, train 58/100, loss=1.0479 acc=0.6400\n",
      "epoch 10, train 59/100, loss=1.3844 acc=0.4667\n",
      "epoch 10, train 60/100, loss=1.0163 acc=0.6267\n",
      "epoch 10, train 61/100, loss=1.4640 acc=0.3600\n",
      "epoch 10, train 62/100, loss=1.4634 acc=0.3600\n",
      "epoch 10, train 63/100, loss=1.0976 acc=0.6800\n",
      "epoch 10, train 64/100, loss=1.4296 acc=0.4133\n",
      "epoch 10, train 65/100, loss=0.9695 acc=0.6267\n",
      "epoch 10, train 66/100, loss=1.2105 acc=0.4933\n",
      "epoch 10, train 67/100, loss=1.2270 acc=0.3467\n",
      "epoch 10, train 68/100, loss=1.5078 acc=0.3467\n",
      "epoch 10, train 69/100, loss=1.1960 acc=0.5600\n",
      "epoch 10, train 70/100, loss=0.8843 acc=0.7067\n",
      "epoch 10, train 71/100, loss=1.4375 acc=0.3600\n",
      "epoch 10, train 72/100, loss=1.5271 acc=0.2667\n",
      "epoch 10, train 73/100, loss=1.7051 acc=0.1733\n",
      "epoch 10, train 74/100, loss=1.3173 acc=0.4133\n",
      "epoch 10, train 75/100, loss=1.8717 acc=0.1600\n",
      "epoch 10, train 76/100, loss=1.6600 acc=0.3200\n",
      "epoch 10, train 77/100, loss=1.2237 acc=0.5867\n",
      "epoch 10, train 78/100, loss=1.3322 acc=0.3467\n",
      "epoch 10, train 79/100, loss=1.0749 acc=0.5200\n",
      "epoch 10, train 80/100, loss=1.7003 acc=0.2133\n",
      "epoch 10, train 81/100, loss=1.1715 acc=0.4800\n",
      "epoch 10, train 82/100, loss=1.4564 acc=0.3467\n",
      "epoch 10, train 83/100, loss=1.4336 acc=0.3733\n",
      "epoch 10, train 84/100, loss=1.3389 acc=0.4933\n",
      "epoch 10, train 85/100, loss=1.5150 acc=0.3067\n",
      "epoch 10, train 86/100, loss=1.3959 acc=0.3600\n",
      "epoch 10, train 87/100, loss=1.3714 acc=0.4267\n",
      "epoch 10, train 88/100, loss=1.3016 acc=0.4400\n",
      "epoch 10, train 89/100, loss=1.2040 acc=0.5067\n",
      "epoch 10, train 90/100, loss=1.4654 acc=0.4133\n",
      "epoch 10, train 91/100, loss=1.7556 acc=0.2667\n",
      "epoch 10, train 92/100, loss=1.4312 acc=0.3733\n",
      "epoch 10, train 93/100, loss=1.1802 acc=0.5200\n",
      "epoch 10, train 94/100, loss=1.3384 acc=0.4800\n",
      "epoch 10, train 95/100, loss=1.5126 acc=0.3467\n",
      "epoch 10, train 96/100, loss=1.6574 acc=0.2533\n",
      "epoch 10, train 97/100, loss=1.4955 acc=0.2933\n",
      "epoch 10, train 98/100, loss=1.4573 acc=0.3600\n",
      "epoch 10, train 99/100, loss=1.5126 acc=0.2400\n",
      "epoch 10, train 100/100, loss=1.0833 acc=0.6667\n",
      "best epoch 9, best val acc=0.4375\n",
      "epoch 10, val, loss=1.3601 acc=0.4461\n",
      "ETA:58m/58m\n",
      "batch 1: 28.00(28.00)\n",
      "batch 2: 30.00(32.00)\n",
      "batch 3: 32.00(36.00)\n",
      "batch 4: 35.33(45.33)\n",
      "batch 5: 34.13(29.33)\n",
      "batch 6: 32.89(26.67)\n",
      "batch 7: 33.14(34.67)\n",
      "batch 8: 34.33(42.67)\n",
      "batch 9: 34.96(40.00)\n",
      "batch 10: 33.60(21.33)\n",
      "batch 11: 34.79(46.67)\n",
      "batch 12: 35.56(44.00)\n",
      "batch 13: 35.90(40.00)\n",
      "batch 14: 35.52(30.67)\n",
      "batch 15: 36.44(49.33)\n",
      "batch 16: 38.08(62.67)\n",
      "batch 17: 38.90(52.00)\n",
      "batch 18: 38.74(36.00)\n",
      "batch 19: 39.86(60.00)\n",
      "batch 20: 38.73(17.33)\n",
      "batch 21: 39.05(45.33)\n",
      "batch 22: 39.58(50.67)\n",
      "batch 23: 39.71(42.67)\n",
      "batch 24: 39.83(42.67)\n",
      "batch 25: 39.68(36.00)\n",
      "batch 26: 39.74(41.33)\n",
      "batch 27: 40.00(46.67)\n",
      "batch 28: 39.95(38.67)\n",
      "batch 29: 39.68(32.00)\n",
      "batch 30: 39.69(40.00)\n",
      "batch 31: 39.01(18.67)\n",
      "batch 32: 39.17(44.00)\n",
      "batch 33: 39.64(54.67)\n",
      "batch 34: 39.37(30.67)\n",
      "batch 35: 38.97(25.33)\n",
      "batch 36: 39.04(41.33)\n",
      "batch 37: 39.03(38.67)\n",
      "batch 38: 39.16(44.00)\n",
      "batch 39: 39.15(38.67)\n",
      "batch 40: 39.17(40.00)\n",
      "batch 41: 39.51(53.33)\n",
      "batch 42: 39.97(58.67)\n",
      "batch 43: 39.78(32.00)\n",
      "batch 44: 40.15(56.00)\n",
      "batch 45: 40.36(49.33)\n",
      "batch 46: 40.64(53.33)\n",
      "batch 47: 40.96(56.00)\n",
      "batch 48: 40.92(38.67)\n",
      "batch 49: 40.65(28.00)\n",
      "batch 50: 40.67(41.33)\n",
      "batch 51: 40.60(37.33)\n",
      "batch 52: 40.56(38.67)\n",
      "batch 53: 40.78(52.00)\n",
      "batch 54: 40.67(34.67)\n",
      "batch 55: 40.70(42.67)\n",
      "batch 56: 40.69(40.00)\n",
      "batch 57: 40.56(33.33)\n",
      "batch 58: 40.62(44.00)\n",
      "batch 59: 40.79(50.67)\n",
      "batch 60: 40.78(40.00)\n",
      "batch 61: 40.66(33.33)\n",
      "batch 62: 40.54(33.33)\n",
      "batch 63: 40.61(45.33)\n",
      "batch 64: 40.58(38.67)\n",
      "batch 65: 40.86(58.67)\n",
      "batch 66: 40.79(36.00)\n",
      "batch 67: 40.84(44.00)\n",
      "batch 68: 41.00(52.00)\n",
      "batch 69: 41.00(41.33)\n",
      "batch 70: 40.99(40.00)\n",
      "batch 71: 41.09(48.00)\n",
      "batch 72: 40.91(28.00)\n",
      "batch 73: 40.66(22.67)\n",
      "batch 74: 40.86(56.00)\n",
      "batch 75: 40.89(42.67)\n",
      "batch 76: 41.00(49.33)\n",
      "batch 77: 40.99(40.00)\n",
      "batch 78: 40.75(22.67)\n",
      "batch 79: 40.93(54.67)\n",
      "batch 80: 40.85(34.67)\n",
      "batch 81: 41.07(58.67)\n",
      "batch 82: 41.17(49.33)\n",
      "batch 83: 41.35(56.00)\n",
      "batch 84: 41.33(40.00)\n",
      "batch 85: 41.63(66.67)\n",
      "batch 86: 41.55(34.67)\n",
      "batch 87: 41.47(34.67)\n",
      "batch 88: 41.38(33.33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 89: 41.59(60.00)\n",
      "batch 90: 41.67(49.33)\n",
      "batch 91: 41.66(40.00)\n",
      "batch 92: 41.58(34.67)\n",
      "batch 93: 41.69(52.00)\n",
      "batch 94: 41.70(42.67)\n",
      "batch 95: 41.81(52.00)\n",
      "batch 96: 41.78(38.67)\n",
      "batch 97: 41.79(42.67)\n",
      "batch 98: 41.73(36.00)\n",
      "batch 99: 41.82(50.67)\n",
      "batch 100: 41.89(49.33)\n",
      "batch 101: 41.93(45.33)\n",
      "batch 102: 41.66(14.67)\n",
      "batch 103: 41.57(32.00)\n",
      "batch 104: 41.44(28.00)\n",
      "batch 105: 41.45(42.67)\n",
      "batch 106: 41.26(21.33)\n",
      "batch 107: 41.18(33.33)\n",
      "batch 108: 40.98(18.67)\n",
      "batch 109: 40.86(28.00)\n",
      "batch 110: 40.84(38.67)\n",
      "batch 111: 40.88(45.33)\n",
      "batch 112: 40.86(38.67)\n",
      "batch 113: 40.92(48.00)\n",
      "batch 114: 40.90(38.67)\n",
      "batch 115: 40.92(42.67)\n",
      "batch 116: 40.84(32.00)\n",
      "batch 117: 40.87(44.00)\n",
      "batch 118: 40.86(40.00)\n",
      "batch 119: 40.78(32.00)\n",
      "batch 120: 40.64(24.00)\n",
      "batch 121: 40.52(25.33)\n",
      "batch 122: 40.54(42.67)\n",
      "batch 123: 40.63(52.00)\n",
      "batch 124: 40.63(41.33)\n",
      "batch 125: 40.65(42.67)\n",
      "batch 126: 40.75(53.33)\n",
      "batch 127: 40.80(46.67)\n",
      "batch 128: 40.89(52.00)\n",
      "batch 129: 40.97(52.00)\n",
      "batch 130: 41.01(45.33)\n",
      "batch 131: 41.05(46.67)\n",
      "batch 132: 41.07(44.00)\n",
      "batch 133: 41.00(32.00)\n",
      "batch 134: 41.00(41.33)\n",
      "batch 135: 41.16(61.33)\n",
      "batch 136: 41.25(54.67)\n",
      "batch 137: 41.28(45.33)\n",
      "batch 138: 41.43(61.33)\n",
      "batch 139: 41.49(49.33)\n",
      "batch 140: 41.57(53.33)\n",
      "batch 141: 41.73(64.00)\n",
      "batch 142: 41.69(36.00)\n",
      "batch 143: 41.66(37.33)\n",
      "batch 144: 41.81(62.67)\n",
      "batch 145: 41.85(48.00)\n",
      "batch 146: 41.78(32.00)\n",
      "batch 147: 41.87(54.67)\n",
      "batch 148: 41.91(48.00)\n",
      "batch 149: 41.88(37.33)\n",
      "batch 150: 41.81(32.00)\n",
      "batch 151: 41.87(50.67)\n",
      "batch 152: 41.80(30.67)\n",
      "batch 153: 41.73(32.00)\n",
      "batch 154: 41.65(28.00)\n",
      "batch 155: 41.56(28.00)\n",
      "batch 156: 41.63(53.33)\n",
      "batch 157: 41.69(50.67)\n",
      "batch 158: 41.67(38.67)\n",
      "batch 159: 41.60(30.67)\n",
      "batch 160: 41.59(40.00)\n",
      "batch 161: 41.55(34.67)\n",
      "batch 162: 41.56(44.00)\n",
      "batch 163: 41.53(36.00)\n",
      "batch 164: 41.53(41.33)\n",
      "batch 165: 41.48(33.33)\n",
      "batch 166: 41.48(41.33)\n",
      "batch 167: 41.37(22.67)\n",
      "batch 168: 41.39(45.33)\n",
      "batch 169: 41.32(29.33)\n",
      "batch 170: 41.30(38.67)\n",
      "batch 171: 41.35(49.33)\n",
      "batch 172: 41.33(37.33)\n",
      "batch 173: 41.20(20.00)\n",
      "batch 174: 41.11(25.33)\n",
      "batch 175: 41.01(22.67)\n",
      "batch 176: 41.05(48.00)\n",
      "batch 177: 41.04(40.00)\n",
      "batch 178: 40.97(28.00)\n",
      "batch 179: 40.98(44.00)\n",
      "batch 180: 40.91(28.00)\n",
      "batch 181: 40.93(44.00)\n",
      "batch 182: 40.93(41.33)\n",
      "batch 183: 40.84(24.00)\n",
      "batch 184: 40.78(29.33)\n",
      "batch 185: 40.86(56.00)\n",
      "batch 186: 40.91(50.67)\n",
      "batch 187: 40.86(30.67)\n",
      "batch 188: 40.83(36.00)\n",
      "batch 189: 40.83(40.00)\n",
      "batch 190: 40.65(6.67)\n",
      "batch 191: 40.73(56.00)\n",
      "batch 192: 40.68(32.00)\n",
      "batch 193: 40.73(49.33)\n",
      "batch 194: 40.62(20.00)\n",
      "batch 195: 40.55(28.00)\n",
      "batch 196: 40.62(53.33)\n",
      "batch 197: 40.54(25.33)\n",
      "batch 198: 40.54(40.00)\n",
      "batch 199: 40.44(21.33)\n",
      "batch 200: 40.38(28.00)\n",
      "batch 201: 40.37(38.67)\n",
      "batch 202: 40.42(49.33)\n",
      "batch 203: 40.45(46.67)\n",
      "batch 204: 40.48(48.00)\n",
      "batch 205: 40.42(28.00)\n",
      "batch 206: 40.40(36.00)\n",
      "batch 207: 40.43(46.67)\n",
      "batch 208: 40.40(34.67)\n",
      "batch 209: 40.42(44.00)\n",
      "batch 210: 40.45(46.67)\n",
      "batch 211: 40.52(54.67)\n",
      "batch 212: 40.46(28.00)\n",
      "batch 213: 40.42(32.00)\n",
      "batch 214: 40.42(41.33)\n",
      "batch 215: 40.47(50.67)\n",
      "batch 216: 40.51(49.33)\n",
      "batch 217: 40.49(34.67)\n",
      "batch 218: 40.59(62.67)\n",
      "batch 219: 40.59(41.33)\n",
      "batch 220: 40.63(49.33)\n",
      "batch 221: 40.72(61.33)\n",
      "batch 222: 40.68(30.67)\n",
      "batch 223: 40.62(26.67)\n",
      "batch 224: 40.55(25.33)\n",
      "batch 225: 40.49(26.67)\n",
      "batch 226: 40.58(62.67)\n",
      "batch 227: 40.62(49.33)\n",
      "batch 228: 40.62(40.00)\n",
      "batch 229: 40.60(36.00)\n",
      "batch 230: 40.66(54.67)\n",
      "batch 231: 40.61(28.00)\n",
      "batch 232: 40.60(40.00)\n",
      "batch 233: 40.65(50.67)\n",
      "batch 234: 40.67(45.33)\n",
      "batch 235: 40.62(29.33)\n",
      "batch 236: 40.56(28.00)\n",
      "batch 237: 40.56(40.00)\n",
      "batch 238: 40.56(40.00)\n",
      "batch 239: 40.60(50.67)\n",
      "batch 240: 40.60(40.00)\n",
      "batch 241: 40.55(28.00)\n",
      "batch 242: 40.55(40.00)\n",
      "batch 243: 40.54(40.00)\n",
      "batch 244: 40.58(49.33)\n",
      "batch 245: 40.58(40.00)\n",
      "batch 246: 40.63(54.67)\n",
      "batch 247: 40.63(38.67)\n",
      "batch 248: 40.55(22.67)\n",
      "batch 249: 40.47(20.00)\n",
      "batch 250: 40.45(36.00)\n",
      "batch 251: 40.46(41.33)\n",
      "batch 252: 40.42(30.67)\n",
      "batch 253: 40.36(26.67)\n",
      "batch 254: 40.41(53.33)\n",
      "batch 255: 40.44(46.67)\n",
      "batch 256: 40.48(52.00)\n",
      "batch 257: 40.49(41.33)\n",
      "batch 258: 40.50(42.67)\n",
      "batch 259: 40.54(52.00)\n",
      "batch 260: 40.53(38.67)\n",
      "batch 261: 40.46(21.33)\n",
      "batch 262: 40.46(41.33)\n",
      "batch 263: 40.47(41.33)\n",
      "batch 264: 40.44(34.67)\n",
      "batch 265: 40.51(57.33)\n",
      "batch 266: 40.50(38.67)\n",
      "batch 267: 40.48(36.00)\n",
      "batch 268: 40.51(46.67)\n",
      "batch 269: 40.47(30.67)\n",
      "batch 270: 40.48(42.67)\n",
      "batch 271: 40.57(64.00)\n",
      "batch 272: 40.63(57.33)\n",
      "batch 273: 40.64(45.33)\n",
      "batch 274: 40.63(36.00)\n",
      "batch 275: 40.63(41.33)\n",
      "batch 276: 40.57(25.33)\n",
      "batch 277: 40.65(62.67)\n",
      "batch 278: 40.67(45.33)\n",
      "batch 279: 40.68(42.67)\n",
      "batch 280: 40.61(21.33)\n",
      "batch 281: 40.54(20.00)\n",
      "batch 282: 40.52(34.67)\n",
      "batch 283: 40.50(37.33)\n",
      "batch 284: 40.44(22.67)\n",
      "batch 285: 40.41(32.00)\n",
      "batch 286: 40.44(49.33)\n",
      "batch 287: 40.42(34.67)\n",
      "batch 288: 40.45(48.00)\n",
      "batch 289: 40.47(45.33)\n",
      "batch 290: 40.46(40.00)\n",
      "batch 291: 40.51(54.67)\n",
      "batch 292: 40.43(16.00)\n",
      "batch 293: 40.35(17.33)\n",
      "batch 294: 40.33(33.33)\n",
      "batch 295: 40.29(30.67)\n",
      "batch 296: 40.27(34.67)\n",
      "batch 297: 40.31(50.67)\n",
      "batch 298: 40.29(33.33)\n",
      "batch 299: 40.31(48.00)\n",
      "batch 300: 40.29(34.67)\n",
      "batch 301: 40.29(40.00)\n",
      "batch 302: 40.32(48.00)\n",
      "batch 303: 40.32(41.33)\n",
      "batch 304: 40.36(53.33)\n",
      "batch 305: 40.36(40.00)\n",
      "batch 306: 40.41(56.00)\n",
      "batch 307: 40.41(40.00)\n",
      "batch 308: 40.39(34.67)\n",
      "batch 309: 40.34(24.00)\n",
      "batch 310: 40.37(48.00)\n",
      "batch 311: 40.37(41.33)\n",
      "batch 312: 40.36(37.33)\n",
      "batch 313: 40.34(34.67)\n",
      "batch 314: 40.32(34.67)\n",
      "batch 315: 40.36(52.00)\n",
      "batch 316: 40.36(40.00)\n",
      "batch 317: 40.29(17.33)\n",
      "batch 318: 40.24(26.67)\n",
      "batch 319: 40.23(34.67)\n",
      "batch 320: 40.24(44.00)\n",
      "batch 321: 40.23(37.33)\n",
      "batch 322: 40.24(45.33)\n",
      "batch 323: 40.24(38.67)\n",
      "batch 324: 40.27(50.67)\n",
      "batch 325: 40.26(37.33)\n",
      "batch 326: 40.18(14.67)\n",
      "batch 327: 40.21(48.00)\n",
      "batch 328: 40.16(25.33)\n",
      "batch 329: 40.19(48.00)\n",
      "batch 330: 40.17(36.00)\n",
      "batch 331: 40.13(25.33)\n",
      "batch 332: 40.06(17.33)\n",
      "batch 333: 40.05(37.33)\n",
      "batch 334: 39.99(18.67)\n",
      "batch 335: 39.99(40.00)\n",
      "batch 336: 40.04(56.00)\n",
      "batch 337: 40.01(32.00)\n",
      "batch 338: 39.98(28.00)\n",
      "batch 339: 39.99(45.33)\n",
      "batch 340: 40.02(49.33)\n",
      "batch 341: 40.05(49.33)\n",
      "batch 342: 40.00(24.00)\n",
      "batch 343: 39.95(24.00)\n",
      "batch 344: 39.90(22.67)\n",
      "batch 345: 39.88(33.33)\n",
      "batch 346: 39.86(30.67)\n",
      "batch 347: 39.88(48.00)\n",
      "batch 348: 39.85(30.67)\n",
      "batch 349: 39.89(50.67)\n",
      "batch 350: 39.89(41.33)\n",
      "batch 351: 39.87(32.00)\n",
      "batch 352: 39.84(29.33)\n",
      "batch 353: 39.83(37.33)\n",
      "batch 354: 39.91(66.67)\n",
      "batch 355: 39.88(30.67)\n",
      "batch 356: 39.89(42.67)\n",
      "batch 357: 39.91(48.00)\n",
      "batch 358: 39.86(22.67)\n",
      "batch 359: 39.88(45.33)\n",
      "batch 360: 39.86(33.33)\n",
      "batch 361: 39.86(41.33)\n",
      "batch 362: 39.82(22.67)\n",
      "batch 363: 39.83(44.00)\n",
      "batch 364: 39.84(44.00)\n",
      "batch 365: 39.89(58.67)\n",
      "batch 366: 39.85(25.33)\n",
      "batch 367: 39.83(32.00)\n",
      "batch 368: 39.83(38.67)\n",
      "batch 369: 39.88(60.00)\n",
      "batch 370: 39.85(28.00)\n",
      "batch 371: 39.78(16.00)\n",
      "batch 372: 39.80(45.33)\n",
      "batch 373: 39.85(60.00)\n",
      "batch 374: 39.85(38.67)\n",
      "batch 375: 39.85(40.00)\n",
      "batch 376: 39.83(32.00)\n",
      "batch 377: 39.83(40.00)\n",
      "batch 378: 39.79(25.33)\n",
      "batch 379: 39.85(60.00)\n",
      "batch 380: 39.86(46.67)\n",
      "batch 381: 39.85(36.00)\n",
      "batch 382: 39.88(52.00)\n",
      "batch 383: 39.88(37.33)\n",
      "batch 384: 39.95(68.00)\n",
      "batch 385: 39.94(34.67)\n",
      "batch 386: 39.96(46.67)\n",
      "batch 387: 39.90(17.33)\n",
      "batch 388: 39.85(21.33)\n",
      "batch 389: 39.85(40.00)\n",
      "batch 390: 39.83(33.33)\n",
      "batch 391: 39.81(29.33)\n",
      "batch 392: 39.79(32.00)\n",
      "batch 393: 39.80(46.67)\n",
      "batch 394: 39.84(56.00)\n",
      "batch 395: 39.87(49.33)\n",
      "batch 396: 39.87(41.33)\n",
      "batch 397: 39.85(30.67)\n",
      "batch 398: 39.79(17.33)\n",
      "batch 399: 39.78(33.33)\n",
      "batch 400: 39.76(34.67)\n",
      "batch 401: 39.76(38.67)\n",
      "batch 402: 39.77(42.67)\n",
      "batch 403: 39.82(62.67)\n",
      "batch 404: 39.84(46.67)\n",
      "batch 405: 39.86(46.67)\n",
      "batch 406: 39.84(32.00)\n",
      "batch 407: 39.83(34.67)\n",
      "batch 408: 39.86(53.33)\n",
      "batch 409: 39.83(29.33)\n",
      "batch 410: 39.87(54.67)\n",
      "batch 411: 39.86(37.33)\n",
      "batch 412: 39.82(21.33)\n",
      "batch 413: 39.78(24.00)\n",
      "batch 414: 39.78(40.00)\n",
      "batch 415: 39.78(40.00)\n",
      "batch 416: 39.77(33.33)\n",
      "batch 417: 39.78(44.00)\n",
      "batch 418: 39.77(37.33)\n",
      "batch 419: 39.76(36.00)\n",
      "batch 420: 39.77(41.33)\n",
      "batch 421: 39.78(45.33)\n",
      "batch 422: 39.74(22.67)\n",
      "batch 423: 39.73(36.00)\n",
      "batch 424: 39.75(50.67)\n",
      "batch 425: 39.76(40.00)\n",
      "batch 426: 39.72(26.67)\n",
      "batch 427: 39.72(37.33)\n",
      "batch 428: 39.72(38.67)\n",
      "batch 429: 39.67(21.33)\n",
      "batch 430: 39.68(42.67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 431: 39.69(44.00)\n",
      "batch 432: 39.69(38.67)\n",
      "batch 433: 39.69(38.67)\n",
      "batch 434: 39.69(42.67)\n",
      "batch 435: 39.73(56.00)\n",
      "batch 436: 39.75(49.33)\n",
      "batch 437: 39.74(36.00)\n",
      "batch 438: 39.74(36.00)\n",
      "batch 439: 39.73(36.00)\n",
      "batch 440: 39.75(49.33)\n",
      "batch 441: 39.81(65.33)\n",
      "batch 442: 39.81(42.67)\n",
      "batch 443: 39.79(29.33)\n",
      "batch 444: 39.77(29.33)\n",
      "batch 445: 39.77(41.33)\n",
      "batch 446: 39.79(49.33)\n",
      "batch 447: 39.80(45.33)\n",
      "batch 448: 39.86(65.33)\n",
      "batch 449: 39.90(60.00)\n",
      "batch 450: 39.92(45.33)\n",
      "batch 451: 39.92(41.33)\n",
      "batch 452: 39.92(38.67)\n",
      "batch 453: 39.94(49.33)\n",
      "batch 454: 39.96(50.67)\n",
      "batch 455: 39.95(34.67)\n",
      "batch 456: 39.98(53.33)\n",
      "batch 457: 39.93(18.67)\n",
      "batch 458: 39.90(24.00)\n",
      "batch 459: 39.90(38.67)\n",
      "batch 460: 39.88(32.00)\n",
      "batch 461: 39.86(33.33)\n",
      "batch 462: 39.88(49.33)\n",
      "batch 463: 39.87(34.67)\n",
      "batch 464: 39.86(36.00)\n",
      "batch 465: 39.89(52.00)\n",
      "batch 466: 39.86(26.67)\n",
      "batch 467: 39.87(42.67)\n",
      "batch 468: 39.87(42.67)\n",
      "batch 469: 39.84(24.00)\n",
      "batch 470: 39.86(46.67)\n",
      "batch 471: 39.81(17.33)\n",
      "batch 472: 39.81(41.33)\n",
      "batch 473: 39.81(41.33)\n",
      "batch 474: 39.84(50.67)\n",
      "batch 475: 39.81(28.00)\n",
      "batch 476: 39.80(32.00)\n",
      "batch 477: 39.80(42.67)\n",
      "batch 478: 39.82(48.00)\n",
      "batch 479: 39.82(42.67)\n",
      "batch 480: 39.80(26.67)\n",
      "batch 481: 39.83(57.33)\n",
      "batch 482: 39.85(48.00)\n",
      "batch 483: 39.84(36.00)\n",
      "batch 484: 39.85(44.00)\n",
      "batch 485: 39.81(20.00)\n",
      "batch 486: 39.83(49.33)\n",
      "batch 487: 39.85(49.33)\n",
      "batch 488: 39.84(37.33)\n",
      "batch 489: 39.83(32.00)\n",
      "batch 490: 39.83(42.67)\n",
      "batch 491: 39.85(48.00)\n",
      "batch 492: 39.87(48.00)\n",
      "batch 493: 39.83(21.33)\n",
      "batch 494: 39.84(42.67)\n",
      "batch 495: 39.80(20.00)\n",
      "batch 496: 39.82(52.00)\n",
      "batch 497: 39.83(46.67)\n",
      "batch 498: 39.85(48.00)\n",
      "batch 499: 39.84(33.33)\n",
      "batch 500: 39.84(41.33)\n",
      "batch 501: 39.87(53.33)\n",
      "batch 502: 39.87(40.00)\n",
      "batch 503: 39.89(49.33)\n",
      "batch 504: 39.86(25.33)\n",
      "batch 505: 39.85(37.33)\n",
      "batch 506: 39.81(17.33)\n",
      "batch 507: 39.81(41.33)\n",
      "batch 508: 39.81(37.33)\n",
      "batch 509: 39.82(45.33)\n",
      "batch 510: 39.78(22.67)\n",
      "batch 511: 39.83(64.00)\n",
      "batch 512: 39.80(25.33)\n",
      "batch 513: 39.80(37.33)\n",
      "batch 514: 39.81(44.00)\n",
      "batch 515: 39.78(28.00)\n",
      "batch 516: 39.78(37.33)\n",
      "batch 517: 39.79(44.00)\n",
      "batch 518: 39.79(41.33)\n",
      "batch 519: 39.78(33.33)\n",
      "batch 520: 39.76(29.33)\n",
      "batch 521: 39.73(25.33)\n",
      "batch 522: 39.72(37.33)\n",
      "batch 523: 39.76(56.00)\n",
      "batch 524: 39.78(53.33)\n",
      "batch 525: 39.77(34.67)\n",
      "batch 526: 39.77(40.00)\n",
      "batch 527: 39.76(34.67)\n",
      "batch 528: 39.77(44.00)\n",
      "batch 529: 39.76(36.00)\n",
      "batch 530: 39.76(40.00)\n",
      "batch 531: 39.78(48.00)\n",
      "batch 532: 39.77(36.00)\n",
      "batch 533: 39.77(37.33)\n",
      "batch 534: 39.82(65.33)\n",
      "batch 535: 39.84(50.67)\n",
      "batch 536: 39.82(29.33)\n",
      "batch 537: 39.81(34.67)\n",
      "batch 538: 39.79(33.33)\n",
      "batch 539: 39.77(29.33)\n",
      "batch 540: 39.76(32.00)\n",
      "batch 541: 39.78(50.67)\n",
      "batch 542: 39.82(60.00)\n",
      "batch 543: 39.85(58.67)\n",
      "batch 544: 39.87(46.67)\n",
      "batch 545: 39.87(42.67)\n",
      "batch 546: 39.89(49.33)\n",
      "batch 547: 39.86(25.33)\n",
      "batch 548: 39.85(33.33)\n",
      "batch 549: 39.84(36.00)\n",
      "batch 550: 39.84(40.00)\n",
      "batch 551: 39.85(44.00)\n",
      "batch 552: 39.85(38.67)\n",
      "batch 553: 39.84(34.67)\n",
      "batch 554: 39.85(44.00)\n",
      "batch 555: 39.84(37.33)\n",
      "batch 556: 39.85(42.67)\n",
      "batch 557: 39.84(36.00)\n",
      "batch 558: 39.84(37.33)\n",
      "batch 559: 39.84(42.67)\n",
      "batch 560: 39.85(42.67)\n",
      "batch 561: 39.84(36.00)\n",
      "batch 562: 39.83(37.33)\n",
      "batch 563: 39.84(42.67)\n",
      "batch 564: 39.87(54.67)\n",
      "batch 565: 39.84(25.33)\n",
      "batch 566: 39.84(41.33)\n",
      "batch 567: 39.83(33.33)\n",
      "batch 568: 39.82(32.00)\n",
      "batch 569: 39.83(46.67)\n",
      "batch 570: 39.86(58.67)\n",
      "batch 571: 39.86(37.33)\n",
      "batch 572: 39.86(38.67)\n",
      "batch 573: 39.87(49.33)\n",
      "batch 574: 39.86(34.67)\n",
      "batch 575: 39.85(33.33)\n",
      "batch 576: 39.85(37.33)\n",
      "batch 577: 39.85(42.67)\n",
      "batch 578: 39.84(33.33)\n",
      "batch 579: 39.83(32.00)\n",
      "batch 580: 39.83(42.67)\n",
      "batch 581: 39.85(52.00)\n",
      "batch 582: 39.86(44.00)\n",
      "batch 583: 39.87(48.00)\n",
      "batch 584: 39.89(50.67)\n",
      "batch 585: 39.89(38.67)\n",
      "batch 586: 39.87(29.33)\n",
      "batch 587: 39.85(25.33)\n",
      "batch 588: 39.83(26.67)\n",
      "batch 589: 39.82(38.67)\n",
      "batch 590: 39.83(41.33)\n",
      "batch 591: 39.85(52.00)\n",
      "batch 592: 39.83(30.67)\n",
      "batch 593: 39.84(45.33)\n",
      "batch 594: 39.88(61.33)\n",
      "batch 595: 39.86(29.33)\n",
      "batch 596: 39.87(44.00)\n",
      "batch 597: 39.86(37.33)\n",
      "batch 598: 39.88(48.00)\n",
      "batch 599: 39.89(50.67)\n",
      "batch 600: 39.90(45.33)\n",
      "batch 601: 39.91(42.67)\n",
      "batch 602: 39.90(33.33)\n",
      "batch 603: 39.89(33.33)\n",
      "batch 604: 39.89(44.00)\n",
      "batch 605: 39.94(68.00)\n",
      "batch 606: 39.96(53.33)\n",
      "batch 607: 39.92(17.33)\n",
      "batch 608: 39.91(29.33)\n",
      "batch 609: 39.90(38.67)\n",
      "batch 610: 39.92(49.33)\n",
      "batch 611: 39.96(62.67)\n",
      "batch 612: 39.95(34.67)\n",
      "batch 613: 39.96(46.67)\n",
      "batch 614: 39.95(32.00)\n",
      "batch 615: 39.94(37.33)\n",
      "batch 616: 39.95(46.67)\n",
      "batch 617: 39.97(50.67)\n",
      "batch 618: 40.00(57.33)\n",
      "batch 619: 39.97(21.33)\n",
      "batch 620: 39.97(40.00)\n",
      "batch 621: 39.94(21.33)\n",
      "batch 622: 39.91(25.33)\n",
      "batch 623: 39.92(41.33)\n",
      "batch 624: 39.91(37.33)\n",
      "batch 625: 39.93(49.33)\n",
      "batch 626: 39.91(32.00)\n",
      "batch 627: 39.92(41.33)\n",
      "batch 628: 39.93(48.00)\n",
      "batch 629: 39.92(32.00)\n",
      "batch 630: 39.93(49.33)\n",
      "batch 631: 39.93(37.33)\n",
      "batch 632: 39.91(25.33)\n",
      "batch 633: 39.90(38.67)\n",
      "batch 634: 39.91(46.67)\n",
      "batch 635: 39.91(34.67)\n",
      "batch 636: 39.89(28.00)\n",
      "batch 637: 39.88(33.33)\n",
      "batch 638: 39.90(52.00)\n",
      "batch 639: 39.87(26.67)\n",
      "batch 640: 39.87(36.00)\n",
      "batch 641: 39.84(22.67)\n",
      "batch 642: 39.86(49.33)\n",
      "batch 643: 39.87(46.67)\n",
      "batch 644: 39.87(44.00)\n",
      "batch 645: 39.84(21.33)\n",
      "batch 646: 39.85(40.00)\n",
      "batch 647: 39.85(45.33)\n",
      "batch 648: 39.89(64.00)\n",
      "batch 649: 39.88(36.00)\n",
      "batch 650: 39.86(24.00)\n",
      "batch 651: 39.83(21.33)\n",
      "batch 652: 39.85(53.33)\n",
      "batch 653: 39.85(38.67)\n",
      "batch 654: 39.85(40.00)\n",
      "batch 655: 39.85(40.00)\n",
      "batch 656: 39.87(50.67)\n",
      "batch 657: 39.86(32.00)\n",
      "batch 658: 39.86(42.67)\n",
      "batch 659: 39.89(57.33)\n",
      "batch 660: 39.90(49.33)\n",
      "batch 661: 39.90(38.67)\n",
      "batch 662: 39.90(37.33)\n",
      "batch 663: 39.89(38.67)\n",
      "batch 664: 39.92(57.33)\n",
      "batch 665: 39.91(33.33)\n",
      "batch 666: 39.92(44.00)\n",
      "batch 667: 39.91(38.67)\n",
      "batch 668: 39.91(36.00)\n",
      "batch 669: 39.90(32.00)\n",
      "batch 670: 39.88(32.00)\n",
      "batch 671: 39.87(32.00)\n",
      "batch 672: 39.88(41.33)\n",
      "batch 673: 39.84(16.00)\n",
      "batch 674: 39.83(30.67)\n",
      "batch 675: 39.83(42.67)\n",
      "batch 676: 39.81(24.00)\n",
      "batch 677: 39.81(42.67)\n",
      "batch 678: 39.80(32.00)\n",
      "batch 679: 39.79(30.67)\n",
      "batch 680: 39.80(49.33)\n",
      "batch 681: 39.80(41.33)\n",
      "batch 682: 39.80(38.67)\n",
      "batch 683: 39.81(44.00)\n",
      "batch 684: 39.84(62.67)\n",
      "batch 685: 39.84(37.33)\n",
      "batch 686: 39.83(37.33)\n",
      "batch 687: 39.83(40.00)\n",
      "batch 688: 39.85(54.67)\n",
      "batch 689: 39.85(36.00)\n",
      "batch 690: 39.85(41.33)\n",
      "batch 691: 39.88(62.67)\n",
      "batch 692: 39.88(36.00)\n",
      "batch 693: 39.86(24.00)\n",
      "batch 694: 39.84(32.00)\n",
      "batch 695: 39.83(30.67)\n",
      "batch 696: 39.83(40.00)\n",
      "batch 697: 39.85(54.67)\n",
      "batch 698: 39.88(56.00)\n",
      "batch 699: 39.87(38.67)\n",
      "batch 700: 39.89(49.33)\n",
      "batch 701: 39.87(28.00)\n",
      "batch 702: 39.86(34.67)\n",
      "batch 703: 39.88(49.33)\n",
      "batch 704: 39.91(65.33)\n",
      "batch 705: 39.91(38.67)\n",
      "batch 706: 39.89(22.67)\n",
      "batch 707: 39.87(26.67)\n",
      "batch 708: 39.87(42.67)\n",
      "batch 709: 39.91(68.00)\n",
      "batch 710: 39.91(36.00)\n",
      "batch 711: 39.89(30.67)\n",
      "batch 712: 39.91(49.33)\n",
      "batch 713: 39.91(42.67)\n",
      "batch 714: 39.90(32.00)\n",
      "batch 715: 39.88(29.33)\n",
      "batch 716: 39.87(30.67)\n",
      "batch 717: 39.89(52.00)\n",
      "batch 718: 39.90(46.67)\n",
      "batch 719: 39.90(41.33)\n",
      "batch 720: 39.90(37.33)\n",
      "batch 721: 39.89(38.67)\n",
      "batch 722: 39.89(37.33)\n",
      "batch 723: 39.85(13.33)\n",
      "batch 724: 39.83(20.00)\n",
      "batch 725: 39.84(48.00)\n",
      "batch 726: 39.84(44.00)\n",
      "batch 727: 39.85(46.67)\n",
      "batch 728: 39.85(38.67)\n",
      "batch 729: 39.87(53.33)\n",
      "batch 730: 39.86(33.33)\n",
      "batch 731: 39.88(50.67)\n",
      "batch 732: 39.90(54.67)\n",
      "batch 733: 39.89(33.33)\n",
      "batch 734: 39.89(44.00)\n",
      "batch 735: 39.89(36.00)\n",
      "batch 736: 39.89(40.00)\n",
      "batch 737: 39.90(49.33)\n",
      "batch 738: 39.94(66.67)\n",
      "batch 739: 39.93(36.00)\n",
      "batch 740: 39.90(14.67)\n",
      "batch 741: 39.88(30.67)\n",
      "batch 742: 39.89(45.33)\n",
      "batch 743: 39.88(32.00)\n",
      "batch 744: 39.87(30.67)\n",
      "batch 745: 39.86(34.67)\n",
      "batch 746: 39.88(53.33)\n",
      "batch 747: 39.88(38.67)\n",
      "batch 748: 39.90(53.33)\n",
      "batch 749: 39.93(65.33)\n",
      "batch 750: 39.93(36.00)\n",
      "batch 751: 39.92(37.33)\n",
      "batch 752: 39.96(68.00)\n",
      "batch 753: 39.95(30.67)\n",
      "batch 754: 39.96(46.67)\n",
      "batch 755: 39.96(41.33)\n",
      "batch 756: 39.96(44.00)\n",
      "batch 757: 39.98(53.33)\n",
      "batch 758: 40.00(54.67)\n",
      "batch 759: 39.99(34.67)\n",
      "batch 760: 40.00(48.00)\n",
      "batch 761: 40.01(44.00)\n",
      "batch 762: 40.02(52.00)\n",
      "batch 763: 40.01(29.33)\n",
      "batch 764: 40.01(37.33)\n",
      "batch 765: 40.01(41.33)\n",
      "batch 766: 40.02(45.33)\n",
      "batch 767: 40.02(41.33)\n",
      "batch 768: 40.01(37.33)\n",
      "batch 769: 40.00(29.33)\n",
      "batch 770: 39.99(33.33)\n",
      "batch 771: 39.99(41.33)\n",
      "batch 772: 39.99(37.33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 773: 39.99(37.33)\n",
      "batch 774: 40.00(49.33)\n",
      "batch 775: 40.00(38.67)\n",
      "batch 776: 40.00(40.00)\n",
      "batch 777: 39.99(33.33)\n",
      "batch 778: 39.99(44.00)\n",
      "batch 779: 40.00(45.33)\n",
      "batch 780: 40.01(46.67)\n",
      "batch 781: 40.02(49.33)\n",
      "batch 782: 40.01(29.33)\n",
      "batch 783: 39.99(30.67)\n",
      "batch 784: 39.97(20.00)\n",
      "batch 785: 39.98(46.67)\n",
      "batch 786: 39.97(36.00)\n",
      "batch 787: 39.97(40.00)\n",
      "batch 788: 39.97(41.33)\n",
      "batch 789: 39.97(38.67)\n",
      "batch 790: 39.98(45.33)\n",
      "batch 791: 39.99(46.67)\n",
      "batch 792: 39.98(37.33)\n",
      "batch 793: 39.99(46.67)\n",
      "batch 794: 40.01(56.00)\n",
      "batch 795: 40.02(41.33)\n",
      "batch 796: 40.02(44.00)\n",
      "batch 797: 40.01(32.00)\n",
      "batch 798: 40.01(40.00)\n",
      "batch 799: 39.99(25.33)\n",
      "batch 800: 40.01(52.00)\n",
      "batch 801: 40.02(52.00)\n",
      "batch 802: 40.04(53.33)\n",
      "batch 803: 40.03(32.00)\n",
      "batch 804: 40.02(30.67)\n",
      "batch 805: 40.03(48.00)\n",
      "batch 806: 40.01(26.67)\n",
      "batch 807: 40.02(45.33)\n",
      "batch 808: 40.01(32.00)\n",
      "batch 809: 40.03(57.33)\n",
      "batch 810: 40.02(37.33)\n",
      "batch 811: 40.05(57.33)\n",
      "batch 812: 40.02(22.67)\n",
      "batch 813: 40.03(42.67)\n",
      "batch 814: 40.02(33.33)\n",
      "batch 815: 40.03(48.00)\n",
      "batch 816: 40.03(41.33)\n",
      "batch 817: 40.00(18.67)\n",
      "batch 818: 40.01(48.00)\n",
      "batch 819: 40.01(38.67)\n",
      "batch 820: 40.00(33.33)\n",
      "batch 821: 39.98(21.33)\n",
      "batch 822: 40.00(56.00)\n",
      "batch 823: 40.02(54.67)\n",
      "batch 824: 40.02(42.67)\n",
      "batch 825: 40.02(41.33)\n",
      "batch 826: 40.03(44.00)\n",
      "batch 827: 40.03(38.67)\n",
      "batch 828: 40.03(40.00)\n",
      "batch 829: 40.01(25.33)\n",
      "batch 830: 40.01(38.67)\n",
      "batch 831: 40.00(29.33)\n",
      "batch 832: 39.98(30.67)\n",
      "batch 833: 39.98(33.33)\n",
      "batch 834: 39.99(49.33)\n",
      "batch 835: 39.98(30.67)\n",
      "batch 836: 39.98(45.33)\n",
      "batch 837: 39.98(38.67)\n",
      "batch 838: 39.99(50.67)\n",
      "batch 839: 40.00(44.00)\n",
      "batch 840: 40.00(41.33)\n",
      "batch 841: 39.99(32.00)\n",
      "batch 842: 39.98(33.33)\n",
      "batch 843: 39.98(40.00)\n",
      "batch 844: 39.99(42.67)\n",
      "batch 845: 39.98(38.67)\n",
      "batch 846: 39.97(26.67)\n",
      "batch 847: 39.98(46.67)\n",
      "batch 848: 39.95(18.67)\n",
      "batch 849: 39.95(42.67)\n",
      "batch 850: 39.94(26.67)\n",
      "batch 851: 39.95(52.00)\n",
      "batch 852: 39.98(61.33)\n",
      "batch 853: 39.97(37.33)\n",
      "batch 854: 39.97(38.67)\n",
      "batch 855: 39.99(54.67)\n",
      "batch 856: 40.01(57.33)\n",
      "batch 857: 40.02(48.00)\n",
      "batch 858: 40.02(36.00)\n",
      "batch 859: 40.01(36.00)\n",
      "batch 860: 40.00(30.67)\n",
      "batch 861: 40.00(41.33)\n",
      "batch 862: 39.99(26.67)\n",
      "batch 863: 39.98(34.67)\n",
      "batch 864: 39.99(50.67)\n",
      "batch 865: 40.00(44.00)\n",
      "batch 866: 40.01(52.00)\n",
      "batch 867: 40.03(54.67)\n",
      "batch 868: 40.03(38.67)\n",
      "batch 869: 40.01(24.00)\n",
      "batch 870: 39.99(24.00)\n",
      "batch 871: 40.00(52.00)\n",
      "batch 872: 40.01(49.33)\n",
      "batch 873: 40.02(44.00)\n",
      "batch 874: 40.01(36.00)\n",
      "batch 875: 40.03(53.33)\n",
      "batch 876: 40.01(21.33)\n",
      "batch 877: 40.00(29.33)\n",
      "batch 878: 40.02(57.33)\n",
      "batch 879: 40.03(53.33)\n",
      "batch 880: 40.02(33.33)\n",
      "batch 881: 40.02(41.33)\n",
      "batch 882: 40.04(52.00)\n",
      "batch 883: 40.05(49.33)\n",
      "batch 884: 40.05(38.67)\n",
      "batch 885: 40.06(54.67)\n",
      "batch 886: 40.08(50.67)\n",
      "batch 887: 40.06(28.00)\n",
      "batch 888: 40.08(56.00)\n",
      "batch 889: 40.07(29.33)\n",
      "batch 890: 40.09(57.33)\n",
      "batch 891: 40.09(42.67)\n",
      "batch 892: 40.08(28.00)\n",
      "batch 893: 40.07(30.67)\n",
      "batch 894: 40.08(52.00)\n",
      "batch 895: 40.09(49.33)\n",
      "batch 896: 40.09(38.67)\n",
      "batch 897: 40.09(45.33)\n",
      "batch 898: 40.08(28.00)\n",
      "batch 899: 40.07(34.67)\n",
      "batch 900: 40.08(46.67)\n",
      "batch 901: 40.08(36.00)\n",
      "batch 902: 40.08(46.67)\n",
      "batch 903: 40.09(46.67)\n",
      "batch 904: 40.08(32.00)\n",
      "batch 905: 40.08(36.00)\n",
      "batch 906: 40.10(57.33)\n",
      "batch 907: 40.09(37.33)\n",
      "batch 908: 40.09(40.00)\n",
      "batch 909: 40.10(42.67)\n",
      "batch 910: 40.08(26.67)\n",
      "batch 911: 40.09(46.67)\n",
      "batch 912: 40.09(37.33)\n",
      "batch 913: 40.08(34.67)\n",
      "batch 914: 40.09(46.67)\n",
      "batch 915: 40.09(42.67)\n",
      "batch 916: 40.10(49.33)\n",
      "batch 917: 40.11(49.33)\n",
      "batch 918: 40.13(57.33)\n",
      "batch 919: 40.11(24.00)\n",
      "batch 920: 40.12(46.67)\n",
      "batch 921: 40.11(32.00)\n",
      "batch 922: 40.11(41.33)\n",
      "batch 923: 40.12(49.33)\n",
      "batch 924: 40.13(52.00)\n",
      "batch 925: 40.15(50.67)\n",
      "batch 926: 40.15(40.00)\n",
      "batch 927: 40.17(61.33)\n",
      "batch 928: 40.17(42.67)\n",
      "batch 929: 40.16(25.33)\n",
      "batch 930: 40.16(41.33)\n",
      "batch 931: 40.18(65.33)\n",
      "batch 932: 40.19(45.33)\n",
      "batch 933: 40.19(38.67)\n",
      "batch 934: 40.17(25.33)\n",
      "batch 935: 40.19(56.00)\n",
      "batch 936: 40.19(41.33)\n",
      "batch 937: 40.19(44.00)\n",
      "batch 938: 40.20(48.00)\n",
      "batch 939: 40.22(54.67)\n",
      "batch 940: 40.24(57.33)\n",
      "batch 941: 40.24(40.00)\n",
      "batch 942: 40.23(36.00)\n",
      "batch 943: 40.25(60.00)\n",
      "batch 944: 40.26(50.67)\n",
      "batch 945: 40.27(46.67)\n",
      "batch 946: 40.29(61.33)\n",
      "batch 947: 40.29(36.00)\n",
      "batch 948: 40.32(72.00)\n",
      "batch 949: 40.32(36.00)\n",
      "batch 950: 40.30(28.00)\n",
      "batch 951: 40.32(58.67)\n",
      "batch 952: 40.32(42.67)\n",
      "batch 953: 40.33(42.67)\n",
      "batch 954: 40.33(46.67)\n",
      "batch 955: 40.34(41.33)\n",
      "batch 956: 40.33(33.33)\n",
      "batch 957: 40.31(24.00)\n",
      "batch 958: 40.30(33.33)\n",
      "batch 959: 40.33(62.67)\n",
      "batch 960: 40.32(37.33)\n",
      "batch 961: 40.32(36.00)\n",
      "batch 962: 40.29(14.67)\n",
      "batch 963: 40.30(46.67)\n",
      "batch 964: 40.32(64.00)\n",
      "batch 965: 40.33(48.00)\n",
      "batch 966: 40.33(41.33)\n",
      "batch 967: 40.32(32.00)\n",
      "batch 968: 40.32(38.67)\n",
      "batch 969: 40.32(34.67)\n",
      "batch 970: 40.31(34.67)\n",
      "batch 971: 40.32(52.00)\n",
      "batch 972: 40.31(26.67)\n",
      "batch 973: 40.30(32.00)\n",
      "batch 974: 40.29(30.67)\n",
      "batch 975: 40.29(36.00)\n",
      "batch 976: 40.29(40.00)\n",
      "batch 977: 40.28(36.00)\n",
      "batch 978: 40.29(52.00)\n",
      "batch 979: 40.30(42.67)\n",
      "batch 980: 40.29(32.00)\n",
      "batch 981: 40.27(26.67)\n",
      "batch 982: 40.28(46.67)\n",
      "batch 983: 40.28(44.00)\n",
      "batch 984: 40.29(50.67)\n",
      "batch 985: 40.29(36.00)\n",
      "batch 986: 40.29(38.67)\n",
      "batch 987: 40.30(52.00)\n",
      "batch 988: 40.31(48.00)\n",
      "batch 989: 40.30(33.33)\n",
      "batch 990: 40.29(34.67)\n",
      "batch 991: 40.29(40.00)\n",
      "batch 992: 40.30(44.00)\n",
      "batch 993: 40.31(48.00)\n",
      "batch 994: 40.31(48.00)\n",
      "batch 995: 40.30(29.33)\n",
      "batch 996: 40.32(53.33)\n",
      "batch 997: 40.32(46.67)\n",
      "batch 998: 40.33(44.00)\n",
      "batch 999: 40.30(14.67)\n",
      "batch 1000: 40.30(37.33)\n",
      "Val Best Acc 0.4461, Test Acc 0.4030\n",
      "Test Acc 0.4030 + 0.0066\n",
      "{'args': {'max_epoch': 10, 'shot': 1, 'query': 15, 'way': 5, 'validation_way': 5, 'lr': 0.001, 'step_size': 20, 'gamma': 0.7, 'temperature': 1, 'dataset': 'CUB', 'save_path': 'CUB-protonetwithhyperbolic_1_15_5_5_20_0.7_0.001_1_True_512_0.05_False_False', 'hyperbolic': True, 'c': 0.05, 'dim': 512, 'init_weights': None, 'gpu': '0', 'lr_decay': True, 'train_c': False, 'train_x': False, 'model_type': 'protonetwithhyperbolic'}, 'train_loss': [1.554306193590164, 1.4923840117454534, 1.4235050475597382, 1.4278099679946898, 1.4155283308029183, 1.3485121595859528, 1.3841634464263917, 1.3732150226831434, 1.3423248249292374, 1.332782269716263], 'val_loss': [1.5010169539451599, 1.4477445695400244, 1.4376674656867985, 1.4021756261587148, 1.3853404803276057, 1.3587871094942097, 1.3441771385669716, 1.4302763092517858, 1.3293862452507021, 1.3600996440649042], 'train_acc': [0.32546667426824577, 0.3433333414793016, 0.3964000104367733, 0.38053334131836897, 0.37866667509078966, 0.42960001170635226, 0.4141333444416523, 0.4229333421587944, 0.4338666757941246, 0.4316000109910965], 'val_acc': [0.34458667385578173, 0.36317334127426154, 0.38826667515933516, 0.3990400100052355, 0.4168533440232277, 0.4206933425962925, 0.4304000100791455, 0.42816000974178325, 0.43754667705297473, 0.4460533442497253], 'max_acc': 0.4460533442497253, 'max_acc_epoch': 10}\n"
     ]
    }
   ],
   "source": [
    "! python train_protonet.py --gpu 0 --hyperbolic --dataset CUB --dim 512 --lr 0.001 --c 0.05 --gamma 0.7 --step_size 20 --max_epoch 10 --model_type protonetwithhyperbolic # --model_type hypnet # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
