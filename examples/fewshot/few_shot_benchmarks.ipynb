{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! bash get_birds.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 0.05,\n",
      " 'dataset': 'CUB',\n",
      " 'dim': 512,\n",
      " 'gamma': 0.7,\n",
      " 'gpu': '0',\n",
      " 'hyperbolic': True,\n",
      " 'init_weights': None,\n",
      " 'lr': 0.001,\n",
      " 'lr_decay': True,\n",
      " 'max_epoch': 10,\n",
      " 'query': 15,\n",
      " 'save_path': None,\n",
      " 'shot': 1,\n",
      " 'step_size': 20,\n",
      " 'temperature': 1,\n",
      " 'train_c': False,\n",
      " 'train_x': False,\n",
      " 'validation_way': 5,\n",
      " 'way': 5}\n",
      "CUDA IS AVAILABLE\n",
      "using gpu: 0\n",
      "epoch 1, train 1/100, loss=1.8121 acc=0.3067\n",
      "epoch 1, train 2/100, loss=2.3138 acc=0.2800\n",
      "epoch 1, train 3/100, loss=1.5610 acc=0.3467\n",
      "epoch 1, train 4/100, loss=1.3809 acc=0.4400\n",
      "epoch 1, train 5/100, loss=1.8745 acc=0.2933\n",
      "epoch 1, train 6/100, loss=1.8518 acc=0.4000\n",
      "epoch 1, train 7/100, loss=1.2580 acc=0.4667\n",
      "epoch 1, train 8/100, loss=1.5075 acc=0.3467\n",
      "epoch 1, train 9/100, loss=1.6178 acc=0.3200\n",
      "epoch 1, train 10/100, loss=1.4630 acc=0.4000\n",
      "epoch 1, train 11/100, loss=2.0157 acc=0.3200\n",
      "epoch 1, train 12/100, loss=1.4026 acc=0.4667\n",
      "epoch 1, train 13/100, loss=2.4490 acc=0.2133\n",
      "epoch 1, train 14/100, loss=1.6662 acc=0.2933\n",
      "epoch 1, train 15/100, loss=1.6195 acc=0.3333\n",
      "epoch 1, train 16/100, loss=1.3940 acc=0.4533\n",
      "epoch 1, train 17/100, loss=1.9176 acc=0.2933\n",
      "epoch 1, train 18/100, loss=1.5573 acc=0.4667\n",
      "epoch 1, train 19/100, loss=1.4269 acc=0.4133\n",
      "epoch 1, train 20/100, loss=1.6520 acc=0.3200\n",
      "epoch 1, train 21/100, loss=1.6790 acc=0.4400\n",
      "epoch 1, train 22/100, loss=1.8517 acc=0.3333\n",
      "epoch 1, train 23/100, loss=1.3575 acc=0.4267\n",
      "epoch 1, train 24/100, loss=1.4527 acc=0.4400\n",
      "epoch 1, train 25/100, loss=1.3799 acc=0.4267\n",
      "epoch 1, train 26/100, loss=1.5499 acc=0.3333\n",
      "epoch 1, train 27/100, loss=1.7901 acc=0.2000\n",
      "epoch 1, train 28/100, loss=1.6963 acc=0.2667\n",
      "epoch 1, train 29/100, loss=1.5424 acc=0.3333\n",
      "epoch 1, train 30/100, loss=1.8718 acc=0.3867\n",
      "epoch 1, train 31/100, loss=1.4452 acc=0.4000\n",
      "epoch 1, train 32/100, loss=1.5220 acc=0.3733\n",
      "epoch 1, train 33/100, loss=1.4239 acc=0.4400\n",
      "epoch 1, train 34/100, loss=1.3995 acc=0.3733\n",
      "epoch 1, train 35/100, loss=1.3432 acc=0.4800\n",
      "epoch 1, train 36/100, loss=2.0044 acc=0.2533\n",
      "epoch 1, train 37/100, loss=1.9084 acc=0.4133\n",
      "epoch 1, train 38/100, loss=1.7590 acc=0.3200\n",
      "epoch 1, train 39/100, loss=1.2924 acc=0.4133\n",
      "epoch 1, train 40/100, loss=1.0403 acc=0.5733\n",
      "epoch 1, train 41/100, loss=1.5547 acc=0.4533\n",
      "epoch 1, train 42/100, loss=1.2088 acc=0.4933\n",
      "epoch 1, train 43/100, loss=1.2615 acc=0.4400\n",
      "epoch 1, train 44/100, loss=1.4471 acc=0.4000\n",
      "epoch 1, train 45/100, loss=0.8779 acc=0.6400\n",
      "epoch 1, train 46/100, loss=1.3317 acc=0.5067\n",
      "epoch 1, train 47/100, loss=1.7543 acc=0.2667\n",
      "epoch 1, train 48/100, loss=1.4357 acc=0.4667\n",
      "epoch 1, train 49/100, loss=1.4528 acc=0.3733\n",
      "epoch 1, train 50/100, loss=1.4169 acc=0.3467\n",
      "epoch 1, train 51/100, loss=1.8577 acc=0.2400\n",
      "epoch 1, train 52/100, loss=1.5124 acc=0.3867\n",
      "epoch 1, train 53/100, loss=1.7177 acc=0.3733\n",
      "epoch 1, train 54/100, loss=1.7372 acc=0.3200\n",
      "epoch 1, train 55/100, loss=1.5396 acc=0.3733\n",
      "epoch 1, train 56/100, loss=1.7098 acc=0.3467\n",
      "epoch 1, train 57/100, loss=1.2972 acc=0.4933\n",
      "epoch 1, train 58/100, loss=1.2808 acc=0.4267\n",
      "epoch 1, train 59/100, loss=1.9222 acc=0.3067\n",
      "epoch 1, train 60/100, loss=1.6064 acc=0.2933\n",
      "epoch 1, train 61/100, loss=0.9056 acc=0.7067\n",
      "epoch 1, train 62/100, loss=1.3083 acc=0.4000\n",
      "epoch 1, train 63/100, loss=1.1570 acc=0.5200\n",
      "epoch 1, train 64/100, loss=1.4861 acc=0.3733\n",
      "epoch 1, train 65/100, loss=1.3730 acc=0.4933\n",
      "epoch 1, train 66/100, loss=1.4981 acc=0.4000\n",
      "epoch 1, train 67/100, loss=1.4549 acc=0.3733\n",
      "epoch 1, train 68/100, loss=1.5341 acc=0.3867\n",
      "epoch 1, train 69/100, loss=1.4738 acc=0.4800\n",
      "epoch 1, train 70/100, loss=1.3830 acc=0.4667\n",
      "epoch 1, train 71/100, loss=1.5256 acc=0.4933\n",
      "epoch 1, train 72/100, loss=1.8504 acc=0.2667\n",
      "epoch 1, train 73/100, loss=1.9131 acc=0.2133\n",
      "epoch 1, train 74/100, loss=1.3455 acc=0.4000\n",
      "epoch 1, train 75/100, loss=1.4383 acc=0.3467\n",
      "epoch 1, train 76/100, loss=1.6408 acc=0.3200\n",
      "epoch 1, train 77/100, loss=1.1980 acc=0.5200\n",
      "epoch 1, train 78/100, loss=2.0021 acc=0.2800\n",
      "epoch 1, train 79/100, loss=1.3619 acc=0.4533\n",
      "epoch 1, train 80/100, loss=1.6652 acc=0.4000\n",
      "epoch 1, train 81/100, loss=0.9758 acc=0.5200\n",
      "epoch 1, train 82/100, loss=1.1309 acc=0.5467\n",
      "epoch 1, train 83/100, loss=1.7551 acc=0.3200\n",
      "epoch 1, train 84/100, loss=1.0709 acc=0.5733\n",
      "epoch 1, train 85/100, loss=1.4018 acc=0.3733\n",
      "epoch 1, train 86/100, loss=1.2256 acc=0.5333\n",
      "epoch 1, train 87/100, loss=0.9886 acc=0.5200\n",
      "epoch 1, train 88/100, loss=1.9805 acc=0.2800\n",
      "epoch 1, train 89/100, loss=1.1231 acc=0.5600\n",
      "epoch 1, train 90/100, loss=1.3069 acc=0.4400\n",
      "epoch 1, train 91/100, loss=1.3265 acc=0.4667\n",
      "epoch 1, train 92/100, loss=1.5020 acc=0.4133\n",
      "epoch 1, train 93/100, loss=1.1674 acc=0.5733\n",
      "epoch 1, train 94/100, loss=1.5737 acc=0.3467\n",
      "epoch 1, train 95/100, loss=1.1095 acc=0.4267\n",
      "epoch 1, train 96/100, loss=1.4734 acc=0.3067\n",
      "epoch 1, train 97/100, loss=1.8297 acc=0.2400\n",
      "epoch 1, train 98/100, loss=2.0243 acc=0.1333\n",
      "epoch 1, train 99/100, loss=1.2642 acc=0.4933\n",
      "epoch 1, train 100/100, loss=1.7498 acc=0.2533\n",
      "best epoch 0, best val acc=0.0000\n",
      "epoch 1, val, loss=1.4413 acc=0.4196\n",
      "ETA:6m/56m\n",
      "epoch 2, train 1/100, loss=1.6549 acc=0.2933\n",
      "epoch 2, train 2/100, loss=1.1904 acc=0.5067\n",
      "epoch 2, train 3/100, loss=1.9157 acc=0.2133\n",
      "epoch 2, train 4/100, loss=1.1667 acc=0.5333\n",
      "epoch 2, train 5/100, loss=1.8707 acc=0.2933\n",
      "epoch 2, train 6/100, loss=1.1246 acc=0.5200\n",
      "epoch 2, train 7/100, loss=1.2883 acc=0.4800\n",
      "epoch 2, train 8/100, loss=1.3244 acc=0.4533\n",
      "epoch 2, train 9/100, loss=0.8970 acc=0.6400\n",
      "epoch 2, train 10/100, loss=1.3709 acc=0.4000\n",
      "epoch 2, train 11/100, loss=1.7829 acc=0.2800\n",
      "epoch 2, train 12/100, loss=1.2926 acc=0.5333\n",
      "epoch 2, train 13/100, loss=1.1971 acc=0.4267\n",
      "epoch 2, train 14/100, loss=1.5617 acc=0.3333\n",
      "epoch 2, train 15/100, loss=0.8181 acc=0.6400\n",
      "epoch 2, train 16/100, loss=1.3087 acc=0.4133\n",
      "epoch 2, train 17/100, loss=1.2685 acc=0.4533\n",
      "epoch 2, train 18/100, loss=1.0853 acc=0.4533\n",
      "epoch 2, train 19/100, loss=1.1773 acc=0.5467\n",
      "epoch 2, train 20/100, loss=1.4309 acc=0.4667\n",
      "epoch 2, train 21/100, loss=1.6242 acc=0.3867\n",
      "epoch 2, train 22/100, loss=1.7413 acc=0.3600\n",
      "epoch 2, train 23/100, loss=0.8915 acc=0.7067\n",
      "epoch 2, train 24/100, loss=1.5445 acc=0.3467\n",
      "epoch 2, train 25/100, loss=1.1296 acc=0.4933\n",
      "epoch 2, train 26/100, loss=1.3054 acc=0.5067\n",
      "epoch 2, train 27/100, loss=1.3646 acc=0.4533\n",
      "epoch 2, train 28/100, loss=1.2265 acc=0.4933\n",
      "epoch 2, train 29/100, loss=1.4828 acc=0.4400\n",
      "epoch 2, train 30/100, loss=1.2817 acc=0.5067\n",
      "epoch 2, train 31/100, loss=1.5227 acc=0.3867\n",
      "epoch 2, train 32/100, loss=1.3808 acc=0.4400\n",
      "epoch 2, train 33/100, loss=1.1623 acc=0.5333\n",
      "epoch 2, train 34/100, loss=1.1881 acc=0.5067\n",
      "epoch 2, train 35/100, loss=1.5551 acc=0.3467\n",
      "epoch 2, train 36/100, loss=1.5701 acc=0.2800\n",
      "epoch 2, train 37/100, loss=1.0664 acc=0.4933\n",
      "epoch 2, train 38/100, loss=0.8742 acc=0.6267\n",
      "epoch 2, train 39/100, loss=1.7945 acc=0.2800\n",
      "epoch 2, train 40/100, loss=1.5813 acc=0.4400\n",
      "epoch 2, train 41/100, loss=1.4288 acc=0.3733\n",
      "epoch 2, train 42/100, loss=1.6420 acc=0.2533\n",
      "epoch 2, train 43/100, loss=1.3714 acc=0.3200\n",
      "epoch 2, train 44/100, loss=1.2190 acc=0.5467\n",
      "epoch 2, train 45/100, loss=1.5902 acc=0.3200\n",
      "epoch 2, train 46/100, loss=1.7247 acc=0.2933\n",
      "epoch 2, train 47/100, loss=1.3754 acc=0.4667\n",
      "epoch 2, train 48/100, loss=1.3962 acc=0.4000\n",
      "epoch 2, train 49/100, loss=1.2942 acc=0.6400\n",
      "epoch 2, train 50/100, loss=1.3433 acc=0.3867\n",
      "epoch 2, train 51/100, loss=0.9053 acc=0.6533\n",
      "epoch 2, train 52/100, loss=1.2595 acc=0.4667\n",
      "epoch 2, train 53/100, loss=1.5720 acc=0.3867\n",
      "epoch 2, train 54/100, loss=1.9297 acc=0.3200\n",
      "epoch 2, train 55/100, loss=1.3061 acc=0.5067\n",
      "epoch 2, train 56/100, loss=0.8750 acc=0.7067\n",
      "epoch 2, train 57/100, loss=1.0785 acc=0.5200\n",
      "epoch 2, train 58/100, loss=1.4794 acc=0.3600\n",
      "epoch 2, train 59/100, loss=1.2481 acc=0.4400\n",
      "epoch 2, train 60/100, loss=0.9886 acc=0.6133\n",
      "epoch 2, train 61/100, loss=1.4595 acc=0.3600\n",
      "epoch 2, train 62/100, loss=1.1866 acc=0.4400\n",
      "epoch 2, train 63/100, loss=1.1755 acc=0.4533\n",
      "epoch 2, train 64/100, loss=1.0020 acc=0.6133\n",
      "epoch 2, train 65/100, loss=1.3077 acc=0.3733\n",
      "epoch 2, train 66/100, loss=1.3162 acc=0.4800\n",
      "epoch 2, train 67/100, loss=1.2214 acc=0.5467\n",
      "epoch 2, train 68/100, loss=1.2555 acc=0.5333\n",
      "epoch 2, train 69/100, loss=1.3410 acc=0.4667\n",
      "epoch 2, train 70/100, loss=1.3044 acc=0.5467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train 71/100, loss=1.0665 acc=0.6133\n",
      "epoch 2, train 72/100, loss=1.9331 acc=0.3600\n",
      "epoch 2, train 73/100, loss=1.6221 acc=0.3733\n",
      "epoch 2, train 74/100, loss=1.4029 acc=0.3867\n",
      "epoch 2, train 75/100, loss=1.4207 acc=0.4267\n",
      "epoch 2, train 76/100, loss=1.0846 acc=0.5600\n",
      "epoch 2, train 77/100, loss=1.0453 acc=0.5600\n",
      "epoch 2, train 78/100, loss=1.3367 acc=0.5333\n",
      "epoch 2, train 79/100, loss=1.7934 acc=0.2933\n",
      "epoch 2, train 80/100, loss=1.6757 acc=0.2267\n",
      "epoch 2, train 81/100, loss=0.9745 acc=0.6667\n",
      "epoch 2, train 82/100, loss=1.6441 acc=0.3600\n",
      "epoch 2, train 83/100, loss=1.5599 acc=0.3467\n",
      "epoch 2, train 84/100, loss=1.6437 acc=0.3733\n",
      "epoch 2, train 85/100, loss=1.0736 acc=0.5200\n",
      "epoch 2, train 86/100, loss=1.2593 acc=0.4267\n",
      "epoch 2, train 87/100, loss=1.1911 acc=0.5867\n",
      "epoch 2, train 88/100, loss=1.4244 acc=0.4667\n",
      "epoch 2, train 89/100, loss=1.2852 acc=0.4800\n",
      "epoch 2, train 90/100, loss=1.0317 acc=0.5867\n",
      "epoch 2, train 91/100, loss=1.2482 acc=0.4400\n",
      "epoch 2, train 92/100, loss=1.6570 acc=0.4000\n",
      "epoch 2, train 93/100, loss=1.2670 acc=0.4800\n",
      "epoch 2, train 94/100, loss=1.3159 acc=0.4133\n",
      "epoch 2, train 95/100, loss=1.8420 acc=0.2667\n",
      "epoch 2, train 96/100, loss=0.8070 acc=0.7600\n",
      "epoch 2, train 97/100, loss=1.0613 acc=0.4933\n",
      "epoch 2, train 98/100, loss=1.0753 acc=0.4800\n",
      "epoch 2, train 99/100, loss=1.5111 acc=0.3067\n",
      "epoch 2, train 100/100, loss=1.2224 acc=0.4933\n",
      "best epoch 1, best val acc=0.4196\n",
      "epoch 2, val, loss=1.3295 acc=0.4564\n",
      "ETA:11m/57m\n",
      "epoch 3, train 1/100, loss=1.2190 acc=0.5067\n",
      "epoch 3, train 2/100, loss=1.2635 acc=0.4800\n",
      "epoch 3, train 3/100, loss=0.4764 acc=0.8533\n",
      "epoch 3, train 4/100, loss=1.2808 acc=0.4667\n",
      "epoch 3, train 5/100, loss=1.2403 acc=0.5067\n",
      "epoch 3, train 6/100, loss=1.0812 acc=0.4533\n",
      "epoch 3, train 7/100, loss=1.4641 acc=0.3867\n",
      "epoch 3, train 8/100, loss=1.3956 acc=0.4533\n",
      "epoch 3, train 9/100, loss=1.4532 acc=0.4000\n",
      "epoch 3, train 10/100, loss=1.3966 acc=0.4267\n",
      "epoch 3, train 11/100, loss=1.2671 acc=0.4800\n",
      "epoch 3, train 12/100, loss=1.3066 acc=0.4267\n",
      "epoch 3, train 13/100, loss=1.3186 acc=0.3733\n",
      "epoch 3, train 14/100, loss=1.0572 acc=0.5600\n",
      "epoch 3, train 15/100, loss=1.3636 acc=0.4133\n",
      "epoch 3, train 16/100, loss=1.6193 acc=0.3600\n",
      "epoch 3, train 17/100, loss=1.5531 acc=0.2667\n",
      "epoch 3, train 18/100, loss=1.3259 acc=0.4933\n",
      "epoch 3, train 19/100, loss=1.1649 acc=0.5333\n",
      "epoch 3, train 20/100, loss=1.1230 acc=0.5333\n",
      "epoch 3, train 21/100, loss=1.2996 acc=0.3467\n",
      "epoch 3, train 22/100, loss=1.5221 acc=0.3733\n",
      "epoch 3, train 23/100, loss=0.9718 acc=0.6400\n",
      "epoch 3, train 24/100, loss=1.5416 acc=0.3467\n",
      "epoch 3, train 25/100, loss=1.4139 acc=0.4667\n",
      "epoch 3, train 26/100, loss=1.4881 acc=0.4133\n",
      "epoch 3, train 27/100, loss=0.9125 acc=0.6000\n",
      "epoch 3, train 28/100, loss=1.6221 acc=0.3600\n",
      "epoch 3, train 29/100, loss=1.2682 acc=0.4533\n",
      "epoch 3, train 30/100, loss=0.9246 acc=0.6133\n",
      "epoch 3, train 31/100, loss=0.6437 acc=0.7333\n",
      "epoch 3, train 32/100, loss=1.2228 acc=0.5467\n",
      "epoch 3, train 33/100, loss=1.5967 acc=0.4267\n",
      "epoch 3, train 34/100, loss=1.1085 acc=0.5600\n",
      "epoch 3, train 35/100, loss=1.5520 acc=0.4000\n",
      "epoch 3, train 36/100, loss=1.0151 acc=0.6267\n",
      "epoch 3, train 37/100, loss=1.4992 acc=0.3867\n",
      "epoch 3, train 38/100, loss=1.0422 acc=0.5333\n",
      "epoch 3, train 39/100, loss=1.0357 acc=0.5200\n",
      "epoch 3, train 40/100, loss=1.3308 acc=0.4400\n",
      "epoch 3, train 41/100, loss=1.0506 acc=0.5200\n",
      "epoch 3, train 42/100, loss=1.5446 acc=0.4133\n",
      "epoch 3, train 43/100, loss=1.0393 acc=0.5733\n",
      "epoch 3, train 44/100, loss=0.8663 acc=0.6267\n",
      "epoch 3, train 45/100, loss=1.5553 acc=0.2533\n",
      "epoch 3, train 46/100, loss=1.7262 acc=0.3733\n",
      "epoch 3, train 47/100, loss=1.2721 acc=0.4667\n",
      "epoch 3, train 48/100, loss=1.2399 acc=0.4800\n",
      "epoch 3, train 49/100, loss=1.0556 acc=0.6133\n",
      "epoch 3, train 50/100, loss=1.5769 acc=0.2933\n",
      "epoch 3, train 51/100, loss=1.1730 acc=0.5333\n",
      "epoch 3, train 52/100, loss=1.4666 acc=0.3733\n",
      "epoch 3, train 53/100, loss=1.2510 acc=0.4267\n",
      "epoch 3, train 54/100, loss=1.0091 acc=0.6400\n",
      "epoch 3, train 55/100, loss=1.6239 acc=0.3467\n",
      "epoch 3, train 56/100, loss=1.6539 acc=0.3600\n",
      "epoch 3, train 57/100, loss=1.1106 acc=0.4933\n",
      "epoch 3, train 58/100, loss=1.5505 acc=0.3333\n",
      "epoch 3, train 59/100, loss=1.1679 acc=0.6133\n",
      "epoch 3, train 60/100, loss=1.3650 acc=0.4933\n",
      "epoch 3, train 61/100, loss=1.2702 acc=0.5200\n",
      "epoch 3, train 62/100, loss=1.6228 acc=0.3200\n",
      "epoch 3, train 63/100, loss=1.0240 acc=0.5733\n",
      "epoch 3, train 64/100, loss=1.0402 acc=0.5333\n",
      "epoch 3, train 65/100, loss=1.4522 acc=0.4800\n",
      "epoch 3, train 66/100, loss=1.0297 acc=0.5467\n",
      "epoch 3, train 67/100, loss=1.3952 acc=0.4267\n",
      "epoch 3, train 68/100, loss=1.6708 acc=0.3200\n",
      "epoch 3, train 69/100, loss=0.6620 acc=0.7600\n",
      "epoch 3, train 70/100, loss=0.7694 acc=0.8133\n",
      "epoch 3, train 71/100, loss=1.5908 acc=0.3467\n",
      "epoch 3, train 72/100, loss=1.1769 acc=0.5200\n",
      "epoch 3, train 73/100, loss=1.1442 acc=0.5333\n",
      "epoch 3, train 74/100, loss=1.6979 acc=0.2933\n",
      "epoch 3, train 75/100, loss=1.7180 acc=0.2133\n",
      "epoch 3, train 76/100, loss=1.4006 acc=0.4400\n",
      "epoch 3, train 77/100, loss=0.9627 acc=0.6000\n",
      "epoch 3, train 78/100, loss=1.1358 acc=0.3867\n",
      "epoch 3, train 79/100, loss=0.9548 acc=0.5867\n",
      "epoch 3, train 80/100, loss=1.1924 acc=0.5067\n",
      "epoch 3, train 81/100, loss=1.4139 acc=0.4533\n",
      "epoch 3, train 82/100, loss=1.4273 acc=0.4800\n",
      "epoch 3, train 83/100, loss=1.4840 acc=0.3333\n",
      "epoch 3, train 84/100, loss=1.1898 acc=0.4267\n",
      "epoch 3, train 85/100, loss=0.7779 acc=0.7333\n",
      "epoch 3, train 86/100, loss=0.9739 acc=0.5733\n",
      "epoch 3, train 87/100, loss=1.4967 acc=0.3600\n",
      "epoch 3, train 88/100, loss=1.4917 acc=0.2933\n",
      "epoch 3, train 89/100, loss=1.2340 acc=0.4800\n",
      "epoch 3, train 90/100, loss=1.1008 acc=0.5733\n",
      "epoch 3, train 91/100, loss=1.4170 acc=0.3467\n",
      "epoch 3, train 92/100, loss=1.3270 acc=0.4800\n",
      "epoch 3, train 93/100, loss=0.9740 acc=0.7067\n",
      "epoch 3, train 94/100, loss=1.1812 acc=0.5867\n",
      "epoch 3, train 95/100, loss=1.3900 acc=0.4267\n",
      "epoch 3, train 96/100, loss=1.0093 acc=0.6267\n",
      "epoch 3, train 97/100, loss=1.0680 acc=0.4933\n",
      "epoch 3, train 98/100, loss=1.3718 acc=0.3867\n",
      "epoch 3, train 99/100, loss=1.1901 acc=0.4667\n",
      "epoch 3, train 100/100, loss=0.8150 acc=0.6933\n",
      "best epoch 2, best val acc=0.4564\n",
      "epoch 3, val, loss=1.2873 acc=0.4796\n",
      "ETA:17m/57m\n",
      "epoch 4, train 1/100, loss=1.2315 acc=0.5333\n",
      "epoch 4, train 2/100, loss=1.4351 acc=0.4533\n",
      "epoch 4, train 3/100, loss=0.8372 acc=0.6800\n",
      "epoch 4, train 4/100, loss=0.7145 acc=0.7467\n",
      "epoch 4, train 5/100, loss=0.9237 acc=0.6000\n",
      "epoch 4, train 6/100, loss=1.2993 acc=0.3600\n",
      "epoch 4, train 7/100, loss=1.1212 acc=0.5600\n",
      "epoch 4, train 8/100, loss=1.5008 acc=0.3867\n",
      "epoch 4, train 9/100, loss=1.1822 acc=0.5600\n",
      "epoch 4, train 10/100, loss=1.1763 acc=0.5333\n",
      "epoch 4, train 11/100, loss=0.6681 acc=0.6667\n",
      "epoch 4, train 12/100, loss=1.5579 acc=0.4267\n",
      "epoch 4, train 13/100, loss=1.4954 acc=0.4667\n",
      "epoch 4, train 14/100, loss=1.0806 acc=0.5600\n",
      "epoch 4, train 15/100, loss=1.4836 acc=0.4667\n",
      "epoch 4, train 16/100, loss=0.9963 acc=0.5067\n",
      "epoch 4, train 17/100, loss=1.1505 acc=0.5600\n",
      "epoch 4, train 18/100, loss=1.3720 acc=0.4533\n",
      "epoch 4, train 19/100, loss=0.9404 acc=0.5200\n",
      "epoch 4, train 20/100, loss=0.9230 acc=0.6533\n",
      "epoch 4, train 21/100, loss=1.0198 acc=0.5600\n",
      "epoch 4, train 22/100, loss=1.1066 acc=0.5600\n",
      "epoch 4, train 23/100, loss=1.4079 acc=0.4400\n",
      "epoch 4, train 24/100, loss=1.1664 acc=0.5200\n",
      "epoch 4, train 25/100, loss=1.3918 acc=0.4533\n",
      "epoch 4, train 26/100, loss=1.0481 acc=0.6267\n",
      "epoch 4, train 27/100, loss=1.3748 acc=0.3867\n",
      "epoch 4, train 28/100, loss=1.3594 acc=0.5067\n",
      "epoch 4, train 29/100, loss=0.8595 acc=0.6000\n",
      "epoch 4, train 30/100, loss=1.6542 acc=0.3200\n",
      "epoch 4, train 31/100, loss=0.9067 acc=0.6133\n",
      "epoch 4, train 32/100, loss=1.1801 acc=0.6133\n",
      "epoch 4, train 33/100, loss=1.2911 acc=0.4800\n",
      "epoch 4, train 34/100, loss=1.0176 acc=0.5067\n",
      "epoch 4, train 35/100, loss=1.5593 acc=0.4133\n",
      "epoch 4, train 36/100, loss=1.4663 acc=0.4400\n",
      "epoch 4, train 37/100, loss=1.2220 acc=0.4667\n",
      "epoch 4, train 38/100, loss=0.6890 acc=0.7067\n",
      "epoch 4, train 39/100, loss=0.9091 acc=0.6533\n",
      "epoch 4, train 40/100, loss=1.1202 acc=0.5733\n",
      "epoch 4, train 41/100, loss=1.4667 acc=0.4267\n",
      "epoch 4, train 42/100, loss=0.8012 acc=0.6667\n",
      "epoch 4, train 43/100, loss=1.2981 acc=0.4400\n",
      "epoch 4, train 44/100, loss=1.3949 acc=0.4533\n",
      "epoch 4, train 45/100, loss=0.9698 acc=0.5067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train 46/100, loss=1.3386 acc=0.4133\n",
      "epoch 4, train 47/100, loss=0.9580 acc=0.6667\n",
      "epoch 4, train 48/100, loss=1.0121 acc=0.5333\n",
      "epoch 4, train 49/100, loss=0.9369 acc=0.6667\n",
      "epoch 4, train 50/100, loss=1.3268 acc=0.3600\n",
      "epoch 4, train 51/100, loss=1.2239 acc=0.4800\n",
      "epoch 4, train 52/100, loss=1.4480 acc=0.3467\n",
      "epoch 4, train 53/100, loss=1.4336 acc=0.3200\n",
      "epoch 4, train 54/100, loss=1.2716 acc=0.4267\n",
      "epoch 4, train 55/100, loss=1.5798 acc=0.3867\n",
      "epoch 4, train 56/100, loss=1.1503 acc=0.5200\n",
      "epoch 4, train 57/100, loss=1.4495 acc=0.4000\n",
      "epoch 4, train 58/100, loss=0.9128 acc=0.6933\n",
      "epoch 4, train 59/100, loss=1.4659 acc=0.3067\n",
      "epoch 4, train 60/100, loss=1.6254 acc=0.4000\n",
      "epoch 4, train 61/100, loss=1.0442 acc=0.5467\n",
      "epoch 4, train 62/100, loss=0.8433 acc=0.7200\n",
      "epoch 4, train 63/100, loss=0.8700 acc=0.6133\n",
      "epoch 4, train 64/100, loss=0.6001 acc=0.7467\n",
      "epoch 4, train 65/100, loss=1.7599 acc=0.3600\n",
      "epoch 4, train 66/100, loss=1.5888 acc=0.4000\n",
      "epoch 4, train 67/100, loss=0.8764 acc=0.6267\n",
      "epoch 4, train 68/100, loss=1.4080 acc=0.4133\n",
      "epoch 4, train 69/100, loss=1.5440 acc=0.3333\n",
      "epoch 4, train 70/100, loss=0.9876 acc=0.7600\n",
      "epoch 4, train 71/100, loss=1.2433 acc=0.4667\n",
      "epoch 4, train 72/100, loss=1.3148 acc=0.4800\n",
      "epoch 4, train 73/100, loss=1.3086 acc=0.4533\n",
      "epoch 4, train 74/100, loss=1.3203 acc=0.4667\n",
      "epoch 4, train 75/100, loss=1.2610 acc=0.4533\n",
      "epoch 4, train 76/100, loss=1.3188 acc=0.5467\n",
      "epoch 4, train 77/100, loss=2.2213 acc=0.2133\n",
      "epoch 4, train 78/100, loss=1.4539 acc=0.3867\n",
      "epoch 4, train 79/100, loss=1.0328 acc=0.5333\n",
      "epoch 4, train 80/100, loss=1.6581 acc=0.3867\n",
      "epoch 4, train 81/100, loss=1.5244 acc=0.3733\n",
      "epoch 4, train 82/100, loss=1.0948 acc=0.5733\n",
      "epoch 4, train 83/100, loss=1.7344 acc=0.2800\n",
      "epoch 4, train 84/100, loss=1.1867 acc=0.4533\n",
      "epoch 4, train 85/100, loss=1.0981 acc=0.5733\n",
      "epoch 4, train 86/100, loss=1.2862 acc=0.4800\n",
      "epoch 4, train 87/100, loss=1.1582 acc=0.5733\n",
      "epoch 4, train 88/100, loss=1.5467 acc=0.2400\n",
      "epoch 4, train 89/100, loss=0.8937 acc=0.6667\n",
      "epoch 4, train 90/100, loss=1.4903 acc=0.4133\n",
      "epoch 4, train 91/100, loss=1.2889 acc=0.5067\n",
      "epoch 4, train 92/100, loss=1.0564 acc=0.5867\n",
      "epoch 4, train 93/100, loss=1.3917 acc=0.3600\n",
      "epoch 4, train 94/100, loss=0.7833 acc=0.7200\n",
      "epoch 4, train 95/100, loss=1.4079 acc=0.4400\n",
      "epoch 4, train 96/100, loss=1.3956 acc=0.3600\n",
      "epoch 4, train 97/100, loss=1.4409 acc=0.4267\n",
      "epoch 4, train 98/100, loss=1.2653 acc=0.4000\n",
      "epoch 4, train 99/100, loss=1.1114 acc=0.5733\n",
      "epoch 4, train 100/100, loss=1.1886 acc=0.5333\n",
      "best epoch 3, best val acc=0.4796\n",
      "epoch 4, val, loss=1.2676 acc=0.4971\n",
      "ETA:23m/57m\n",
      "epoch 5, train 1/100, loss=0.9559 acc=0.6533\n",
      "epoch 5, train 2/100, loss=0.9729 acc=0.6133\n",
      "epoch 5, train 3/100, loss=1.1168 acc=0.5333\n",
      "epoch 5, train 4/100, loss=1.4716 acc=0.4000\n",
      "epoch 5, train 5/100, loss=1.1226 acc=0.5867\n",
      "epoch 5, train 6/100, loss=1.3275 acc=0.4800\n",
      "epoch 5, train 7/100, loss=0.9589 acc=0.6133\n",
      "epoch 5, train 8/100, loss=1.4029 acc=0.4133\n",
      "epoch 5, train 9/100, loss=0.8373 acc=0.6267\n",
      "epoch 5, train 10/100, loss=0.8300 acc=0.6400\n",
      "epoch 5, train 11/100, loss=1.4553 acc=0.3867\n",
      "epoch 5, train 12/100, loss=1.5188 acc=0.3600\n",
      "epoch 5, train 13/100, loss=1.0951 acc=0.6000\n",
      "epoch 5, train 14/100, loss=1.2857 acc=0.5467\n",
      "epoch 5, train 15/100, loss=1.1700 acc=0.4933\n",
      "epoch 5, train 16/100, loss=1.1562 acc=0.5467\n",
      "epoch 5, train 17/100, loss=1.3210 acc=0.4133\n",
      "epoch 5, train 18/100, loss=0.6636 acc=0.7200\n",
      "epoch 5, train 19/100, loss=1.2474 acc=0.5067\n",
      "epoch 5, train 20/100, loss=1.2163 acc=0.4267\n",
      "epoch 5, train 21/100, loss=1.5291 acc=0.4000\n",
      "epoch 5, train 22/100, loss=1.1060 acc=0.6267\n",
      "epoch 5, train 23/100, loss=1.2320 acc=0.5467\n",
      "epoch 5, train 24/100, loss=1.4171 acc=0.4000\n",
      "epoch 5, train 25/100, loss=1.2164 acc=0.4667\n",
      "epoch 5, train 26/100, loss=1.0817 acc=0.5733\n",
      "epoch 5, train 27/100, loss=0.9359 acc=0.5867\n",
      "epoch 5, train 28/100, loss=1.1588 acc=0.5200\n",
      "epoch 5, train 29/100, loss=1.0698 acc=0.6000\n",
      "epoch 5, train 30/100, loss=1.8531 acc=0.3733\n",
      "epoch 5, train 31/100, loss=1.6370 acc=0.3867\n",
      "epoch 5, train 32/100, loss=1.0219 acc=0.6933\n",
      "epoch 5, train 33/100, loss=0.6875 acc=0.7467\n",
      "epoch 5, train 34/100, loss=1.0439 acc=0.5733\n",
      "epoch 5, train 35/100, loss=0.9264 acc=0.6000\n",
      "epoch 5, train 36/100, loss=1.5365 acc=0.5333\n",
      "epoch 5, train 37/100, loss=1.5551 acc=0.2933\n",
      "epoch 5, train 38/100, loss=1.3740 acc=0.5067\n",
      "epoch 5, train 39/100, loss=1.2612 acc=0.4267\n",
      "epoch 5, train 40/100, loss=1.2782 acc=0.4800\n",
      "epoch 5, train 41/100, loss=1.2964 acc=0.4933\n",
      "epoch 5, train 42/100, loss=0.8972 acc=0.7733\n",
      "epoch 5, train 43/100, loss=1.4458 acc=0.4267\n",
      "epoch 5, train 44/100, loss=1.2121 acc=0.5200\n",
      "epoch 5, train 45/100, loss=1.5002 acc=0.3600\n",
      "epoch 5, train 46/100, loss=1.1429 acc=0.5067\n",
      "epoch 5, train 47/100, loss=0.9412 acc=0.5867\n",
      "epoch 5, train 48/100, loss=1.1509 acc=0.5467\n",
      "epoch 5, train 49/100, loss=1.3716 acc=0.4533\n",
      "epoch 5, train 50/100, loss=1.4162 acc=0.4000\n",
      "epoch 5, train 51/100, loss=0.9313 acc=0.7200\n",
      "epoch 5, train 52/100, loss=1.1119 acc=0.5333\n",
      "epoch 5, train 53/100, loss=1.3870 acc=0.3733\n",
      "epoch 5, train 54/100, loss=0.9142 acc=0.7200\n",
      "epoch 5, train 55/100, loss=0.8944 acc=0.6667\n",
      "epoch 5, train 56/100, loss=1.3741 acc=0.4933\n",
      "epoch 5, train 57/100, loss=0.6211 acc=0.8400\n",
      "epoch 5, train 58/100, loss=1.5611 acc=0.3067\n",
      "epoch 5, train 59/100, loss=0.8367 acc=0.7067\n",
      "epoch 5, train 60/100, loss=1.5847 acc=0.4400\n",
      "epoch 5, train 61/100, loss=1.2659 acc=0.4133\n",
      "epoch 5, train 62/100, loss=0.5328 acc=0.8400\n",
      "epoch 5, train 63/100, loss=1.4910 acc=0.4400\n",
      "epoch 5, train 64/100, loss=0.8617 acc=0.6533\n",
      "epoch 5, train 65/100, loss=1.3030 acc=0.4667\n",
      "epoch 5, train 66/100, loss=1.0389 acc=0.6133\n",
      "epoch 5, train 67/100, loss=1.1265 acc=0.6400\n",
      "epoch 5, train 68/100, loss=1.3312 acc=0.4400\n",
      "epoch 5, train 69/100, loss=1.2616 acc=0.4667\n",
      "epoch 5, train 70/100, loss=0.9702 acc=0.5200\n",
      "epoch 5, train 71/100, loss=1.1552 acc=0.5200\n",
      "epoch 5, train 72/100, loss=1.1621 acc=0.5733\n",
      "epoch 5, train 73/100, loss=1.3025 acc=0.4800\n",
      "epoch 5, train 74/100, loss=1.6230 acc=0.3467\n",
      "epoch 5, train 75/100, loss=1.5116 acc=0.3733\n",
      "epoch 5, train 76/100, loss=1.3191 acc=0.4400\n",
      "epoch 5, train 77/100, loss=1.3132 acc=0.5067\n",
      "epoch 5, train 78/100, loss=1.1967 acc=0.5067\n",
      "epoch 5, train 79/100, loss=1.1606 acc=0.5600\n",
      "epoch 5, train 80/100, loss=1.0773 acc=0.6000\n",
      "epoch 5, train 81/100, loss=1.3117 acc=0.4533\n",
      "epoch 5, train 82/100, loss=0.9263 acc=0.5867\n",
      "epoch 5, train 83/100, loss=1.0073 acc=0.5467\n",
      "epoch 5, train 84/100, loss=0.8152 acc=0.6667\n",
      "epoch 5, train 85/100, loss=1.1908 acc=0.5200\n",
      "epoch 5, train 86/100, loss=1.2093 acc=0.5067\n",
      "epoch 5, train 87/100, loss=0.9502 acc=0.6800\n",
      "epoch 5, train 88/100, loss=1.1257 acc=0.6000\n",
      "epoch 5, train 89/100, loss=1.5624 acc=0.3467\n",
      "epoch 5, train 90/100, loss=0.9332 acc=0.6667\n",
      "epoch 5, train 91/100, loss=0.7359 acc=0.7067\n",
      "epoch 5, train 92/100, loss=1.4204 acc=0.5200\n",
      "epoch 5, train 93/100, loss=0.9855 acc=0.5733\n",
      "epoch 5, train 94/100, loss=0.9689 acc=0.6400\n",
      "epoch 5, train 95/100, loss=1.2174 acc=0.5067\n",
      "epoch 5, train 96/100, loss=0.9522 acc=0.6000\n",
      "epoch 5, train 97/100, loss=1.0061 acc=0.6000\n",
      "epoch 5, train 98/100, loss=1.3847 acc=0.4667\n",
      "epoch 5, train 99/100, loss=1.0290 acc=0.6000\n",
      "epoch 5, train 100/100, loss=1.4668 acc=0.4000\n",
      "best epoch 4, best val acc=0.4971\n",
      "epoch 5, val, loss=1.1931 acc=0.5165\n",
      "ETA:28m/56m\n",
      "epoch 6, train 1/100, loss=1.3908 acc=0.4667\n",
      "epoch 6, train 2/100, loss=1.2244 acc=0.5067\n",
      "epoch 6, train 3/100, loss=1.3807 acc=0.4133\n",
      "epoch 6, train 4/100, loss=1.1199 acc=0.5200\n",
      "epoch 6, train 5/100, loss=0.6999 acc=0.7600\n",
      "epoch 6, train 6/100, loss=1.0645 acc=0.6400\n",
      "epoch 6, train 7/100, loss=1.5531 acc=0.3467\n",
      "epoch 6, train 8/100, loss=0.8913 acc=0.6933\n",
      "epoch 6, train 9/100, loss=0.5787 acc=0.7733\n",
      "epoch 6, train 10/100, loss=0.6755 acc=0.7467\n",
      "epoch 6, train 11/100, loss=1.6626 acc=0.2800\n",
      "epoch 6, train 12/100, loss=1.4240 acc=0.4267\n",
      "epoch 6, train 13/100, loss=1.1860 acc=0.4933\n",
      "epoch 6, train 14/100, loss=0.9720 acc=0.5467\n",
      "epoch 6, train 15/100, loss=1.3514 acc=0.4000\n",
      "epoch 6, train 16/100, loss=1.2377 acc=0.4267\n",
      "epoch 6, train 17/100, loss=0.8849 acc=0.5733\n",
      "epoch 6, train 18/100, loss=0.8178 acc=0.6933\n",
      "epoch 6, train 19/100, loss=1.0329 acc=0.6133\n",
      "epoch 6, train 20/100, loss=0.7569 acc=0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train 21/100, loss=0.8490 acc=0.6533\n",
      "epoch 6, train 22/100, loss=1.1216 acc=0.5333\n",
      "epoch 6, train 23/100, loss=1.0395 acc=0.5467\n",
      "epoch 6, train 24/100, loss=1.1416 acc=0.5467\n",
      "epoch 6, train 25/100, loss=1.1694 acc=0.5333\n",
      "epoch 6, train 26/100, loss=1.3531 acc=0.4933\n",
      "epoch 6, train 27/100, loss=1.3680 acc=0.4533\n",
      "epoch 6, train 28/100, loss=1.0688 acc=0.6000\n",
      "epoch 6, train 29/100, loss=1.5159 acc=0.3733\n",
      "epoch 6, train 30/100, loss=0.6392 acc=0.8133\n",
      "epoch 6, train 31/100, loss=1.4312 acc=0.3867\n",
      "epoch 6, train 32/100, loss=1.0434 acc=0.5600\n",
      "epoch 6, train 33/100, loss=1.3183 acc=0.4933\n",
      "epoch 6, train 34/100, loss=1.4714 acc=0.3867\n",
      "epoch 6, train 35/100, loss=1.3083 acc=0.4800\n",
      "epoch 6, train 36/100, loss=1.3520 acc=0.4667\n",
      "epoch 6, train 37/100, loss=1.4046 acc=0.4133\n",
      "epoch 6, train 38/100, loss=1.4850 acc=0.3600\n",
      "epoch 6, train 39/100, loss=1.4123 acc=0.4400\n",
      "epoch 6, train 40/100, loss=1.3375 acc=0.5333\n",
      "epoch 6, train 41/100, loss=1.2950 acc=0.4133\n",
      "epoch 6, train 42/100, loss=1.0336 acc=0.6000\n",
      "epoch 6, train 43/100, loss=1.4682 acc=0.3600\n",
      "epoch 6, train 44/100, loss=1.1452 acc=0.5200\n",
      "epoch 6, train 45/100, loss=1.1293 acc=0.5867\n",
      "epoch 6, train 46/100, loss=1.3323 acc=0.4667\n",
      "epoch 6, train 47/100, loss=1.2451 acc=0.4800\n",
      "epoch 6, train 48/100, loss=1.6322 acc=0.3467\n",
      "epoch 6, train 49/100, loss=0.9115 acc=0.6400\n",
      "epoch 6, train 50/100, loss=0.5720 acc=0.7867\n",
      "epoch 6, train 51/100, loss=0.9661 acc=0.6133\n",
      "epoch 6, train 52/100, loss=1.2643 acc=0.4533\n",
      "epoch 6, train 53/100, loss=0.7217 acc=0.6667\n",
      "epoch 6, train 54/100, loss=0.7761 acc=0.6000\n",
      "epoch 6, train 55/100, loss=1.6599 acc=0.3200\n",
      "epoch 6, train 56/100, loss=0.9892 acc=0.6267\n",
      "epoch 6, train 57/100, loss=1.1335 acc=0.6533\n",
      "epoch 6, train 58/100, loss=1.6275 acc=0.3467\n",
      "epoch 6, train 59/100, loss=1.7529 acc=0.3200\n",
      "epoch 6, train 60/100, loss=1.0655 acc=0.5333\n",
      "epoch 6, train 61/100, loss=1.2820 acc=0.4800\n",
      "epoch 6, train 62/100, loss=0.9570 acc=0.6667\n",
      "epoch 6, train 63/100, loss=1.2697 acc=0.4267\n",
      "epoch 6, train 64/100, loss=0.9003 acc=0.5733\n",
      "epoch 6, train 65/100, loss=1.3032 acc=0.4533\n",
      "epoch 6, train 66/100, loss=0.9787 acc=0.5867\n",
      "epoch 6, train 67/100, loss=1.1243 acc=0.4933\n",
      "epoch 6, train 68/100, loss=1.0547 acc=0.5867\n",
      "epoch 6, train 69/100, loss=0.7494 acc=0.7067\n",
      "epoch 6, train 70/100, loss=1.0945 acc=0.5733\n",
      "epoch 6, train 71/100, loss=0.5620 acc=0.8267\n",
      "epoch 6, train 72/100, loss=0.7407 acc=0.7733\n",
      "epoch 6, train 73/100, loss=1.1878 acc=0.4400\n",
      "epoch 6, train 74/100, loss=1.1974 acc=0.4667\n",
      "epoch 6, train 75/100, loss=0.9196 acc=0.6667\n",
      "epoch 6, train 76/100, loss=0.9687 acc=0.5733\n",
      "epoch 6, train 77/100, loss=1.0595 acc=0.5733\n",
      "epoch 6, train 78/100, loss=1.0820 acc=0.5067\n",
      "epoch 6, train 79/100, loss=1.5251 acc=0.4533\n",
      "epoch 6, train 80/100, loss=1.2801 acc=0.5067\n",
      "epoch 6, train 81/100, loss=1.4535 acc=0.3733\n",
      "epoch 6, train 82/100, loss=1.4016 acc=0.4267\n",
      "epoch 6, train 83/100, loss=0.8947 acc=0.6267\n",
      "epoch 6, train 84/100, loss=0.6620 acc=0.7333\n",
      "epoch 6, train 85/100, loss=0.9150 acc=0.6000\n",
      "epoch 6, train 86/100, loss=1.0388 acc=0.5067\n",
      "epoch 6, train 87/100, loss=1.0392 acc=0.6000\n",
      "epoch 6, train 88/100, loss=1.0016 acc=0.6000\n",
      "epoch 6, train 89/100, loss=1.3208 acc=0.4400\n",
      "epoch 6, train 90/100, loss=0.9564 acc=0.6667\n",
      "epoch 6, train 91/100, loss=1.2229 acc=0.4667\n",
      "epoch 6, train 92/100, loss=1.1290 acc=0.5600\n",
      "epoch 6, train 93/100, loss=1.0162 acc=0.5733\n",
      "epoch 6, train 94/100, loss=1.2920 acc=0.4400\n",
      "epoch 6, train 95/100, loss=0.9679 acc=0.6400\n",
      "epoch 6, train 96/100, loss=1.2043 acc=0.4400\n",
      "epoch 6, train 97/100, loss=1.4267 acc=0.3333\n",
      "epoch 6, train 98/100, loss=0.8663 acc=0.5867\n",
      "epoch 6, train 99/100, loss=0.9106 acc=0.6533\n",
      "epoch 6, train 100/100, loss=1.6728 acc=0.2933\n",
      "best epoch 5, best val acc=0.5165\n",
      "epoch 6, val, loss=1.1598 acc=0.5304\n",
      "ETA:34m/56m\n",
      "epoch 7, train 1/100, loss=1.0494 acc=0.5200\n",
      "epoch 7, train 2/100, loss=1.3250 acc=0.4667\n",
      "epoch 7, train 3/100, loss=1.2243 acc=0.4533\n",
      "epoch 7, train 4/100, loss=1.1507 acc=0.5600\n",
      "epoch 7, train 5/100, loss=1.5681 acc=0.3600\n",
      "epoch 7, train 6/100, loss=1.2878 acc=0.5600\n",
      "epoch 7, train 7/100, loss=0.9586 acc=0.6133\n",
      "epoch 7, train 8/100, loss=1.7298 acc=0.2667\n",
      "epoch 7, train 9/100, loss=1.6203 acc=0.2667\n",
      "epoch 7, train 10/100, loss=1.5589 acc=0.3467\n",
      "epoch 7, train 11/100, loss=0.5637 acc=0.8000\n",
      "epoch 7, train 12/100, loss=1.1636 acc=0.4800\n",
      "epoch 7, train 13/100, loss=1.0716 acc=0.6000\n",
      "epoch 7, train 14/100, loss=1.1942 acc=0.6000\n",
      "epoch 7, train 15/100, loss=0.9410 acc=0.6933\n",
      "epoch 7, train 16/100, loss=1.2652 acc=0.5600\n",
      "epoch 7, train 17/100, loss=0.9573 acc=0.5733\n",
      "epoch 7, train 18/100, loss=0.7810 acc=0.7733\n",
      "epoch 7, train 19/100, loss=1.0953 acc=0.5467\n",
      "epoch 7, train 20/100, loss=1.2261 acc=0.4533\n",
      "epoch 7, train 21/100, loss=1.2662 acc=0.4267\n",
      "epoch 7, train 22/100, loss=0.7292 acc=0.7200\n",
      "epoch 7, train 23/100, loss=1.4166 acc=0.3733\n",
      "epoch 7, train 24/100, loss=1.1126 acc=0.5867\n",
      "epoch 7, train 25/100, loss=1.2181 acc=0.4667\n",
      "epoch 7, train 26/100, loss=1.1822 acc=0.4533\n",
      "epoch 7, train 27/100, loss=0.8059 acc=0.6933\n",
      "epoch 7, train 28/100, loss=0.8588 acc=0.6133\n",
      "epoch 7, train 29/100, loss=0.9365 acc=0.6400\n",
      "epoch 7, train 30/100, loss=0.7461 acc=0.7067\n",
      "epoch 7, train 31/100, loss=1.4569 acc=0.4000\n",
      "epoch 7, train 32/100, loss=0.8058 acc=0.6000\n",
      "epoch 7, train 33/100, loss=1.1385 acc=0.5333\n",
      "epoch 7, train 34/100, loss=1.3290 acc=0.4933\n",
      "epoch 7, train 35/100, loss=1.2380 acc=0.5867\n",
      "epoch 7, train 36/100, loss=1.1457 acc=0.6133\n",
      "epoch 7, train 37/100, loss=0.9123 acc=0.6533\n",
      "epoch 7, train 38/100, loss=1.3622 acc=0.5067\n",
      "epoch 7, train 39/100, loss=1.0972 acc=0.4667\n",
      "epoch 7, train 40/100, loss=1.2365 acc=0.5067\n",
      "epoch 7, train 41/100, loss=1.1867 acc=0.5200\n",
      "epoch 7, train 42/100, loss=1.1114 acc=0.4667\n",
      "epoch 7, train 43/100, loss=0.8934 acc=0.6667\n",
      "epoch 7, train 44/100, loss=0.8181 acc=0.7067\n",
      "epoch 7, train 45/100, loss=0.8879 acc=0.7333\n",
      "epoch 7, train 46/100, loss=1.3260 acc=0.4933\n",
      "epoch 7, train 47/100, loss=0.7698 acc=0.6800\n",
      "epoch 7, train 48/100, loss=0.8309 acc=0.7067\n",
      "epoch 7, train 49/100, loss=1.1739 acc=0.5200\n",
      "epoch 7, train 50/100, loss=0.8192 acc=0.6533\n",
      "epoch 7, train 51/100, loss=1.0731 acc=0.5867\n",
      "epoch 7, train 52/100, loss=1.6102 acc=0.2533\n",
      "epoch 7, train 53/100, loss=0.7258 acc=0.7600\n",
      "epoch 7, train 54/100, loss=1.2147 acc=0.5333\n",
      "epoch 7, train 55/100, loss=0.8358 acc=0.6400\n",
      "epoch 7, train 56/100, loss=0.9174 acc=0.6267\n",
      "epoch 7, train 57/100, loss=1.3672 acc=0.4267\n",
      "epoch 7, train 58/100, loss=1.2652 acc=0.4933\n",
      "epoch 7, train 59/100, loss=0.5943 acc=0.8133\n",
      "epoch 7, train 60/100, loss=0.6860 acc=0.7333\n",
      "epoch 7, train 61/100, loss=0.8412 acc=0.5733\n",
      "epoch 7, train 62/100, loss=1.2773 acc=0.4667\n",
      "epoch 7, train 63/100, loss=0.6494 acc=0.8400\n",
      "epoch 7, train 64/100, loss=1.1638 acc=0.4667\n",
      "epoch 7, train 65/100, loss=0.5276 acc=0.7867\n",
      "epoch 7, train 66/100, loss=1.2035 acc=0.5200\n",
      "epoch 7, train 67/100, loss=0.9190 acc=0.6533\n",
      "epoch 7, train 68/100, loss=0.9155 acc=0.6533\n",
      "epoch 7, train 69/100, loss=1.2104 acc=0.4667\n",
      "epoch 7, train 70/100, loss=1.5205 acc=0.3733\n",
      "epoch 7, train 71/100, loss=1.0017 acc=0.5467\n",
      "epoch 7, train 72/100, loss=1.4570 acc=0.4267\n",
      "epoch 7, train 73/100, loss=0.9924 acc=0.5200\n",
      "epoch 7, train 74/100, loss=0.9394 acc=0.5467\n",
      "epoch 7, train 75/100, loss=1.2125 acc=0.4400\n",
      "epoch 7, train 76/100, loss=0.8739 acc=0.6267\n",
      "epoch 7, train 77/100, loss=1.4904 acc=0.4000\n",
      "epoch 7, train 78/100, loss=1.2379 acc=0.3600\n",
      "epoch 7, train 79/100, loss=1.3225 acc=0.4933\n",
      "epoch 7, train 80/100, loss=0.9465 acc=0.6667\n",
      "epoch 7, train 81/100, loss=0.8895 acc=0.6400\n",
      "epoch 7, train 82/100, loss=0.8959 acc=0.6267\n",
      "epoch 7, train 83/100, loss=0.8264 acc=0.6267\n",
      "epoch 7, train 84/100, loss=0.9355 acc=0.6267\n",
      "epoch 7, train 85/100, loss=1.2875 acc=0.4667\n",
      "epoch 7, train 86/100, loss=1.0641 acc=0.5867\n",
      "epoch 7, train 87/100, loss=1.3383 acc=0.5067\n",
      "epoch 7, train 88/100, loss=1.2335 acc=0.4400\n",
      "epoch 7, train 89/100, loss=1.1087 acc=0.6000\n",
      "epoch 7, train 90/100, loss=1.6903 acc=0.2933\n",
      "epoch 7, train 91/100, loss=1.5013 acc=0.3200\n",
      "epoch 7, train 92/100, loss=1.2074 acc=0.5067\n",
      "epoch 7, train 93/100, loss=1.4941 acc=0.3600\n",
      "epoch 7, train 94/100, loss=1.1767 acc=0.5333\n",
      "epoch 7, train 95/100, loss=1.2464 acc=0.5067\n",
      "epoch 7, train 96/100, loss=0.5470 acc=0.8000\n",
      "epoch 7, train 97/100, loss=1.1436 acc=0.4400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train 98/100, loss=1.2453 acc=0.4800\n",
      "epoch 7, train 99/100, loss=0.8838 acc=0.5867\n",
      "epoch 7, train 100/100, loss=1.0487 acc=0.5467\n",
      "best epoch 6, best val acc=0.5304\n",
      "epoch 7, val, loss=1.1599 acc=0.5340\n",
      "ETA:40m/57m\n",
      "epoch 8, train 1/100, loss=1.1269 acc=0.5867\n",
      "epoch 8, train 2/100, loss=1.2182 acc=0.5333\n",
      "epoch 8, train 3/100, loss=1.1964 acc=0.4800\n",
      "epoch 8, train 4/100, loss=0.9467 acc=0.5867\n",
      "epoch 8, train 5/100, loss=1.1781 acc=0.5067\n",
      "epoch 8, train 6/100, loss=0.9562 acc=0.5733\n",
      "epoch 8, train 7/100, loss=1.4088 acc=0.3600\n",
      "epoch 8, train 8/100, loss=1.0380 acc=0.5867\n",
      "epoch 8, train 9/100, loss=1.1437 acc=0.5067\n",
      "epoch 8, train 10/100, loss=1.5172 acc=0.3200\n",
      "epoch 8, train 11/100, loss=1.0448 acc=0.6133\n",
      "epoch 8, train 12/100, loss=1.1561 acc=0.4533\n",
      "epoch 8, train 13/100, loss=0.8241 acc=0.6933\n",
      "epoch 8, train 14/100, loss=1.1713 acc=0.4667\n",
      "epoch 8, train 15/100, loss=1.0495 acc=0.5600\n",
      "epoch 8, train 16/100, loss=1.5894 acc=0.3467\n",
      "epoch 8, train 17/100, loss=1.2450 acc=0.4800\n",
      "epoch 8, train 18/100, loss=0.4376 acc=0.8533\n",
      "epoch 8, train 19/100, loss=0.6942 acc=0.7067\n",
      "epoch 8, train 20/100, loss=1.7123 acc=0.2667\n",
      "epoch 8, train 21/100, loss=1.1920 acc=0.5333\n",
      "epoch 8, train 22/100, loss=1.2019 acc=0.4800\n",
      "epoch 8, train 23/100, loss=0.8390 acc=0.6667\n",
      "epoch 8, train 24/100, loss=0.7181 acc=0.7333\n",
      "epoch 8, train 25/100, loss=1.2011 acc=0.5200\n",
      "epoch 8, train 26/100, loss=1.1099 acc=0.6133\n",
      "epoch 8, train 27/100, loss=0.8807 acc=0.6000\n",
      "epoch 8, train 28/100, loss=1.1271 acc=0.5200\n",
      "epoch 8, train 29/100, loss=1.2269 acc=0.4800\n",
      "epoch 8, train 30/100, loss=1.0105 acc=0.5733\n",
      "epoch 8, train 31/100, loss=0.7480 acc=0.6933\n",
      "epoch 8, train 32/100, loss=1.3856 acc=0.5067\n",
      "epoch 8, train 33/100, loss=0.7630 acc=0.7067\n",
      "epoch 8, train 34/100, loss=1.2212 acc=0.5467\n",
      "epoch 8, train 35/100, loss=0.7788 acc=0.6800\n",
      "epoch 8, train 36/100, loss=0.6804 acc=0.7200\n",
      "epoch 8, train 37/100, loss=0.9200 acc=0.5867\n",
      "epoch 8, train 38/100, loss=1.0602 acc=0.5333\n",
      "epoch 8, train 39/100, loss=1.0223 acc=0.6533\n",
      "epoch 8, train 40/100, loss=0.7725 acc=0.6933\n",
      "epoch 8, train 41/100, loss=1.6213 acc=0.3733\n",
      "epoch 8, train 42/100, loss=0.9543 acc=0.6133\n",
      "epoch 8, train 43/100, loss=0.9132 acc=0.6533\n",
      "epoch 8, train 44/100, loss=0.7164 acc=0.6800\n",
      "epoch 8, train 45/100, loss=0.9288 acc=0.4933\n",
      "epoch 8, train 46/100, loss=1.2340 acc=0.4800\n",
      "epoch 8, train 47/100, loss=1.0172 acc=0.6267\n",
      "epoch 8, train 48/100, loss=1.1378 acc=0.4800\n",
      "epoch 8, train 49/100, loss=1.1885 acc=0.5733\n",
      "epoch 8, train 50/100, loss=0.6412 acc=0.8400\n",
      "epoch 8, train 51/100, loss=1.1970 acc=0.4800\n",
      "epoch 8, train 52/100, loss=0.9043 acc=0.6400\n",
      "epoch 8, train 53/100, loss=1.3837 acc=0.5467\n",
      "epoch 8, train 54/100, loss=0.9586 acc=0.6000\n",
      "epoch 8, train 55/100, loss=0.9683 acc=0.6000\n",
      "epoch 8, train 56/100, loss=1.0732 acc=0.6133\n",
      "epoch 8, train 57/100, loss=0.8189 acc=0.6533\n",
      "epoch 8, train 58/100, loss=0.9661 acc=0.6400\n",
      "epoch 8, train 59/100, loss=1.3721 acc=0.3600\n",
      "epoch 8, train 60/100, loss=1.1284 acc=0.5467\n",
      "epoch 8, train 61/100, loss=1.1515 acc=0.5200\n",
      "epoch 8, train 62/100, loss=0.9034 acc=0.6267\n",
      "epoch 8, train 63/100, loss=1.2039 acc=0.5200\n",
      "epoch 8, train 64/100, loss=1.3574 acc=0.3467\n",
      "epoch 8, train 65/100, loss=0.8992 acc=0.6400\n",
      "epoch 8, train 66/100, loss=1.3661 acc=0.4000\n",
      "epoch 8, train 67/100, loss=1.3826 acc=0.3867\n",
      "epoch 8, train 68/100, loss=1.0220 acc=0.6267\n",
      "epoch 8, train 69/100, loss=0.9404 acc=0.6533\n",
      "epoch 8, train 70/100, loss=1.2346 acc=0.5467\n",
      "epoch 8, train 71/100, loss=1.6271 acc=0.3733\n",
      "epoch 8, train 72/100, loss=0.8176 acc=0.7467\n",
      "epoch 8, train 73/100, loss=1.6559 acc=0.3333\n",
      "epoch 8, train 74/100, loss=0.8399 acc=0.7333\n",
      "epoch 8, train 75/100, loss=0.8086 acc=0.6400\n",
      "epoch 8, train 76/100, loss=1.3101 acc=0.4400\n",
      "epoch 8, train 77/100, loss=1.3683 acc=0.3733\n",
      "epoch 8, train 78/100, loss=0.9328 acc=0.6267\n",
      "epoch 8, train 79/100, loss=0.8331 acc=0.6800\n",
      "epoch 8, train 80/100, loss=0.8215 acc=0.7067\n",
      "epoch 8, train 81/100, loss=1.2847 acc=0.4933\n",
      "epoch 8, train 82/100, loss=1.1178 acc=0.6000\n",
      "epoch 8, train 83/100, loss=1.1226 acc=0.4800\n",
      "epoch 8, train 84/100, loss=1.5781 acc=0.3867\n",
      "epoch 8, train 85/100, loss=1.2928 acc=0.4933\n",
      "epoch 8, train 86/100, loss=0.8987 acc=0.5600\n",
      "epoch 8, train 87/100, loss=1.3264 acc=0.4000\n",
      "epoch 8, train 88/100, loss=1.4480 acc=0.3733\n",
      "epoch 8, train 89/100, loss=0.7522 acc=0.6667\n",
      "epoch 8, train 90/100, loss=0.7050 acc=0.7067\n",
      "epoch 8, train 91/100, loss=1.5451 acc=0.3467\n",
      "epoch 8, train 92/100, loss=1.4319 acc=0.4667\n",
      "epoch 8, train 93/100, loss=0.6672 acc=0.7467\n",
      "epoch 8, train 94/100, loss=1.7124 acc=0.4000\n",
      "epoch 8, train 95/100, loss=1.3363 acc=0.3600\n",
      "epoch 8, train 96/100, loss=0.6693 acc=0.7600\n",
      "epoch 8, train 97/100, loss=1.3584 acc=0.4800\n",
      "epoch 8, train 98/100, loss=0.7575 acc=0.6533\n",
      "epoch 8, train 99/100, loss=0.9232 acc=0.6267\n",
      "epoch 8, train 100/100, loss=1.1711 acc=0.5867\n",
      "best epoch 7, best val acc=0.5340\n",
      "epoch 8, val, loss=1.1293 acc=0.5468\n",
      "ETA:46m/57m\n",
      "epoch 9, train 1/100, loss=0.9148 acc=0.6667\n",
      "epoch 9, train 2/100, loss=1.1740 acc=0.4933\n",
      "epoch 9, train 3/100, loss=1.3449 acc=0.4667\n",
      "epoch 9, train 4/100, loss=1.0663 acc=0.6133\n",
      "epoch 9, train 5/100, loss=0.9200 acc=0.6400\n",
      "epoch 9, train 6/100, loss=1.0281 acc=0.5600\n",
      "epoch 9, train 7/100, loss=0.9154 acc=0.5733\n",
      "epoch 9, train 8/100, loss=1.2859 acc=0.4667\n",
      "epoch 9, train 9/100, loss=0.8656 acc=0.6133\n",
      "epoch 9, train 10/100, loss=1.2929 acc=0.4667\n",
      "epoch 9, train 11/100, loss=0.6309 acc=0.8000\n",
      "epoch 9, train 12/100, loss=0.7955 acc=0.7067\n",
      "epoch 9, train 13/100, loss=1.2427 acc=0.4800\n",
      "epoch 9, train 14/100, loss=1.4497 acc=0.4533\n",
      "epoch 9, train 15/100, loss=0.7749 acc=0.6400\n",
      "epoch 9, train 16/100, loss=0.7987 acc=0.6800\n",
      "epoch 9, train 17/100, loss=0.9472 acc=0.7067\n",
      "epoch 9, train 18/100, loss=0.9573 acc=0.6267\n",
      "epoch 9, train 19/100, loss=1.2633 acc=0.3867\n",
      "epoch 9, train 20/100, loss=0.5531 acc=0.8133\n",
      "epoch 9, train 21/100, loss=1.3269 acc=0.3467\n",
      "epoch 9, train 22/100, loss=0.7841 acc=0.6533\n",
      "epoch 9, train 23/100, loss=1.8753 acc=0.3600\n",
      "epoch 9, train 24/100, loss=0.8815 acc=0.6267\n",
      "epoch 9, train 25/100, loss=1.0901 acc=0.4133\n",
      "epoch 9, train 26/100, loss=1.0106 acc=0.5600\n",
      "epoch 9, train 27/100, loss=1.1406 acc=0.5467\n",
      "epoch 9, train 28/100, loss=0.8737 acc=0.6267\n",
      "epoch 9, train 29/100, loss=1.5292 acc=0.3200\n",
      "epoch 9, train 30/100, loss=0.6400 acc=0.7867\n",
      "epoch 9, train 31/100, loss=1.1076 acc=0.4933\n",
      "epoch 9, train 32/100, loss=1.0854 acc=0.5867\n",
      "epoch 9, train 33/100, loss=1.2080 acc=0.5467\n",
      "epoch 9, train 34/100, loss=1.2391 acc=0.5600\n",
      "epoch 9, train 35/100, loss=0.8955 acc=0.6400\n",
      "epoch 9, train 36/100, loss=0.9184 acc=0.6667\n",
      "epoch 9, train 37/100, loss=1.2586 acc=0.4800\n",
      "epoch 9, train 38/100, loss=1.2782 acc=0.4533\n",
      "epoch 9, train 39/100, loss=1.1378 acc=0.4933\n",
      "epoch 9, train 40/100, loss=1.3722 acc=0.4800\n",
      "epoch 9, train 41/100, loss=0.9028 acc=0.6000\n",
      "epoch 9, train 42/100, loss=0.9684 acc=0.6533\n",
      "epoch 9, train 43/100, loss=1.0792 acc=0.5600\n",
      "epoch 9, train 44/100, loss=1.2774 acc=0.4400\n",
      "epoch 9, train 45/100, loss=1.3438 acc=0.4400\n",
      "epoch 9, train 46/100, loss=1.4170 acc=0.4000\n",
      "epoch 9, train 47/100, loss=1.0120 acc=0.5200\n",
      "epoch 9, train 48/100, loss=1.2383 acc=0.5200\n",
      "epoch 9, train 49/100, loss=1.1022 acc=0.4667\n",
      "epoch 9, train 50/100, loss=1.1781 acc=0.5867\n",
      "epoch 9, train 51/100, loss=1.2082 acc=0.5200\n",
      "epoch 9, train 52/100, loss=0.9481 acc=0.5200\n",
      "epoch 9, train 53/100, loss=1.2423 acc=0.5733\n",
      "epoch 9, train 54/100, loss=0.8859 acc=0.6800\n",
      "epoch 9, train 55/100, loss=0.8459 acc=0.7333\n",
      "epoch 9, train 56/100, loss=1.5131 acc=0.2667\n",
      "epoch 9, train 57/100, loss=0.8357 acc=0.6400\n",
      "epoch 9, train 58/100, loss=1.2488 acc=0.5333\n",
      "epoch 9, train 59/100, loss=1.1822 acc=0.5467\n",
      "epoch 9, train 60/100, loss=1.1459 acc=0.6133\n",
      "epoch 9, train 61/100, loss=1.1080 acc=0.5867\n",
      "epoch 9, train 62/100, loss=1.0858 acc=0.5733\n",
      "epoch 9, train 63/100, loss=1.3752 acc=0.4800\n",
      "epoch 9, train 64/100, loss=0.9795 acc=0.5733\n",
      "epoch 9, train 65/100, loss=1.0750 acc=0.5467\n",
      "epoch 9, train 66/100, loss=0.7582 acc=0.6933\n",
      "epoch 9, train 67/100, loss=1.0624 acc=0.5333\n",
      "epoch 9, train 68/100, loss=0.9768 acc=0.6400\n",
      "epoch 9, train 69/100, loss=1.4520 acc=0.4267\n",
      "epoch 9, train 70/100, loss=0.6215 acc=0.7867\n",
      "epoch 9, train 71/100, loss=0.8643 acc=0.6933\n",
      "epoch 9, train 72/100, loss=1.0414 acc=0.5867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train 73/100, loss=1.2527 acc=0.4667\n",
      "epoch 9, train 74/100, loss=0.8226 acc=0.7733\n",
      "epoch 9, train 75/100, loss=1.1883 acc=0.4000\n",
      "epoch 9, train 76/100, loss=1.4741 acc=0.4267\n",
      "epoch 9, train 77/100, loss=1.2772 acc=0.5067\n",
      "epoch 9, train 78/100, loss=0.7768 acc=0.6533\n",
      "epoch 9, train 79/100, loss=1.0700 acc=0.6800\n",
      "epoch 9, train 80/100, loss=1.0621 acc=0.5467\n",
      "epoch 9, train 81/100, loss=1.1039 acc=0.4800\n",
      "epoch 9, train 82/100, loss=0.5917 acc=0.7867\n",
      "epoch 9, train 83/100, loss=0.6464 acc=0.7600\n",
      "epoch 9, train 84/100, loss=1.2221 acc=0.4933\n",
      "epoch 9, train 85/100, loss=1.3147 acc=0.5067\n",
      "epoch 9, train 86/100, loss=1.4608 acc=0.3600\n",
      "epoch 9, train 87/100, loss=1.1604 acc=0.4667\n",
      "epoch 9, train 88/100, loss=1.2899 acc=0.4400\n",
      "epoch 9, train 89/100, loss=1.5387 acc=0.3600\n",
      "epoch 9, train 90/100, loss=0.9204 acc=0.6933\n",
      "epoch 9, train 91/100, loss=1.2165 acc=0.4933\n",
      "epoch 9, train 92/100, loss=1.0615 acc=0.6000\n",
      "epoch 9, train 93/100, loss=1.0304 acc=0.5467\n",
      "epoch 9, train 94/100, loss=1.1914 acc=0.5467\n",
      "epoch 9, train 95/100, loss=0.6650 acc=0.7067\n",
      "epoch 9, train 96/100, loss=1.2472 acc=0.4400\n",
      "epoch 9, train 97/100, loss=1.5286 acc=0.4000\n",
      "epoch 9, train 98/100, loss=1.0818 acc=0.6000\n",
      "epoch 9, train 99/100, loss=0.6697 acc=0.8133\n",
      "epoch 9, train 100/100, loss=0.9333 acc=0.6800\n",
      "best epoch 8, best val acc=0.5468\n",
      "epoch 9, val, loss=1.0924 acc=0.5683\n",
      "ETA:55m/1.0h\n",
      "epoch 10, train 1/100, loss=1.0399 acc=0.5067\n",
      "epoch 10, train 2/100, loss=1.5537 acc=0.4267\n",
      "epoch 10, train 3/100, loss=1.4403 acc=0.4000\n",
      "epoch 10, train 4/100, loss=0.7821 acc=0.6667\n",
      "epoch 10, train 5/100, loss=0.8966 acc=0.6533\n",
      "epoch 10, train 6/100, loss=0.8837 acc=0.6000\n",
      "epoch 10, train 7/100, loss=1.2764 acc=0.4533\n",
      "epoch 10, train 8/100, loss=0.8768 acc=0.6800\n",
      "epoch 10, train 9/100, loss=1.1701 acc=0.5067\n",
      "epoch 10, train 10/100, loss=0.9388 acc=0.6933\n",
      "epoch 10, train 11/100, loss=1.6202 acc=0.4533\n",
      "epoch 10, train 12/100, loss=0.7749 acc=0.7467\n",
      "epoch 10, train 13/100, loss=0.5191 acc=0.8267\n",
      "epoch 10, train 14/100, loss=0.6031 acc=0.7467\n",
      "epoch 10, train 15/100, loss=1.2433 acc=0.5067\n",
      "epoch 10, train 16/100, loss=0.8569 acc=0.6133\n",
      "epoch 10, train 17/100, loss=1.2246 acc=0.5067\n",
      "epoch 10, train 18/100, loss=1.0003 acc=0.5600\n",
      "epoch 10, train 19/100, loss=0.7137 acc=0.6933\n",
      "epoch 10, train 20/100, loss=0.6321 acc=0.7467\n",
      "epoch 10, train 21/100, loss=0.3130 acc=0.9067\n",
      "epoch 10, train 22/100, loss=0.5293 acc=0.8267\n",
      "epoch 10, train 23/100, loss=0.9407 acc=0.6533\n",
      "epoch 10, train 24/100, loss=0.8005 acc=0.7067\n",
      "epoch 10, train 25/100, loss=1.1612 acc=0.5333\n",
      "epoch 10, train 26/100, loss=1.1031 acc=0.5600\n",
      "epoch 10, train 27/100, loss=1.3469 acc=0.4400\n",
      "epoch 10, train 28/100, loss=1.0536 acc=0.5333\n",
      "epoch 10, train 29/100, loss=1.0075 acc=0.6800\n",
      "epoch 10, train 30/100, loss=1.4173 acc=0.4933\n",
      "epoch 10, train 31/100, loss=0.9858 acc=0.5733\n",
      "epoch 10, train 32/100, loss=1.3339 acc=0.4000\n",
      "epoch 10, train 33/100, loss=0.9960 acc=0.6133\n",
      "epoch 10, train 34/100, loss=1.1980 acc=0.5733\n",
      "epoch 10, train 35/100, loss=0.6467 acc=0.8267\n",
      "epoch 10, train 36/100, loss=1.0091 acc=0.5600\n",
      "epoch 10, train 37/100, loss=0.9113 acc=0.6667\n",
      "epoch 10, train 38/100, loss=0.9827 acc=0.5333\n",
      "epoch 10, train 39/100, loss=1.1699 acc=0.4933\n",
      "epoch 10, train 40/100, loss=1.3389 acc=0.3733\n",
      "epoch 10, train 41/100, loss=0.6598 acc=0.7733\n",
      "epoch 10, train 42/100, loss=0.6167 acc=0.6933\n",
      "epoch 10, train 43/100, loss=1.0945 acc=0.5333\n",
      "epoch 10, train 44/100, loss=0.7804 acc=0.6533\n",
      "epoch 10, train 45/100, loss=1.0692 acc=0.6000\n",
      "epoch 10, train 46/100, loss=1.0838 acc=0.5067\n",
      "epoch 10, train 47/100, loss=0.7733 acc=0.6667\n",
      "epoch 10, train 48/100, loss=0.8662 acc=0.6133\n",
      "epoch 10, train 49/100, loss=0.9793 acc=0.6267\n",
      "epoch 10, train 50/100, loss=0.5132 acc=0.8267\n",
      "epoch 10, train 51/100, loss=0.7005 acc=0.7867\n",
      "epoch 10, train 52/100, loss=1.7027 acc=0.3600\n",
      "epoch 10, train 53/100, loss=0.5825 acc=0.7333\n",
      "epoch 10, train 54/100, loss=1.1996 acc=0.3867\n",
      "epoch 10, train 55/100, loss=1.3375 acc=0.4000\n",
      "epoch 10, train 56/100, loss=0.8703 acc=0.6533\n",
      "epoch 10, train 57/100, loss=0.9782 acc=0.6267\n",
      "epoch 10, train 58/100, loss=0.8620 acc=0.6533\n",
      "epoch 10, train 59/100, loss=0.6571 acc=0.7733\n",
      "epoch 10, train 60/100, loss=0.9596 acc=0.5867\n",
      "epoch 10, train 61/100, loss=1.1265 acc=0.6133\n",
      "epoch 10, train 62/100, loss=1.1738 acc=0.4800\n",
      "epoch 10, train 63/100, loss=0.8035 acc=0.7067\n",
      "epoch 10, train 64/100, loss=1.2132 acc=0.4933\n",
      "epoch 10, train 65/100, loss=1.2488 acc=0.5067\n",
      "epoch 10, train 66/100, loss=0.9640 acc=0.6133\n",
      "epoch 10, train 67/100, loss=0.8635 acc=0.7067\n",
      "epoch 10, train 68/100, loss=0.8935 acc=0.6533\n",
      "epoch 10, train 69/100, loss=1.1814 acc=0.5200\n",
      "epoch 10, train 70/100, loss=0.8325 acc=0.6533\n",
      "epoch 10, train 71/100, loss=1.2206 acc=0.5067\n",
      "epoch 10, train 72/100, loss=1.1493 acc=0.5067\n",
      "epoch 10, train 73/100, loss=0.6976 acc=0.7067\n",
      "epoch 10, train 74/100, loss=0.6177 acc=0.8267\n",
      "epoch 10, train 75/100, loss=1.7109 acc=0.4667\n",
      "epoch 10, train 76/100, loss=1.0935 acc=0.5067\n",
      "epoch 10, train 77/100, loss=1.0041 acc=0.5333\n",
      "epoch 10, train 78/100, loss=0.8970 acc=0.6933\n",
      "epoch 10, train 79/100, loss=0.7489 acc=0.6267\n",
      "epoch 10, train 80/100, loss=0.7225 acc=0.7600\n",
      "epoch 10, train 81/100, loss=0.6217 acc=0.8000\n",
      "epoch 10, train 82/100, loss=1.1466 acc=0.5333\n",
      "epoch 10, train 83/100, loss=0.8144 acc=0.7200\n",
      "epoch 10, train 84/100, loss=0.8868 acc=0.6800\n",
      "epoch 10, train 85/100, loss=0.8790 acc=0.5867\n",
      "epoch 10, train 86/100, loss=1.4970 acc=0.4133\n",
      "epoch 10, train 87/100, loss=0.6567 acc=0.7600\n",
      "epoch 10, train 88/100, loss=0.4063 acc=0.8267\n",
      "epoch 10, train 89/100, loss=1.2787 acc=0.5200\n",
      "epoch 10, train 90/100, loss=1.0973 acc=0.4800\n",
      "epoch 10, train 91/100, loss=0.4588 acc=0.8133\n",
      "epoch 10, train 92/100, loss=1.1692 acc=0.5467\n",
      "epoch 10, train 93/100, loss=0.8293 acc=0.6667\n",
      "epoch 10, train 94/100, loss=1.1756 acc=0.4267\n",
      "epoch 10, train 95/100, loss=1.2306 acc=0.4400\n",
      "epoch 10, train 96/100, loss=1.1369 acc=0.5467\n",
      "epoch 10, train 97/100, loss=1.1406 acc=0.5867\n",
      "epoch 10, train 98/100, loss=0.8793 acc=0.7333\n",
      "epoch 10, train 99/100, loss=0.9801 acc=0.5600\n",
      "epoch 10, train 100/100, loss=1.0184 acc=0.6667\n",
      "best epoch 9, best val acc=0.5683\n",
      "epoch 10, val, loss=1.1313 acc=0.5500\n",
      "ETA:1.1h/1.1h\n",
      "batch 1: 56.00(56.00)\n",
      "batch 2: 60.67(65.33)\n",
      "batch 3: 56.44(48.00)\n",
      "batch 4: 56.00(54.67)\n",
      "batch 5: 50.93(30.67)\n",
      "batch 6: 50.67(49.33)\n",
      "batch 7: 52.95(66.67)\n",
      "batch 8: 55.33(72.00)\n",
      "batch 9: 56.00(61.33)\n",
      "batch 10: 54.67(42.67)\n",
      "batch 11: 55.64(65.33)\n",
      "batch 12: 56.22(62.67)\n",
      "batch 13: 55.69(49.33)\n",
      "batch 14: 54.57(40.00)\n",
      "batch 15: 54.49(53.33)\n",
      "batch 16: 54.17(49.33)\n",
      "batch 17: 52.63(28.00)\n",
      "batch 18: 51.85(38.67)\n",
      "batch 19: 52.28(60.00)\n",
      "batch 20: 51.67(40.00)\n",
      "batch 21: 51.49(48.00)\n",
      "batch 22: 51.27(46.67)\n",
      "batch 23: 51.42(54.67)\n",
      "batch 24: 51.22(46.67)\n",
      "batch 25: 51.15(49.33)\n",
      "batch 26: 50.77(41.33)\n",
      "batch 27: 50.52(44.00)\n",
      "batch 28: 51.05(65.33)\n",
      "batch 29: 51.40(61.33)\n",
      "batch 30: 50.84(34.67)\n",
      "batch 31: 50.06(26.67)\n",
      "batch 32: 50.63(68.00)\n",
      "batch 33: 50.79(56.00)\n",
      "batch 34: 51.29(68.00)\n",
      "batch 35: 51.58(61.33)\n",
      "batch 36: 51.89(62.67)\n",
      "batch 37: 51.57(40.00)\n",
      "batch 38: 51.68(56.00)\n",
      "batch 39: 51.56(46.67)\n",
      "batch 40: 51.20(37.33)\n",
      "batch 41: 51.45(61.33)\n",
      "batch 42: 51.40(49.33)\n",
      "batch 43: 51.60(60.00)\n",
      "batch 44: 51.82(61.33)\n",
      "batch 45: 51.56(40.00)\n",
      "batch 46: 51.74(60.00)\n",
      "batch 47: 51.63(46.67)\n",
      "batch 48: 51.67(53.33)\n",
      "batch 49: 51.76(56.00)\n",
      "batch 50: 51.47(37.33)\n",
      "batch 51: 51.87(72.00)\n",
      "batch 52: 51.92(54.67)\n",
      "batch 53: 52.15(64.00)\n",
      "batch 54: 52.10(49.33)\n",
      "batch 55: 51.88(40.00)\n",
      "batch 56: 51.62(37.33)\n",
      "batch 57: 51.27(32.00)\n",
      "batch 58: 51.31(53.33)\n",
      "batch 59: 51.68(73.33)\n",
      "batch 60: 51.73(54.67)\n",
      "batch 61: 51.43(33.33)\n",
      "batch 62: 51.46(53.33)\n",
      "batch 63: 51.17(33.33)\n",
      "batch 64: 51.25(56.00)\n",
      "batch 65: 51.34(57.33)\n",
      "batch 66: 51.49(61.33)\n",
      "batch 67: 51.66(62.67)\n",
      "batch 68: 51.82(62.67)\n",
      "batch 69: 52.04(66.67)\n",
      "batch 70: 51.96(46.67)\n",
      "batch 71: 52.09(61.33)\n",
      "batch 72: 51.98(44.00)\n",
      "batch 73: 52.00(53.33)\n",
      "batch 74: 51.98(50.67)\n",
      "batch 75: 51.95(49.33)\n",
      "batch 76: 51.89(48.00)\n",
      "batch 77: 52.02(61.33)\n",
      "batch 78: 51.85(38.67)\n",
      "batch 79: 51.95(60.00)\n",
      "batch 80: 51.83(42.67)\n",
      "batch 81: 51.75(45.33)\n",
      "batch 82: 51.71(48.00)\n",
      "batch 83: 51.79(58.67)\n",
      "batch 84: 52.00(69.33)\n",
      "batch 85: 52.00(52.00)\n",
      "batch 86: 51.80(34.67)\n",
      "batch 87: 51.88(58.67)\n",
      "batch 88: 51.91(54.67)\n",
      "batch 89: 52.10(69.33)\n",
      "batch 90: 51.94(37.33)\n",
      "batch 91: 51.79(38.67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 92: 51.77(49.33)\n",
      "batch 93: 51.81(56.00)\n",
      "batch 94: 51.70(41.33)\n",
      "batch 95: 51.78(58.67)\n",
      "batch 96: 52.00(73.33)\n",
      "batch 97: 52.14(65.33)\n",
      "batch 98: 52.15(53.33)\n",
      "batch 99: 52.13(50.67)\n",
      "batch 100: 51.96(34.67)\n",
      "batch 101: 51.96(52.00)\n",
      "batch 102: 51.86(41.33)\n",
      "batch 103: 51.79(45.33)\n",
      "batch 104: 51.82(54.67)\n",
      "batch 105: 51.96(66.67)\n",
      "batch 106: 51.96(52.00)\n",
      "batch 107: 51.86(41.33)\n",
      "batch 108: 52.09(76.00)\n",
      "batch 109: 52.13(57.33)\n",
      "batch 110: 52.24(64.00)\n",
      "batch 111: 52.34(62.67)\n",
      "batch 112: 52.37(56.00)\n",
      "batch 113: 52.42(58.67)\n",
      "batch 114: 52.41(50.67)\n",
      "batch 115: 52.45(57.33)\n",
      "batch 116: 52.37(42.67)\n",
      "batch 117: 52.33(48.00)\n",
      "batch 118: 52.34(53.33)\n",
      "batch 119: 52.30(48.00)\n",
      "batch 120: 52.29(50.67)\n",
      "batch 121: 52.35(60.00)\n",
      "batch 122: 52.22(36.00)\n",
      "batch 123: 52.22(52.00)\n",
      "batch 124: 52.20(50.67)\n",
      "batch 125: 52.21(53.33)\n",
      "batch 126: 52.25(57.33)\n",
      "batch 127: 52.08(30.67)\n",
      "batch 128: 51.90(28.00)\n",
      "batch 129: 51.91(53.33)\n",
      "batch 130: 51.85(44.00)\n",
      "batch 131: 51.84(50.67)\n",
      "batch 132: 51.76(41.33)\n",
      "batch 133: 51.85(64.00)\n",
      "batch 134: 51.76(40.00)\n",
      "batch 135: 51.90(70.67)\n",
      "batch 136: 52.03(69.33)\n",
      "batch 137: 51.85(28.00)\n",
      "batch 138: 51.86(52.00)\n",
      "batch 139: 51.88(56.00)\n",
      "batch 140: 51.76(34.67)\n",
      "batch 141: 51.86(65.33)\n",
      "batch 142: 51.83(48.00)\n",
      "batch 143: 51.93(66.67)\n",
      "batch 144: 51.92(49.33)\n",
      "batch 145: 52.03(68.00)\n",
      "batch 146: 52.03(52.00)\n",
      "batch 147: 52.12(65.33)\n",
      "batch 148: 52.00(34.67)\n",
      "batch 149: 51.99(50.67)\n",
      "batch 150: 51.91(40.00)\n",
      "batch 151: 51.99(64.00)\n",
      "batch 152: 51.87(33.33)\n",
      "batch 153: 51.84(48.00)\n",
      "batch 154: 51.75(37.33)\n",
      "batch 155: 51.77(54.67)\n",
      "batch 156: 51.66(34.67)\n",
      "batch 157: 51.60(42.67)\n",
      "batch 158: 51.54(42.67)\n",
      "batch 159: 51.61(62.67)\n",
      "batch 160: 51.55(41.33)\n",
      "batch 161: 51.49(41.33)\n",
      "batch 162: 51.47(49.33)\n",
      "batch 163: 51.53(60.00)\n",
      "batch 164: 51.70(80.00)\n",
      "batch 165: 51.64(41.33)\n",
      "batch 166: 51.69(60.00)\n",
      "batch 167: 51.61(38.67)\n",
      "batch 168: 51.67(62.67)\n",
      "batch 169: 51.64(46.67)\n",
      "batch 170: 51.52(30.67)\n",
      "batch 171: 51.57(60.00)\n",
      "batch 172: 51.55(48.00)\n",
      "batch 173: 51.45(34.67)\n",
      "batch 174: 51.56(70.67)\n",
      "batch 175: 51.64(65.33)\n",
      "batch 176: 51.62(48.00)\n",
      "batch 177: 51.80(82.67)\n",
      "batch 178: 51.81(53.33)\n",
      "batch 179: 51.75(42.67)\n",
      "batch 180: 51.90(77.33)\n",
      "batch 181: 51.90(53.33)\n",
      "batch 182: 51.88(48.00)\n",
      "batch 183: 51.86(48.00)\n",
      "batch 184: 51.88(54.67)\n",
      "batch 185: 51.86(49.33)\n",
      "batch 186: 51.81(41.33)\n",
      "batch 187: 51.67(26.67)\n",
      "batch 188: 51.60(38.67)\n",
      "batch 189: 51.61(53.33)\n",
      "batch 190: 51.62(53.33)\n",
      "batch 191: 51.57(42.67)\n",
      "batch 192: 51.49(34.67)\n",
      "batch 193: 51.53(60.00)\n",
      "batch 194: 51.48(41.33)\n",
      "batch 195: 51.54(62.67)\n",
      "batch 196: 51.54(53.33)\n",
      "batch 197: 51.61(64.00)\n",
      "batch 198: 51.59(48.00)\n",
      "batch 199: 51.62(58.67)\n",
      "batch 200: 51.59(44.00)\n",
      "batch 201: 51.64(61.33)\n",
      "batch 202: 51.55(34.67)\n",
      "batch 203: 51.57(56.00)\n",
      "batch 204: 51.53(42.67)\n",
      "batch 205: 51.40(25.33)\n",
      "batch 206: 51.40(52.00)\n",
      "batch 207: 51.45(60.00)\n",
      "batch 208: 51.42(46.67)\n",
      "batch 209: 51.50(66.67)\n",
      "batch 210: 51.55(62.67)\n",
      "batch 211: 51.49(38.67)\n",
      "batch 212: 51.55(65.33)\n",
      "batch 213: 51.56(53.33)\n",
      "batch 214: 51.64(69.33)\n",
      "batch 215: 51.66(54.67)\n",
      "batch 216: 51.60(40.00)\n",
      "batch 217: 51.70(72.00)\n",
      "batch 218: 51.75(62.67)\n",
      "batch 219: 51.68(36.00)\n",
      "batch 220: 51.73(62.67)\n",
      "batch 221: 51.71(48.00)\n",
      "batch 222: 51.63(34.67)\n",
      "batch 223: 51.58(40.00)\n",
      "batch 224: 51.60(56.00)\n",
      "batch 225: 51.57(44.00)\n",
      "batch 226: 51.48(32.00)\n",
      "batch 227: 51.47(49.33)\n",
      "batch 228: 51.48(53.33)\n",
      "batch 229: 51.45(45.33)\n",
      "batch 230: 51.40(40.00)\n",
      "batch 231: 51.37(42.67)\n",
      "batch 232: 51.32(41.33)\n",
      "batch 233: 51.27(38.67)\n",
      "batch 234: 51.32(62.67)\n",
      "batch 235: 51.26(38.67)\n",
      "batch 236: 51.21(38.67)\n",
      "batch 237: 51.18(44.00)\n",
      "batch 238: 51.13(40.00)\n",
      "batch 239: 51.07(37.33)\n",
      "batch 240: 51.09(54.67)\n",
      "batch 241: 51.17(70.67)\n",
      "batch 242: 51.12(40.00)\n",
      "batch 243: 51.16(58.67)\n",
      "batch 244: 51.16(53.33)\n",
      "batch 245: 51.15(46.67)\n",
      "batch 246: 51.14(49.33)\n",
      "batch 247: 51.16(56.00)\n",
      "batch 248: 51.16(52.00)\n",
      "batch 249: 51.07(29.33)\n",
      "batch 250: 51.13(64.00)\n",
      "batch 251: 51.20(70.67)\n",
      "batch 252: 51.20(50.67)\n",
      "batch 253: 51.23(58.67)\n",
      "batch 254: 51.19(40.00)\n",
      "batch 255: 51.16(44.00)\n",
      "batch 256: 51.17(54.67)\n",
      "batch 257: 51.11(34.67)\n",
      "batch 258: 51.07(41.33)\n",
      "batch 259: 51.04(42.67)\n",
      "batch 260: 51.06(57.33)\n",
      "batch 261: 51.11(62.67)\n",
      "batch 262: 51.17(66.67)\n",
      "batch 263: 51.26(76.00)\n",
      "batch 264: 51.26(52.00)\n",
      "batch 265: 51.15(22.67)\n",
      "batch 266: 51.14(46.67)\n",
      "batch 267: 51.14(52.00)\n",
      "batch 268: 51.13(49.33)\n",
      "batch 269: 51.16(57.33)\n",
      "batch 270: 51.15(49.33)\n",
      "batch 271: 51.15(50.67)\n",
      "batch 272: 51.20(64.00)\n",
      "batch 273: 51.16(40.00)\n",
      "batch 274: 51.22(68.00)\n",
      "batch 275: 51.20(48.00)\n",
      "batch 276: 51.18(45.33)\n",
      "batch 277: 51.23(62.67)\n",
      "batch 278: 51.20(45.33)\n",
      "batch 279: 51.18(44.00)\n",
      "batch 280: 51.25(72.00)\n",
      "batch 281: 51.25(50.67)\n",
      "batch 282: 51.19(34.67)\n",
      "batch 283: 51.22(60.00)\n",
      "batch 284: 51.22(49.33)\n",
      "batch 285: 51.28(69.33)\n",
      "batch 286: 51.33(65.33)\n",
      "batch 287: 51.35(57.33)\n",
      "batch 288: 51.36(53.33)\n",
      "batch 289: 51.41(66.67)\n",
      "batch 290: 51.45(62.67)\n",
      "batch 291: 51.37(29.33)\n",
      "batch 292: 51.44(70.67)\n",
      "batch 293: 51.45(54.67)\n",
      "batch 294: 51.50(66.67)\n",
      "batch 295: 51.50(52.00)\n",
      "batch 296: 51.55(64.00)\n",
      "batch 297: 51.52(42.67)\n",
      "batch 298: 51.57(69.33)\n",
      "batch 299: 51.57(49.33)\n",
      "batch 300: 51.61(65.33)\n",
      "batch 301: 51.61(52.00)\n",
      "batch 302: 51.61(49.33)\n",
      "batch 303: 51.55(33.33)\n",
      "batch 304: 51.64(80.00)\n",
      "batch 305: 51.73(80.00)\n",
      "batch 306: 51.71(44.00)\n",
      "batch 307: 51.68(42.67)\n",
      "batch 308: 51.74(70.67)\n",
      "batch 309: 51.74(52.00)\n",
      "batch 310: 51.76(58.67)\n",
      "batch 311: 51.73(41.33)\n",
      "batch 312: 51.68(34.67)\n",
      "batch 313: 51.63(37.33)\n",
      "batch 314: 51.62(49.33)\n",
      "batch 315: 51.61(48.00)\n",
      "batch 316: 51.60(49.33)\n",
      "batch 317: 51.59(48.00)\n",
      "batch 318: 51.59(50.67)\n",
      "batch 319: 51.64(69.33)\n",
      "batch 320: 51.61(41.33)\n",
      "batch 321: 51.57(37.33)\n",
      "batch 322: 51.52(34.67)\n",
      "batch 323: 51.49(42.67)\n",
      "batch 324: 51.51(58.67)\n",
      "batch 325: 51.45(33.33)\n",
      "batch 326: 51.37(25.33)\n",
      "batch 327: 51.38(52.00)\n",
      "batch 328: 51.33(37.33)\n",
      "batch 329: 51.33(49.33)\n",
      "batch 330: 51.31(46.67)\n",
      "batch 331: 51.31(49.33)\n",
      "batch 332: 51.34(62.67)\n",
      "batch 333: 51.35(53.33)\n",
      "batch 334: 51.36(56.00)\n",
      "batch 335: 51.36(50.67)\n",
      "batch 336: 51.40(64.00)\n",
      "batch 337: 51.38(46.67)\n",
      "batch 338: 51.39(53.33)\n",
      "batch 339: 51.34(33.33)\n",
      "batch 340: 51.31(41.33)\n",
      "batch 341: 51.31(52.00)\n",
      "batch 342: 51.36(70.67)\n",
      "batch 343: 51.30(30.67)\n",
      "batch 344: 51.33(60.00)\n",
      "batch 345: 51.31(44.00)\n",
      "batch 346: 51.29(46.67)\n",
      "batch 347: 51.29(50.67)\n",
      "batch 348: 51.24(32.00)\n",
      "batch 349: 51.24(52.00)\n",
      "batch 350: 51.31(76.00)\n",
      "batch 351: 51.29(45.33)\n",
      "batch 352: 51.31(56.00)\n",
      "batch 353: 51.28(41.33)\n",
      "batch 354: 51.25(40.00)\n",
      "batch 355: 51.18(29.33)\n",
      "batch 356: 51.19(54.67)\n",
      "batch 357: 51.14(33.33)\n",
      "batch 358: 51.15(53.33)\n",
      "batch 359: 51.21(72.00)\n",
      "batch 360: 51.20(49.33)\n",
      "batch 361: 51.18(41.33)\n",
      "batch 362: 51.16(44.00)\n",
      "batch 363: 51.21(69.33)\n",
      "batch 364: 51.21(52.00)\n",
      "batch 365: 51.23(57.33)\n",
      "batch 366: 51.18(34.67)\n",
      "batch 367: 51.13(32.00)\n",
      "batch 368: 51.07(29.33)\n",
      "batch 369: 51.11(66.67)\n",
      "batch 370: 51.11(52.00)\n",
      "batch 371: 51.12(52.00)\n",
      "batch 372: 51.11(50.67)\n",
      "batch 373: 51.02(17.33)\n",
      "batch 374: 50.97(32.00)\n",
      "batch 375: 50.96(46.67)\n",
      "batch 376: 50.95(46.67)\n",
      "batch 377: 50.96(56.00)\n",
      "batch 378: 50.93(38.67)\n",
      "batch 379: 50.98(69.33)\n",
      "batch 380: 50.95(38.67)\n",
      "batch 381: 50.96(57.33)\n",
      "batch 382: 51.02(73.33)\n",
      "batch 383: 50.96(25.33)\n",
      "batch 384: 50.97(57.33)\n",
      "batch 385: 50.98(53.33)\n",
      "batch 386: 51.04(73.33)\n",
      "batch 387: 51.02(44.00)\n",
      "batch 388: 51.06(68.00)\n",
      "batch 389: 51.07(53.33)\n",
      "batch 390: 51.13(74.67)\n",
      "batch 391: 51.17(66.67)\n",
      "batch 392: 51.13(37.33)\n",
      "batch 393: 51.18(68.00)\n",
      "batch 394: 51.15(42.67)\n",
      "batch 395: 51.13(40.00)\n",
      "batch 396: 51.17(69.33)\n",
      "batch 397: 51.20(61.33)\n",
      "batch 398: 51.18(42.67)\n",
      "batch 399: 51.24(77.33)\n",
      "batch 400: 51.24(50.67)\n",
      "batch 401: 51.25(53.33)\n",
      "batch 402: 51.29(70.67)\n",
      "batch 403: 51.28(46.67)\n",
      "batch 404: 51.27(46.67)\n",
      "batch 405: 51.28(53.33)\n",
      "batch 406: 51.24(36.00)\n",
      "batch 407: 51.25(54.67)\n",
      "batch 408: 51.25(53.33)\n",
      "batch 409: 51.28(64.00)\n",
      "batch 410: 51.29(56.00)\n",
      "batch 411: 51.27(41.33)\n",
      "batch 412: 51.24(40.00)\n",
      "batch 413: 51.26(60.00)\n",
      "batch 414: 51.28(58.67)\n",
      "batch 415: 51.24(36.00)\n",
      "batch 416: 51.26(57.33)\n",
      "batch 417: 51.33(78.67)\n",
      "batch 418: 51.33(53.33)\n",
      "batch 419: 51.33(52.00)\n",
      "batch 420: 51.38(70.67)\n",
      "batch 421: 51.39(57.33)\n",
      "batch 422: 51.45(77.33)\n",
      "batch 423: 51.50(72.00)\n",
      "batch 424: 51.53(61.33)\n",
      "batch 425: 51.55(60.00)\n",
      "batch 426: 51.54(49.33)\n",
      "batch 427: 51.50(36.00)\n",
      "batch 428: 51.47(38.67)\n",
      "batch 429: 51.48(54.67)\n",
      "batch 430: 51.54(78.67)\n",
      "batch 431: 51.58(65.33)\n",
      "batch 432: 51.56(46.67)\n",
      "batch 433: 51.58(58.67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 434: 51.62(69.33)\n",
      "batch 435: 51.63(56.00)\n",
      "batch 436: 51.68(70.67)\n",
      "batch 437: 51.68(54.67)\n",
      "batch 438: 51.70(58.67)\n",
      "batch 439: 51.71(58.67)\n",
      "batch 440: 51.71(49.33)\n",
      "batch 441: 51.76(74.67)\n",
      "batch 442: 51.81(72.00)\n",
      "batch 443: 51.83(60.00)\n",
      "batch 444: 51.83(56.00)\n",
      "batch 445: 51.83(50.67)\n",
      "batch 446: 51.85(61.33)\n",
      "batch 447: 51.86(53.33)\n",
      "batch 448: 51.82(37.33)\n",
      "batch 449: 51.83(56.00)\n",
      "batch 450: 51.83(52.00)\n",
      "batch 451: 51.84(53.33)\n",
      "batch 452: 51.78(25.33)\n",
      "batch 453: 51.76(42.67)\n",
      "batch 454: 51.77(54.67)\n",
      "batch 455: 51.78(58.67)\n",
      "batch 456: 51.77(45.33)\n",
      "batch 457: 51.79(62.67)\n",
      "batch 458: 51.82(64.00)\n",
      "batch 459: 51.84(61.33)\n",
      "batch 460: 51.83(48.00)\n",
      "batch 461: 51.78(29.33)\n",
      "batch 462: 51.83(73.33)\n",
      "batch 463: 51.81(45.33)\n",
      "batch 464: 51.81(52.00)\n",
      "batch 465: 51.82(54.67)\n",
      "batch 466: 51.81(45.33)\n",
      "batch 467: 51.81(52.00)\n",
      "batch 468: 51.81(53.33)\n",
      "batch 469: 51.84(66.67)\n",
      "batch 470: 51.85(56.00)\n",
      "batch 471: 51.87(61.33)\n",
      "batch 472: 51.88(57.33)\n",
      "batch 473: 51.90(62.67)\n",
      "batch 474: 51.93(62.67)\n",
      "batch 475: 51.89(36.00)\n",
      "batch 476: 51.87(42.67)\n",
      "batch 477: 51.89(57.33)\n",
      "batch 478: 51.85(34.67)\n",
      "batch 479: 51.87(60.00)\n",
      "batch 480: 51.88(58.67)\n",
      "batch 481: 51.89(56.00)\n",
      "batch 482: 51.89(54.67)\n",
      "batch 483: 51.90(56.00)\n",
      "batch 484: 51.90(50.67)\n",
      "batch 485: 51.85(29.33)\n",
      "batch 486: 51.84(46.67)\n",
      "batch 487: 51.89(73.33)\n",
      "batch 488: 51.90(60.00)\n",
      "batch 489: 51.92(61.33)\n",
      "batch 490: 51.97(73.33)\n",
      "batch 491: 51.96(49.33)\n",
      "batch 492: 51.96(53.33)\n",
      "batch 493: 51.97(53.33)\n",
      "batch 494: 51.95(45.33)\n",
      "batch 495: 51.98(62.67)\n",
      "batch 496: 52.00(62.67)\n",
      "batch 497: 52.00(54.67)\n",
      "batch 498: 52.02(60.00)\n",
      "batch 499: 52.01(49.33)\n",
      "batch 500: 51.99(42.67)\n",
      "batch 501: 51.99(49.33)\n",
      "batch 502: 51.98(48.00)\n",
      "batch 503: 51.96(42.67)\n",
      "batch 504: 52.00(69.33)\n",
      "batch 505: 51.96(34.67)\n",
      "batch 506: 51.98(61.33)\n",
      "batch 507: 51.96(42.67)\n",
      "batch 508: 51.95(46.67)\n",
      "batch 509: 51.91(30.67)\n",
      "batch 510: 51.95(69.33)\n",
      "batch 511: 51.94(49.33)\n",
      "batch 512: 51.94(52.00)\n",
      "batch 513: 51.97(68.00)\n",
      "batch 514: 51.96(45.33)\n",
      "batch 515: 51.92(30.67)\n",
      "batch 516: 51.89(36.00)\n",
      "batch 517: 51.91(66.67)\n",
      "batch 518: 51.95(72.00)\n",
      "batch 519: 51.95(49.33)\n",
      "batch 520: 51.93(40.00)\n",
      "batch 521: 51.88(26.67)\n",
      "batch 522: 51.87(48.00)\n",
      "batch 523: 51.85(42.67)\n",
      "batch 524: 51.88(65.33)\n",
      "batch 525: 51.87(46.67)\n",
      "batch 526: 51.87(53.33)\n",
      "batch 527: 51.91(70.67)\n",
      "batch 528: 51.90(50.67)\n",
      "batch 529: 51.88(41.33)\n",
      "batch 530: 51.91(64.00)\n",
      "batch 531: 51.88(37.33)\n",
      "batch 532: 51.90(61.33)\n",
      "batch 533: 51.92(66.67)\n",
      "batch 534: 51.94(57.33)\n",
      "batch 535: 51.91(38.67)\n",
      "batch 536: 51.91(52.00)\n",
      "batch 537: 51.91(52.00)\n",
      "batch 538: 51.90(48.00)\n",
      "batch 539: 51.88(40.00)\n",
      "batch 540: 51.89(58.67)\n",
      "batch 541: 51.84(24.00)\n",
      "batch 542: 51.83(42.67)\n",
      "batch 543: 51.81(41.33)\n",
      "batch 544: 51.77(33.33)\n",
      "batch 545: 51.82(78.67)\n",
      "batch 546: 51.82(49.33)\n",
      "batch 547: 51.79(34.67)\n",
      "batch 548: 51.80(58.67)\n",
      "batch 549: 51.83(66.67)\n",
      "batch 550: 51.82(50.67)\n",
      "batch 551: 51.83(56.00)\n",
      "batch 552: 51.84(56.00)\n",
      "batch 553: 51.84(53.33)\n",
      "batch 554: 51.84(53.33)\n",
      "batch 555: 51.85(53.33)\n",
      "batch 556: 51.81(30.67)\n",
      "batch 557: 51.79(44.00)\n",
      "batch 558: 51.82(64.00)\n",
      "batch 559: 51.81(46.67)\n",
      "batch 560: 51.82(57.33)\n",
      "batch 561: 51.84(62.67)\n",
      "batch 562: 51.84(52.00)\n",
      "batch 563: 51.83(50.67)\n",
      "batch 564: 51.84(53.33)\n",
      "batch 565: 51.86(62.67)\n",
      "batch 566: 51.88(68.00)\n",
      "batch 567: 51.88(52.00)\n",
      "batch 568: 51.88(50.67)\n",
      "batch 569: 51.87(46.67)\n",
      "batch 570: 51.90(65.33)\n",
      "batch 571: 51.92(65.33)\n",
      "batch 572: 51.89(36.00)\n",
      "batch 573: 51.91(61.33)\n",
      "batch 574: 51.89(40.00)\n",
      "batch 575: 51.89(53.33)\n",
      "batch 576: 51.85(28.00)\n",
      "batch 577: 51.87(62.67)\n",
      "batch 578: 51.86(46.67)\n",
      "batch 579: 51.84(38.67)\n",
      "batch 580: 51.82(41.33)\n",
      "batch 581: 51.84(65.33)\n",
      "batch 582: 51.85(57.33)\n",
      "batch 583: 51.85(49.33)\n",
      "batch 584: 51.84(48.00)\n",
      "batch 585: 51.86(64.00)\n",
      "batch 586: 51.87(57.33)\n",
      "batch 587: 51.86(45.33)\n",
      "batch 588: 51.82(29.33)\n",
      "batch 589: 51.85(68.00)\n",
      "batch 590: 51.84(44.00)\n",
      "batch 591: 51.84(53.33)\n",
      "batch 592: 51.83(49.33)\n",
      "batch 593: 51.84(53.33)\n",
      "batch 594: 51.82(44.00)\n",
      "batch 595: 51.81(45.33)\n",
      "batch 596: 51.82(54.67)\n",
      "batch 597: 51.83(60.00)\n",
      "batch 598: 51.81(42.67)\n",
      "batch 599: 51.82(52.00)\n",
      "batch 600: 51.81(50.67)\n",
      "batch 601: 51.82(53.33)\n",
      "batch 602: 51.83(58.67)\n",
      "batch 603: 51.79(30.67)\n",
      "batch 604: 51.82(70.67)\n",
      "batch 605: 51.83(57.33)\n",
      "batch 606: 51.83(48.00)\n",
      "batch 607: 51.80(37.33)\n",
      "batch 608: 51.78(36.00)\n",
      "batch 609: 51.80(68.00)\n",
      "batch 610: 51.78(40.00)\n",
      "batch 611: 51.78(52.00)\n",
      "batch 612: 51.80(62.67)\n",
      "batch 613: 51.81(56.00)\n",
      "batch 614: 51.84(72.00)\n",
      "batch 615: 51.84(52.00)\n",
      "batch 616: 51.87(66.67)\n",
      "batch 617: 51.88(61.33)\n",
      "batch 618: 51.89(54.67)\n",
      "batch 619: 51.89(57.33)\n",
      "batch 620: 51.88(45.33)\n",
      "batch 621: 51.90(61.33)\n",
      "batch 622: 51.91(58.67)\n",
      "batch 623: 51.94(68.00)\n",
      "batch 624: 51.91(36.00)\n",
      "batch 625: 51.90(48.00)\n",
      "batch 626: 51.93(66.67)\n",
      "batch 627: 51.97(76.00)\n",
      "batch 628: 51.98(60.00)\n",
      "batch 629: 51.97(49.33)\n",
      "batch 630: 51.97(48.00)\n",
      "batch 631: 51.93(30.67)\n",
      "batch 632: 51.93(48.00)\n",
      "batch 633: 51.95(68.00)\n",
      "batch 634: 51.95(52.00)\n",
      "batch 635: 51.95(50.67)\n",
      "batch 636: 51.96(57.33)\n",
      "batch 637: 51.97(60.00)\n",
      "batch 638: 51.96(41.33)\n",
      "batch 639: 51.95(46.67)\n",
      "batch 640: 51.98(69.33)\n",
      "batch 641: 51.94(29.33)\n",
      "batch 642: 51.95(56.00)\n",
      "batch 643: 51.92(36.00)\n",
      "batch 644: 51.88(25.33)\n",
      "batch 645: 51.91(70.67)\n",
      "batch 646: 51.89(37.33)\n",
      "batch 647: 51.90(62.67)\n",
      "batch 648: 51.90(52.00)\n",
      "batch 649: 51.92(60.00)\n",
      "batch 650: 51.92(54.67)\n",
      "batch 651: 51.93(58.67)\n",
      "batch 652: 51.92(42.67)\n",
      "batch 653: 51.92(57.33)\n",
      "batch 654: 51.95(66.67)\n",
      "batch 655: 51.95(50.67)\n",
      "batch 656: 51.93(44.00)\n",
      "batch 657: 51.95(60.00)\n",
      "batch 658: 51.98(72.00)\n",
      "batch 659: 51.97(46.67)\n",
      "batch 660: 51.97(56.00)\n",
      "batch 661: 51.99(61.33)\n",
      "batch 662: 51.98(44.00)\n",
      "batch 663: 52.00(65.33)\n",
      "batch 664: 51.99(49.33)\n",
      "batch 665: 51.99(50.67)\n",
      "batch 666: 52.00(58.67)\n",
      "batch 667: 52.02(65.33)\n",
      "batch 668: 52.03(60.00)\n",
      "batch 669: 52.04(56.00)\n",
      "batch 670: 52.04(53.33)\n",
      "batch 671: 52.08(76.00)\n",
      "batch 672: 52.05(36.00)\n",
      "batch 673: 52.05(53.33)\n",
      "batch 674: 52.07(60.00)\n",
      "batch 675: 52.08(65.33)\n",
      "batch 676: 52.06(32.00)\n",
      "batch 677: 52.08(66.67)\n",
      "batch 678: 52.10(65.33)\n",
      "batch 679: 52.09(50.67)\n",
      "batch 680: 52.08(45.33)\n",
      "batch 681: 52.07(45.33)\n",
      "batch 682: 52.08(53.33)\n",
      "batch 683: 52.06(41.33)\n",
      "batch 684: 52.04(34.67)\n",
      "batch 685: 52.04(56.00)\n",
      "batch 686: 52.04(52.00)\n",
      "batch 687: 52.05(60.00)\n",
      "batch 688: 52.07(62.67)\n",
      "batch 689: 52.04(34.67)\n",
      "batch 690: 52.03(41.33)\n",
      "batch 691: 52.03(50.67)\n",
      "batch 692: 52.01(40.00)\n",
      "batch 693: 52.02(57.33)\n",
      "batch 694: 52.02(54.67)\n",
      "batch 695: 52.04(68.00)\n",
      "batch 696: 52.03(44.00)\n",
      "batch 697: 52.00(33.33)\n",
      "batch 698: 52.02(66.67)\n",
      "batch 699: 52.02(48.00)\n",
      "batch 700: 52.01(48.00)\n",
      "batch 701: 52.04(69.33)\n",
      "batch 702: 52.04(54.67)\n",
      "batch 703: 52.03(45.33)\n",
      "batch 704: 52.02(45.33)\n",
      "batch 705: 52.02(46.67)\n",
      "batch 706: 52.01(46.67)\n",
      "batch 707: 52.01(52.00)\n",
      "batch 708: 51.98(36.00)\n",
      "batch 709: 52.00(65.33)\n",
      "batch 710: 52.02(65.33)\n",
      "batch 711: 52.04(61.33)\n",
      "batch 712: 52.02(44.00)\n",
      "batch 713: 52.04(61.33)\n"
     ]
    }
   ],
   "source": [
    "! python train_protonet.py --gpu 0 --hyperbolic --dataset CUB --dim 512 --lr 0.001 --c 0.05 --gamma 0.7 --step_size 20 --max_epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protonet_val_results = [0.4196, 0.4564, 0.4796, 0.4971, 0.5165, 0.5304, 0.5340, 0.5468, 0.5683, 0.5500]\n",
    "hypnet_val_results = [0.2871, 0.2812, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(protonet_val_results, label='ProtNet Khrulkov Hyperbolic')\n",
    "plt.plot(hypnet_val_results, label='HypNet Hyperbolic')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
